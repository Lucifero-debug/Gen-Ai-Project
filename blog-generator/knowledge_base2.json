[
  {
    "title": "Private Business, Government and Blockchain",
    "content": "Private Business, Government and Blockchain\n\nA major private IT company implements blockchain, artificial intelligence, and Internet of Things to optimize and improve high technology workflow. The representatives of a major state structure from the same country like this experiment so much they decide to use it in their work and conclude an agreement with the IT giant. This is an ideal example of interaction between private business and the state regarding blockchain, don\u2019t you think? What is even better is that this story is real: in South Korea a local customs office has signed the respective partnership agreement with Samsung. I believe that the near-term development of blockchain will be built on just such examples of cooperation. In a world where all the best technological decisions are copied at supersonic speed, one cannot remain behind the trends for long. That\u2019s why I\u2019m confident that blockchain and other crypto technologies will soon be adopted around the world. In the 21st century it would be strange to go searching for a telephone booth to make a call, when you can do so from anywhere on the planet with one click on your gadget.\nhttps://www.coindesk.com/korea-taps-samsungs-blockchain-tech-to-fight-customs-fraud/\n"
  },
  {
    "title": "Private Business, Government and Blockchain",
    "content": "Private Business, Government and Blockchain\n\nA major private IT company implements blockchain, artificial intelligence, and Internet of Things to optimize and improve high technology workflow. The representatives of a major state structure from the same country like this experiment so much they decide to use it in their work and conclude an agreement with the IT giant. This is an ideal example of interaction between private business and the state regarding blockchain, don\u2019t you think? What is even better is that this story is real: in South Korea a local customs office has signed the respective partnership agreement with Samsung. I believe that the near-term development of blockchain will be built on just such examples of cooperation. In a world where all the best technological decisions are copied at supersonic speed, one cannot remain behind the trends for long. That\u2019s why I\u2019m confident that blockchain and other crypto technologies will soon be adopted around the world. In the 21st century it would be strange to go searching for a telephone booth to make a call, when you can do so from anywhere on the planet with one click on your gadget.\nhttps://www.coindesk.com/korea-taps-samsungs-blockchain-tech-to-fight-customs-fraud/\n"
  },
  {
    "title": "Private Business, Government and Blockchain",
    "content": "Private Business, Government and Blockchain\n\nA major private IT company implements blockchain, artificial intelligence, and Internet of Things to optimize and improve high technology workflow. The representatives of a major state structure from the same country like this experiment so much they decide to use it in their work and conclude an agreement with the IT giant. This is an ideal example of interaction between private business and the state regarding blockchain, don\u2019t you think? What is even better is that this story is real: in South Korea a local customs office has signed the respective partnership agreement with Samsung. I believe that the near-term development of blockchain will be built on just such examples of cooperation. In a world where all the best technological decisions are copied at supersonic speed, one cannot remain behind the trends for long. That\u2019s why I\u2019m confident that blockchain and other crypto technologies will soon be adopted around the world. In the 21st century it would be strange to go searching for a telephone booth to make a call, when you can do so from anywhere on the planet with one click on your gadget.\nhttps://www.coindesk.com/korea-taps-samsungs-blockchain-tech-to-fight-customs-fraud/\n"
  },
  {
    "title": "EPQ draft 1 (4844 words)",
    "content": "EPQ draft 1 (4844 words)\nhttps://upload.wikimedia.org/wikipedia/commons/1/1f/Sanko_Seisakusyo_%28%E4%B8%89%E5%B9%B8%E8%A3%BD%E4%BD%9C%E6%89%80%29_%E2%80%93_Tin_Wind_Up_%E2%80%93_Tiny_Smoking_Spaceman_Robots_%E2%80%93_Close_Up.jpg\nIntroduction\nAutomation is set to un-employ people at a scale and rate never seen before, while simultaneously changing societies very nature on an epic scale; to mitigate its impact we must undertake projects and policies that push ourselves, humanity, and society to its limits. The future could take one of two shapes; a utopian wonderland where everyone is happy, or a dystopia where algorithms and machines run the world for maximum efficiency leaving humanity in the slums. However, despite the impending danger, we are seemingly unaware of it. This is because automation creeps in slowly, so we don\u2019t notice it, only once the teamsters, lawyers, and the CEO\u2019s start to lose their jobs will we notice the extent of what we have created. This is nature of automation you don\u2019t notice until it\u2019s your job, your income, your life that is affected.\nHowever, we might hope that our governments have foreseen this danger and are planning how to avoid it. Yet we do not see any real indication from the government (as of time of writing) that they need to do anything to prepare for the unemployed masses. On the contrary in the 2017 autumn budget the government announced that they wanted to see fully driverless cars by 2021 (HM Treasury, 2017). This is even though a CGPS study showed that over 4 million jobs will be lost to driverless cars in the US (Center for Global Policy Solutions., 2017). IN this report I aim to investigate three main key factors that need to be addressed by both policy makers and the public, to prepare ourselves for the future. These are; Too what extent will automation occur, how will this automation effect society and how should we mitigate its impact? By answering these three questions I hope to bring further clarity to a pressing issue that will affect society from top to bottom.\nToo what extent will automation happen\nThe first question that must be answered in this topic is how much automation will occur. There have been many studies that have attempted to estimate this, and their findings have varied considerably. The most recent study is one by PWC (Berriman & Hawksworth, 2017). By analyzing the other studies and improving upon their methods, they conducted a new survey which concluded that.\n\u201cOur analysis suggests that up to 30% of UK jobs could potentially be at high risk of automation by the early 2030s, lower than the US (38%) or Germany (35%), but higher than Japan (21%).\u201d (Berriman & Hawksworth, 2017) I have converted this data into a graph below along with other recent studies.\n\nAs we can see from the graph the results of automation studies vary greatly. The original study by FO classified jobs as automatable or not by looking at whether most of its tasks could be automated, this meant that they could develop an algorithm to predict what jobs could and could not be automated. AGZ on the other hand, claimed a job was only automatable if all its tasks where fully automatable. This however leads to a vastly reduced number of jobs being classed as automatable. If a job has ten parts and five can be automated surely you can still fire half the workers and maintain the same output. This meant that the results of the AGZ study underestimate the likely impact of automation. For this reason, I have chosen to use the most recent study (PwC) to base my study off.\nWill new jobs be created?\nIf we can have expected jobs to be lost surely, we should also expect new ones to be created to take their place? However, despite this logic the data suggests otherwise see the graph below (Durden, 2017).\n\nAs we can see quite clearly although rig count and therefore oil production has increased, the number of employers has stayed almost the same. This indicates that we are producing more oil with less and less energy required. What\u2019s more interesting if you look at the percentage of eligible workers employed over time (Gross, 2016).\n\nAs you can see from the graph, the percentage of people employed increases until a recession; at this point employment drops as business make cuts and increase automation, employment regains and then falls. Overtime this cycle reduces peak employment. Furthermore, we can see that the greater the recession the more jobs are irretrievably lost. Currently many believe that we could be in one of the biggest bubbles of all time. The crypto bubble. This term refers to the presumed bubble of cryptocurrencies such as bitcoin and Ethereum. The graph below shows the price of bitcoin over the last year alone (Coindesk, 2017).\n\nIt is widely assumed and even accepted that the crypto bubble will be the biggest of our lifetimes and that at some point it will almost certainly burst crashing everyone else with it. This conclusion is mainly drawn from its similarities to the dotcom bubble which burst in 2000\u20132002. In comparison to the crypto bubble the dot com bubble is expected to look almost reasonable. However, many technology enthusiasts point out that this is okay seeming as we do now all use the internet (Katz & Verhage, 2017). Either way if this is a bubble then we should expect to see job losses in the extremes, jobs that we should not expect to return.\nFinally, we must consider whether the new sectors will produce new jobs. Technologists often argue that despite jobs being automated its fine because new jobs such as software developers are being created. And yes, this is true. Whilst it would be unthinkable for the jobs \u2018Computer Software Engineer\u2019 or \u2018Computer Programmer\u2019 to have existed back in 1980 and now there is 1,300,000 of them. Does not deny the fact that one team of software engineers eleven can design, build, and deploy the next \u2018killer app\u2019 within two years and walk away with one billion dollars from its sale. This is the story of Instagram (BBC News technology, 2012). This is a classic case; one we can expect to see much more of. It demonstrates that you no longer need tons of workers to make tons of money. So yes while a few new jobs will be created, we should not rely on these new jobs to support people.\nIn conclusion we can expect to see lots of job losses within the next 30 years. This is due to the combined effect of automation enabling more jobs to be automated and an impending recession that will drive business to make cuts and improve their business efficiency, with an increasingly small number of people required to make a business successful. We can expect to see unemployment rise to 30% by 2030 and possibly even as high as 50% by 2050.\nWhy do we work?\nThroughout all of time humanity has been in a constant struggle to survive. From stone age man hunting the mighty mammoth, to office workers hunting the mighty pay rise. Humans have always had to strive to survive. Never have we been given the opportunity to simply have it provided to us, although yes, we do get our sustenance easier now than ever before we still must work to get it. But what if we didn\u2019t?\nThere are three main points of view on the meaning of work. Some people believe that we work because it gives us meaning, that without it we would be aimless with no purpose. The other group say that we work simply for the money and that if that wasn\u2019t an issue we could quite happily live our lives doing what we really wanted to do.\n\nSome people argue that we work to give meaning to our lives. If we did not work, we would all very quickly turn to violence and crime. To find out more about this I conducted a survey of 249 random subjects.\n\nFrom this we can see that people are clearly divided on the topic. But I was asking about work in general. If, however you ask someone whether their job has meaning you get a very different response. This is demonstrated by a 2015 YouGov poll. The poll showed that 37% of people do not believe that their job is contributing to the world (Yougov, 2015). This is a shocking statistic and makes us wonder quite what jobs these people are doing that they their jobs as pointless.\n\nBy analysing the data in the survey, we can conclude that working class people are more likely to believe that their job is not having a meaningful contribution to the world than middle class people. We can also see that some areas have significantly lower levels of meaningfulness than others such as London. Despite the elevated levels of meaninglessness in London less people said that they would be \u201cnot proud to tell a stranger what their job was\u201d, unlike in Scotland where there are elevated levels of meaningfulness and elevated levels of shame.\n\nSo, we can conclude that people in lower economic brackets are more likely to see themselves in pointless jobs. We can also see that people in areas of high population concentration such as London and the north are more likely to be not fulfilled by their job.\nIn August 2013 David Graeber wrote an influential article for STRIKE! Magazine (Graeber, 2013).In this article he argued that many modern jobs are \u2018bullshit jobs\u2019. They point out that in 1930 John Maynard Keynes (arguably the capitalist equivalent to Karl Marx), predicted that by the centuries end that developed countries such as Great Britain would be so technologically advanced that people who lived there would on average work only 15 hours a week. And yes, as predicted most of manufacturing jobs have been automated yet despite this we have not achieved the 15-hour week. Graeber argues that this is due to the creation of \u2018bullshit jobs\u2019. There has been a massive explosion in the services/administration sector. In fact, between 1948 and 2011 the services sector in the US has\nFigure 3: https ://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\ngone from 45% of total employment to 68% of total employment (not including government jobs) (The Economist, 2014)\nThe new services sector comprises many jobs such as:\n\u00b7 Financial services\n\u00b7 Telemarketing\n\u00b7 Corporate law\n\u00b7 Academic/health administration\n\u00b7 Human resources\n\u00b7 Public relations\nThese are what Graeber proposes are \u2018bullshit jobs\u2019. A bullshit hob is one that provides little or no meaning to society and the world. And yet even though the people doing these jobs find them pointless they continue to do them. And what\u2019s more they continue to be created.\nFigure 4: https://www.vice.com/en_uk/article/yvq9qg/david-graeber-pointless-jobs-tube-poster-interview-912\nIf bullshit jobs are pointless why are they created? Many would argue that society creates jobs to ensure that they can continue to partake in society. Some would argue that because of this if people did not have to work to have a good enough income to live on then they would not work. They argue that instead they would spend their time doing things they enjoy and getting the education required to do interesting jobs such as medicine or teaching. This is backed up by universal basic income studies. A universal basic income is a guaranteed income that is paid to all eligible members of society. This is often done by a negative income tax; this is where after earning below a certain point the state stats to give you a guaranteed income. Most importantly however this payment has no strings attached. This means that if people want to then they can and can do no work and just live of benefits. However, the statistics from the studies do not show that this happens. In 1974 a basic income study was carried out in Manitoba (Canada); it showed that people barely reduced their working hours, and those that did used it to spend more time with their families and or taking additional classes reaping untold benefits for the economy (Hum & Simpson, 1993).\nMany argue that even if automation does occur then people could continue to do jobs that give them meaning if they wish. Just because a job could be done by a robot does not necessarily mean it will be. If people find meaning in work, then they can continue to do so. However, if your job is mind bogglingly boring then why should you have to do it if you don\u2019t want to? As we enter the new automated age then we are going to have to realize that we should have fun in life and if that means not working then so be it. But the clear majority will find something to do be it inventing, painting, or pushing the boundaries we must accept that our society will change to accommodate our new-found freedom.\nHow can we mitigate its impact?\nWorking on the dual assumptions that; soon robotic automation will increase so that 30% of jobs become automated (with not enough being created to replace them), and that in our current state if we get rid of work then there would be large increases in crime and violence. We can conclude that preemptive measures need to take preemptive measures to mitigate the impact. I have split these preemptive measures into two main types.\n\nOnly by combining a variety of government policies and regulation with a collective societal move towards less work based system we can ensure that minimal damage is done. This is the main subject of this report. I will first discuss potential government policies and then the action that society must implement to make the most of automation.\nGovernment policies and responsibillities\nGovernment policies come in the form of taxes, benefits, regulation, or programs. A tax is designed to incite a behavior using negative reinforcement i.e. persuade someone or a company to do something otherwise they will lose more money. Benefits give money to people (typically working-class people), this provides them with an income to survive even if they lose their jobs. Regulation prevents the development \u2018bad robots\u2019 such as terminators. Programs run by governments help to retrain people to get them new jobs by giving them new skills such as programming.\nTax\nThe tax I am investigate is a robot tax. A robot tax is a system where cooperation\u2019s are taxed depending on how much of their workforce is automated. For instance, if you were a company that \u2018employed\u2019 a robot corporate lawyer you would pay robot tax equivalent to the income tax a corporate lawyer would have paid. This money could be used to fund other government initiatives such as new benefits and retraining programs (Varoufakis, 2017). Proponents for the tax are wide ranging and include tech giants such as Bill Gates (Gates, 2017) and futurists such as Elon Musk (Musk, 2016). However, some people such as Estonian politician Andrus Ansip believe that this is a bad idea (Ansip, 2017). It is argued that it would be difficult if not impossible to calculate the equivalent wage that the robot would have earned if a human where doing the same job. Furthermore, it is argued that this would reduce innovation as it would stop companies automating jobs, this is bad as some jobs a very dangerous and it is ethical to automate them even if it means someone loses their job (Isaac & Wallace, 2017).\nBenifits\nA common suggestion to mitigate the impact of robotics is the implementation of a new benefit called a Universal Basic Income (UBI), it is also known as basic income (BI), citizens income (CI) and negative income tax (NIT). But whatever its name (I shall use UBI) it involves giving all citizens a basic income (except in NIT where it is only the poorest) (Basic Income Earth Network, 2017). It has been studied in many studies in a range of situations for a variety of clients. It is argued that doing so would be cheaper than our current welfare system, this is because there would be very low administration costs. Furthermore, it is argued (and proven in studies) that a basic income gives better outcome than independent benefits (Hum & Simpson, 1993). It is also shown to increase personal development and entrepreneurship as people have a safety floor to stand on to achieve their aims be it setting up a company or training to get into a new profession. This is how UBI solves the issue of automation, it encourages personal retraining and entrepreneurship which in turn provides new jobs and bolsters the economy. Opponents argue that a UBI would encourage crime and antisocial behavior such as drug abuse. However, a report by the world bank that summarized the findings of 30 studies disproved this (Evans & Popova, 2014).\nRegulation\nOne big worry about robots is that they will rise and take over the world. Whilst this may at first seem like an unrealistic and reactionary response to automation. However, these fears are well founded. In 2015 a robot was released by Queensland university of technology that will patrol coral reefs, and autonomously make the decision to kill the deadly crown of thorns starfish that destroys reefs (Dayoub, Dunbabin, & Corke, 2015). Although this application is undeniably good as we need to protect corals; it sets a dangerous precedent. The same technology can easily be expanded into military drones. Drones have long been used by the military, however this has led to sometimes disastrous consequences. The pilots feel detached and say it is like stepping on an ant (Pilkington, 2015). Imagine how much that feeling of detachment will become when instead of pulling a trigger you just must sign a piece of paper to authorize the strike. Despite this and warnings from high profile critics such as Stephen Hawking, Elon Musk, and Steve Wozniak (Future of Life Institute, 2015). As such it is undeniable that we should enact legislation to prevent the development of AI that decides when to kill human to ensure that we do not lose control.\nprogrames\nOne proposed solution is retraining. This is where people who have been or will be made redundant due to automation are retrained to do new jobs. This retraining is funded by the government or previous employer and is usually in the form of a course or other qualification (Carson, 2015). These types of programs are useful and are a common way to mitigate impact when unemployment occurs on a mass scale. However, the type of unemployment that we will see might not end up being concentrated as it is normally. If all the manufacturing companies fired half their workers, yes there would be a lot of unemployment, but it would be widely dispersed; it is also harder to retrain people when they are dispersed as you cannot just set up one program. Therefore, these new courses will mostly have to be done online. But this again throws up another problem. The jobs that will be created/will not be automated are not manufacturing or laboring jobs, rather ones that require intelligence, independent/creative thinking, and human understanding (see next page) (McKinsey Global Institute, 2017). We can see that the jobs that will be automated the least are all degree level, education, management (less so with this one) and professionals. From this we can conclude that instead of providing standard retraining we need to other degree level retraining. To do this though the new students will have to pay tuition fees which are prohibitively high to some students let alone parents trying to support their own children going through uni who cannot access grants. In short if we want to mass retrain people at a degree level we need to get rid of tuition fees.\n\nSocietal action\nCurrently our society is geared to attain 100% employment. This full employment model creates pointless jobs just for the sake of keeping people working (Graeber, 2013). However, if 30% of people become unemployed this model will quickly fall apart. So undoubtedly retraining programs will appear and retraining some of the unemployed. But a large portion won\u2019t want to be. If you are a lawyer, you\u2019re not going to want to retrain into a teacher or a therapist because they\u2019re completely different fields that wouldn\u2019t interest you. And even if a UBI is implemented then we can\u2019t all be entrepreneurs. This is mostly because it costs a lot less to run a successful company in the modern day. For instance, Instagram was bought for $1 billion, at that time it only had 13 employees (Geron, 2012). As this clearly shows you now need a lot less people to have an even bigger impact than ever before. So, we need to find something to occupy ourselves with.\nInterplanatary colonisation\nOne suggestion is that we apply our newfound technological capabilities to undertaking a great task such as exploring space. This has several benefits.\n1. It would retrain people\na. This is because starting a colony will take many new skills from all backgrounds. We could gear the retraining programs to train people to build rockets\n2. It would produce employment\na. Yes, it might be much cheaper to build rockets by robot but why do that when you could employ people? On earth we could use the robots to do the mundane tasks that just have to be done such as; mass farming to feed everyone, building homes, treating illnesses.\n3. Life would be less likely to be wiped out\na. We might just be the only life in the entire universe. Maybe even all of time. So it would be a real shame if we were wiped out by a single asteroid or a territorial spat or a massive plague. But if we have a self-sufficient colony on another world the chances of ALL of humanity drop to practically zero.\nDespite these benefits there are some serous disadvantages. For instance we might accidently create a dystopia such as in Kim Stanley Robinsons Mars trilogy and 2312 (Robinson, The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars, 2015) (Robinson, 2312, 2013), if we want to avoid this we should ensure that the selection criteria for colonization is not financial but based on ability.\nElimination of the great killers\nThroughout human history life has been short and nasty. If you were lucky enough to be born and your mother to have survived the ordeal you lived through roughly 40 grueling years of work to end up dead. By comparison even the poorest person in the first world would not suffer that much. However, many people in LIC\u2019s (less industrialized countries) still live in this Malthusian misery trap. However, we now have the technological abilities to free them. We could use robots to mass farm to feed cheaply people (farmbot, 2018), we could use modified 3d printers with concrete to 3d print houses in areas with high homelessness (apis-cor, 2018), and we can release genetically engineered mosquitoes to crash the population of a certain type of mosquito (Carvalho DO, 2015). All these techniques use the latest in technology and robotics to solve the great problems of the world. However, to deploy we will need to work together with a large human fleet to support it.\nA new social order\nAutomation itself will undoubtedly cause a great in politics. This is because as previously established society will have to change and so will our priorities. And seeming as political order and systems, I descended from those governed as per defined by social contract theory (Rousseau, 1913). However, as our society changes rapidly our systems will quickly unfold and become unsuitable for the modern world. This will inevitably lead to the creation of new types of government such as Futarchy (Buterin, 2014) and liquid democracy (Jochmann, 2012). However, if not properly handled the opportunity maybe seized by the \u2018new radicals\u2019 such as Donald Trump and Heinz-Christian Strache (Carswell, 2017). However, if we can seize the opportunity then we have a chance like no other to make a real lasting impact on the world.\nConclusion\nRobotic automation will have a wide-ranging effect on society. The predicted levels of unemployment can only be described as catastrophic by today\u2019s standards. To cope with this change, we must find meaning in our lives and our existence. To cope we will take on new and exciting challenges such as founding a Martian colony and becoming more than human. Sadly, though the governments that have the power to enact the decisions required to help humanity cope with the turbulence of change, seem blissfully ignorant of the dire need for discussion and debate on this most important debate.\nBibliography\nAnsip, A. (2017, June 2). EU Commissioner Says No to Bill Gates\u2019 Robot Tax Idea. (CNBC, Interviewer)\napis-cor. (2018, January 7). Home apis-cor. Retrieved from apis-cor: http://apis-cor.com/en\nArntz, M., Gregory, T., & Ulrich, Z. (2016). The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis. OECD Social, Employment and Migration Working. Paris: OECD Publishing. doi:http://dx.doi.org/10.1787/5jlz9h56dvq7-en\nBasic Income Earth Network. (2017, December 28). BIEN: Basic Income Earth Network. Retrieved from About basic income: http://basicincome.org/basic-income/\nBBC News technology. (2012, April 10). BBC. Retrieved from BBC|News|Technology|Facebook buys Instagram photo sharing network for $1bn: http://www.bbc.co.uk/news/technology-17658264\nBerriman, R., & Hawksworth, J. (2017). Will robots steal our jobs? The potential impact of automation on the UK and other major economies. London: Price-waterhouse-Coopers LLP.\nButerin, V. (2014, August 21). An Introduction to Futarchy. Retrieved from Ethereum blog: https://blog.ethereum.org/2014/08/21/introduction-futarchy/\nCarson, E. (2015, August 3). How workers can retrain for careers in an automated world. Retrieved from ZDnet: http://www.zdnet.com/article/how-workers-can-retrain-for-careers-in-an-automated-world/\nCarvalho DO, M. A. (2015). Suppression of a Field Population of Aedes aegypti in Brazil by Sustained Release of Transgenic Male Mosquitoes. PLoS Negl Trop Dis, 1. Retrieved from https://doi.org/10.1371/journal.pntd.0003864\nCenter for Global Policy Solutions. (2017). Stick Shift: Autonomous Vehicles, Driving Jobs, and the Future of Work. Washington, DC: Center for Global Policy Solutions.\nCoindesk. (2017, November 30). Price page, 2017\u20132018. Retrieved from Coindesk: https://www.coindesk.com/price/\nDayoub, F., Dunbabin, M., & Corke, P. (2015). Robotic Detection and Tracking of Crown-of-Thorns Starfish. Queensland: Queensland University of Technology.\nDurden, T. (2017, Febuary 3). Rig Count Surges Again To 16-Month Highs (But Where\u2019s The Oil Industry Jobs). Retrieved from ZeroHedge: http://www.zerohedge.com/news/2017-02-03/rig-count-surges-again-16-month-highs-wheres-oil-industry-jobs\nEvans, D. K., & Popova, A. (2014). Cash transfers and remptation goods: a review of global evidence (English). Washington DC: World Bank. Retrieved from http://documents.worldbank.org/curated/en/617631468001808739/Cash-transfers-and-temptation-goods-a-review-of-global-evidence\nfarmbot. (2018, January 7). Home farmbot. Retrieved from Farmbot website: https://farm.bot/\nFrey, C. B., & Osborne, M. A. (2013). THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION? Oxford: Oxford University.\nFuture of Life Institute. (2015, July 28). Autonomous Weapons: an Open Letter from AI & Robotics Researchers. Retrieved from Future of Life Institute: https://futureoflife.org/open-letter-autonomous-weapons/\nGates, B. (2017, Febuary 17). Why Bill Gates would tax robots. (Quartz, Interviewer)\nGeron, T. (2012, September 6). Facebook Officially Closes Instagram Deal. Retrieved from Forbes: https://www.forbes.com/sites/tomiogeron/2012/09/06/facebook-officially-closes-instagram-deal/#6bed65c61d45\nGraeber, D. (2013, August 1). On the Phenomenon of Bullshit Jobs: A Work Rant. Retrieved from STRIKE! Magazine: https://strikemag.org/bullshit-jobs\nGross, B. (2016). Culture Clash. Investment Outlook, 2. Retrieved from https://17eb94422c7de298ec1b-8601c126654e9663374c173ae837a562.ssl.cf1.rackcdn.com/Documents/umbrella%2Fbill%20gross%2FBill%20Gross%20Investment%20Outlook_May%202016.pdf\nHM Treasury. (2017). Autumn Budget 2017. London: HM Treasury.\nHum, D., & Simpson, W. (1993). Economic Response to a Guaranteed Annual Income: Experience from Canada and the United States. Journal of Labor Economics, 11.\nIsaac, A., & Wallace, T. (2017, September 27). Return of the Luddites: why a robot tax could never work. Retrieved from The Telegraph: www.telegraph.co.uk/business/2017/09/27/return-luddites-robot-tax-could-never-work/\nJochmann, J. (2012, November 18). Liquid Democracy In Simple Terms. Youtube. Retrieved January 7, 2018, from https://www.youtube.com/watch?v=fg0_Vhldz-8\nKatz, L., & Verhage, J. (2017, November 27). Bloomberg Technology. Retrieved from Novogratz Says Crypto Will Be \u2018Biggest Bubble of Our Lifetimes\u2019: https://www.bloomberg.com/news/articles/2017-11-28/novogratz-says-bitcoin-to-win-out-over-other-digital-currencies\nMcKinsey Global Institute. (2017). A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY. London: McKinsey&Company.\nMusk, E. (2016, November 4). Elon Musk: Robots will take your jobs, government will have to pay your wage. (CNBC, Interviewer)\nPilkington, E. (2015, November 19). The Gaurdian. Retrieved from Life as a drone operator: \u2018Ever step on ants and never give it another thought?\u2019 : https://www.theguardian.com/world/2015/nov/18/life-as-a-drone-pilot-creech-air-force-base-nevada\nRobinson, K. S. (2013). 2312. London: Orbit.\nRobinson, K. S. (2015). The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars. New York City: Harper Voyager.\nRousseau, J. J. (1913). Social Contract & Discourses, Translated with Introduction by G. D. H. Cole. New York: Dutton&Co. Retrieved January 7, 2018, from http://www.bartleby.com/br/168.html\nThe Economist. (2014, Jannuary 18). The onrushing wave. Retrieved from The Economist: https://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\nVaroufakis, Y. (2017, Febuary 27). A Tax on Robots? Retrieved from Project Syndicate: https://www.project-syndicate.org/commentary/bill-gates-tax-on-robots-by-yanis-varoufakis-2017-02?barrier=accessreg\nYougov. (2015, August 12). Yougov|News|37% of British workers think their jobs are meaningless. Retrieved from Yougov: https://yougov.co.uk/news/2015/08/12/british-jobs-meaningless/\n\u000eX\n"
  },
  {
    "title": "EPQ draft 1 (4844 words)",
    "content": "EPQ draft 1 (4844 words)\nhttps://upload.wikimedia.org/wikipedia/commons/1/1f/Sanko_Seisakusyo_%28%E4%B8%89%E5%B9%B8%E8%A3%BD%E4%BD%9C%E6%89%80%29_%E2%80%93_Tin_Wind_Up_%E2%80%93_Tiny_Smoking_Spaceman_Robots_%E2%80%93_Close_Up.jpg\nIntroduction\nAutomation is set to un-employ people at a scale and rate never seen before, while simultaneously changing societies very nature on an epic scale; to mitigate its impact we must undertake projects and policies that push ourselves, humanity, and society to its limits. The future could take one of two shapes; a utopian wonderland where everyone is happy, or a dystopia where algorithms and machines run the world for maximum efficiency leaving humanity in the slums. However, despite the impending danger, we are seemingly unaware of it. This is because automation creeps in slowly, so we don\u2019t notice it, only once the teamsters, lawyers, and the CEO\u2019s start to lose their jobs will we notice the extent of what we have created. This is nature of automation you don\u2019t notice until it\u2019s your job, your income, your life that is affected.\nHowever, we might hope that our governments have foreseen this danger and are planning how to avoid it. Yet we do not see any real indication from the government (as of time of writing) that they need to do anything to prepare for the unemployed masses. On the contrary in the 2017 autumn budget the government announced that they wanted to see fully driverless cars by 2021 (HM Treasury, 2017). This is even though a CGPS study showed that over 4 million jobs will be lost to driverless cars in the US (Center for Global Policy Solutions., 2017). IN this report I aim to investigate three main key factors that need to be addressed by both policy makers and the public, to prepare ourselves for the future. These are; Too what extent will automation occur, how will this automation effect society and how should we mitigate its impact? By answering these three questions I hope to bring further clarity to a pressing issue that will affect society from top to bottom.\nToo what extent will automation happen\nThe first question that must be answered in this topic is how much automation will occur. There have been many studies that have attempted to estimate this, and their findings have varied considerably. The most recent study is one by PWC (Berriman & Hawksworth, 2017). By analyzing the other studies and improving upon their methods, they conducted a new survey which concluded that.\n\u201cOur analysis suggests that up to 30% of UK jobs could potentially be at high risk of automation by the early 2030s, lower than the US (38%) or Germany (35%), but higher than Japan (21%).\u201d (Berriman & Hawksworth, 2017) I have converted this data into a graph below along with other recent studies.\n\nAs we can see from the graph the results of automation studies vary greatly. The original study by FO classified jobs as automatable or not by looking at whether most of its tasks could be automated, this meant that they could develop an algorithm to predict what jobs could and could not be automated. AGZ on the other hand, claimed a job was only automatable if all its tasks where fully automatable. This however leads to a vastly reduced number of jobs being classed as automatable. If a job has ten parts and five can be automated surely you can still fire half the workers and maintain the same output. This meant that the results of the AGZ study underestimate the likely impact of automation. For this reason, I have chosen to use the most recent study (PwC) to base my study off.\nWill new jobs be created?\nIf we can have expected jobs to be lost surely, we should also expect new ones to be created to take their place? However, despite this logic the data suggests otherwise see the graph below (Durden, 2017).\n\nAs we can see quite clearly although rig count and therefore oil production has increased, the number of employers has stayed almost the same. This indicates that we are producing more oil with less and less energy required. What\u2019s more interesting if you look at the percentage of eligible workers employed over time (Gross, 2016).\n\nAs you can see from the graph, the percentage of people employed increases until a recession; at this point employment drops as business make cuts and increase automation, employment regains and then falls. Overtime this cycle reduces peak employment. Furthermore, we can see that the greater the recession the more jobs are irretrievably lost. Currently many believe that we could be in one of the biggest bubbles of all time. The crypto bubble. This term refers to the presumed bubble of cryptocurrencies such as bitcoin and Ethereum. The graph below shows the price of bitcoin over the last year alone (Coindesk, 2017).\n\nIt is widely assumed and even accepted that the crypto bubble will be the biggest of our lifetimes and that at some point it will almost certainly burst crashing everyone else with it. This conclusion is mainly drawn from its similarities to the dotcom bubble which burst in 2000\u20132002. In comparison to the crypto bubble the dot com bubble is expected to look almost reasonable. However, many technology enthusiasts point out that this is okay seeming as we do now all use the internet (Katz & Verhage, 2017). Either way if this is a bubble then we should expect to see job losses in the extremes, jobs that we should not expect to return.\nFinally, we must consider whether the new sectors will produce new jobs. Technologists often argue that despite jobs being automated its fine because new jobs such as software developers are being created. And yes, this is true. Whilst it would be unthinkable for the jobs \u2018Computer Software Engineer\u2019 or \u2018Computer Programmer\u2019 to have existed back in 1980 and now there is 1,300,000 of them. Does not deny the fact that one team of software engineers eleven can design, build, and deploy the next \u2018killer app\u2019 within two years and walk away with one billion dollars from its sale. This is the story of Instagram (BBC News technology, 2012). This is a classic case; one we can expect to see much more of. It demonstrates that you no longer need tons of workers to make tons of money. So yes while a few new jobs will be created, we should not rely on these new jobs to support people.\nIn conclusion we can expect to see lots of job losses within the next 30 years. This is due to the combined effect of automation enabling more jobs to be automated and an impending recession that will drive business to make cuts and improve their business efficiency, with an increasingly small number of people required to make a business successful. We can expect to see unemployment rise to 30% by 2030 and possibly even as high as 50% by 2050.\nWhy do we work?\nThroughout all of time humanity has been in a constant struggle to survive. From stone age man hunting the mighty mammoth, to office workers hunting the mighty pay rise. Humans have always had to strive to survive. Never have we been given the opportunity to simply have it provided to us, although yes, we do get our sustenance easier now than ever before we still must work to get it. But what if we didn\u2019t?\nThere are three main points of view on the meaning of work. Some people believe that we work because it gives us meaning, that without it we would be aimless with no purpose. The other group say that we work simply for the money and that if that wasn\u2019t an issue we could quite happily live our lives doing what we really wanted to do.\n\nSome people argue that we work to give meaning to our lives. If we did not work, we would all very quickly turn to violence and crime. To find out more about this I conducted a survey of 249 random subjects.\n\nFrom this we can see that people are clearly divided on the topic. But I was asking about work in general. If, however you ask someone whether their job has meaning you get a very different response. This is demonstrated by a 2015 YouGov poll. The poll showed that 37% of people do not believe that their job is contributing to the world (Yougov, 2015). This is a shocking statistic and makes us wonder quite what jobs these people are doing that they their jobs as pointless.\n\nBy analysing the data in the survey, we can conclude that working class people are more likely to believe that their job is not having a meaningful contribution to the world than middle class people. We can also see that some areas have significantly lower levels of meaningfulness than others such as London. Despite the elevated levels of meaninglessness in London less people said that they would be \u201cnot proud to tell a stranger what their job was\u201d, unlike in Scotland where there are elevated levels of meaningfulness and elevated levels of shame.\n\nSo, we can conclude that people in lower economic brackets are more likely to see themselves in pointless jobs. We can also see that people in areas of high population concentration such as London and the north are more likely to be not fulfilled by their job.\nIn August 2013 David Graeber wrote an influential article for STRIKE! Magazine (Graeber, 2013).In this article he argued that many modern jobs are \u2018bullshit jobs\u2019. They point out that in 1930 John Maynard Keynes (arguably the capitalist equivalent to Karl Marx), predicted that by the centuries end that developed countries such as Great Britain would be so technologically advanced that people who lived there would on average work only 15 hours a week. And yes, as predicted most of manufacturing jobs have been automated yet despite this we have not achieved the 15-hour week. Graeber argues that this is due to the creation of \u2018bullshit jobs\u2019. There has been a massive explosion in the services/administration sector. In fact, between 1948 and 2011 the services sector in the US has\nFigure 3: https ://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\ngone from 45% of total employment to 68% of total employment (not including government jobs) (The Economist, 2014)\nThe new services sector comprises many jobs such as:\n\u00b7 Financial services\n\u00b7 Telemarketing\n\u00b7 Corporate law\n\u00b7 Academic/health administration\n\u00b7 Human resources\n\u00b7 Public relations\nThese are what Graeber proposes are \u2018bullshit jobs\u2019. A bullshit hob is one that provides little or no meaning to society and the world. And yet even though the people doing these jobs find them pointless they continue to do them. And what\u2019s more they continue to be created.\nFigure 4: https://www.vice.com/en_uk/article/yvq9qg/david-graeber-pointless-jobs-tube-poster-interview-912\nIf bullshit jobs are pointless why are they created? Many would argue that society creates jobs to ensure that they can continue to partake in society. Some would argue that because of this if people did not have to work to have a good enough income to live on then they would not work. They argue that instead they would spend their time doing things they enjoy and getting the education required to do interesting jobs such as medicine or teaching. This is backed up by universal basic income studies. A universal basic income is a guaranteed income that is paid to all eligible members of society. This is often done by a negative income tax; this is where after earning below a certain point the state stats to give you a guaranteed income. Most importantly however this payment has no strings attached. This means that if people want to then they can and can do no work and just live of benefits. However, the statistics from the studies do not show that this happens. In 1974 a basic income study was carried out in Manitoba (Canada); it showed that people barely reduced their working hours, and those that did used it to spend more time with their families and or taking additional classes reaping untold benefits for the economy (Hum & Simpson, 1993).\nMany argue that even if automation does occur then people could continue to do jobs that give them meaning if they wish. Just because a job could be done by a robot does not necessarily mean it will be. If people find meaning in work, then they can continue to do so. However, if your job is mind bogglingly boring then why should you have to do it if you don\u2019t want to? As we enter the new automated age then we are going to have to realize that we should have fun in life and if that means not working then so be it. But the clear majority will find something to do be it inventing, painting, or pushing the boundaries we must accept that our society will change to accommodate our new-found freedom.\nHow can we mitigate its impact?\nWorking on the dual assumptions that; soon robotic automation will increase so that 30% of jobs become automated (with not enough being created to replace them), and that in our current state if we get rid of work then there would be large increases in crime and violence. We can conclude that preemptive measures need to take preemptive measures to mitigate the impact. I have split these preemptive measures into two main types.\n\nOnly by combining a variety of government policies and regulation with a collective societal move towards less work based system we can ensure that minimal damage is done. This is the main subject of this report. I will first discuss potential government policies and then the action that society must implement to make the most of automation.\nGovernment policies and responsibillities\nGovernment policies come in the form of taxes, benefits, regulation, or programs. A tax is designed to incite a behavior using negative reinforcement i.e. persuade someone or a company to do something otherwise they will lose more money. Benefits give money to people (typically working-class people), this provides them with an income to survive even if they lose their jobs. Regulation prevents the development \u2018bad robots\u2019 such as terminators. Programs run by governments help to retrain people to get them new jobs by giving them new skills such as programming.\nTax\nThe tax I am investigate is a robot tax. A robot tax is a system where cooperation\u2019s are taxed depending on how much of their workforce is automated. For instance, if you were a company that \u2018employed\u2019 a robot corporate lawyer you would pay robot tax equivalent to the income tax a corporate lawyer would have paid. This money could be used to fund other government initiatives such as new benefits and retraining programs (Varoufakis, 2017). Proponents for the tax are wide ranging and include tech giants such as Bill Gates (Gates, 2017) and futurists such as Elon Musk (Musk, 2016). However, some people such as Estonian politician Andrus Ansip believe that this is a bad idea (Ansip, 2017). It is argued that it would be difficult if not impossible to calculate the equivalent wage that the robot would have earned if a human where doing the same job. Furthermore, it is argued that this would reduce innovation as it would stop companies automating jobs, this is bad as some jobs a very dangerous and it is ethical to automate them even if it means someone loses their job (Isaac & Wallace, 2017).\nBenifits\nA common suggestion to mitigate the impact of robotics is the implementation of a new benefit called a Universal Basic Income (UBI), it is also known as basic income (BI), citizens income (CI) and negative income tax (NIT). But whatever its name (I shall use UBI) it involves giving all citizens a basic income (except in NIT where it is only the poorest) (Basic Income Earth Network, 2017). It has been studied in many studies in a range of situations for a variety of clients. It is argued that doing so would be cheaper than our current welfare system, this is because there would be very low administration costs. Furthermore, it is argued (and proven in studies) that a basic income gives better outcome than independent benefits (Hum & Simpson, 1993). It is also shown to increase personal development and entrepreneurship as people have a safety floor to stand on to achieve their aims be it setting up a company or training to get into a new profession. This is how UBI solves the issue of automation, it encourages personal retraining and entrepreneurship which in turn provides new jobs and bolsters the economy. Opponents argue that a UBI would encourage crime and antisocial behavior such as drug abuse. However, a report by the world bank that summarized the findings of 30 studies disproved this (Evans & Popova, 2014).\nRegulation\nOne big worry about robots is that they will rise and take over the world. Whilst this may at first seem like an unrealistic and reactionary response to automation. However, these fears are well founded. In 2015 a robot was released by Queensland university of technology that will patrol coral reefs, and autonomously make the decision to kill the deadly crown of thorns starfish that destroys reefs (Dayoub, Dunbabin, & Corke, 2015). Although this application is undeniably good as we need to protect corals; it sets a dangerous precedent. The same technology can easily be expanded into military drones. Drones have long been used by the military, however this has led to sometimes disastrous consequences. The pilots feel detached and say it is like stepping on an ant (Pilkington, 2015). Imagine how much that feeling of detachment will become when instead of pulling a trigger you just must sign a piece of paper to authorize the strike. Despite this and warnings from high profile critics such as Stephen Hawking, Elon Musk, and Steve Wozniak (Future of Life Institute, 2015). As such it is undeniable that we should enact legislation to prevent the development of AI that decides when to kill human to ensure that we do not lose control.\nprogrames\nOne proposed solution is retraining. This is where people who have been or will be made redundant due to automation are retrained to do new jobs. This retraining is funded by the government or previous employer and is usually in the form of a course or other qualification (Carson, 2015). These types of programs are useful and are a common way to mitigate impact when unemployment occurs on a mass scale. However, the type of unemployment that we will see might not end up being concentrated as it is normally. If all the manufacturing companies fired half their workers, yes there would be a lot of unemployment, but it would be widely dispersed; it is also harder to retrain people when they are dispersed as you cannot just set up one program. Therefore, these new courses will mostly have to be done online. But this again throws up another problem. The jobs that will be created/will not be automated are not manufacturing or laboring jobs, rather ones that require intelligence, independent/creative thinking, and human understanding (see next page) (McKinsey Global Institute, 2017). We can see that the jobs that will be automated the least are all degree level, education, management (less so with this one) and professionals. From this we can conclude that instead of providing standard retraining we need to other degree level retraining. To do this though the new students will have to pay tuition fees which are prohibitively high to some students let alone parents trying to support their own children going through uni who cannot access grants. In short if we want to mass retrain people at a degree level we need to get rid of tuition fees.\n\nSocietal action\nCurrently our society is geared to attain 100% employment. This full employment model creates pointless jobs just for the sake of keeping people working (Graeber, 2013). However, if 30% of people become unemployed this model will quickly fall apart. So undoubtedly retraining programs will appear and retraining some of the unemployed. But a large portion won\u2019t want to be. If you are a lawyer, you\u2019re not going to want to retrain into a teacher or a therapist because they\u2019re completely different fields that wouldn\u2019t interest you. And even if a UBI is implemented then we can\u2019t all be entrepreneurs. This is mostly because it costs a lot less to run a successful company in the modern day. For instance, Instagram was bought for $1 billion, at that time it only had 13 employees (Geron, 2012). As this clearly shows you now need a lot less people to have an even bigger impact than ever before. So, we need to find something to occupy ourselves with.\nInterplanatary colonisation\nOne suggestion is that we apply our newfound technological capabilities to undertaking a great task such as exploring space. This has several benefits.\n1. It would retrain people\na. This is because starting a colony will take many new skills from all backgrounds. We could gear the retraining programs to train people to build rockets\n2. It would produce employment\na. Yes, it might be much cheaper to build rockets by robot but why do that when you could employ people? On earth we could use the robots to do the mundane tasks that just have to be done such as; mass farming to feed everyone, building homes, treating illnesses.\n3. Life would be less likely to be wiped out\na. We might just be the only life in the entire universe. Maybe even all of time. So it would be a real shame if we were wiped out by a single asteroid or a territorial spat or a massive plague. But if we have a self-sufficient colony on another world the chances of ALL of humanity drop to practically zero.\nDespite these benefits there are some serous disadvantages. For instance we might accidently create a dystopia such as in Kim Stanley Robinsons Mars trilogy and 2312 (Robinson, The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars, 2015) (Robinson, 2312, 2013), if we want to avoid this we should ensure that the selection criteria for colonization is not financial but based on ability.\nElimination of the great killers\nThroughout human history life has been short and nasty. If you were lucky enough to be born and your mother to have survived the ordeal you lived through roughly 40 grueling years of work to end up dead. By comparison even the poorest person in the first world would not suffer that much. However, many people in LIC\u2019s (less industrialized countries) still live in this Malthusian misery trap. However, we now have the technological abilities to free them. We could use robots to mass farm to feed cheaply people (farmbot, 2018), we could use modified 3d printers with concrete to 3d print houses in areas with high homelessness (apis-cor, 2018), and we can release genetically engineered mosquitoes to crash the population of a certain type of mosquito (Carvalho DO, 2015). All these techniques use the latest in technology and robotics to solve the great problems of the world. However, to deploy we will need to work together with a large human fleet to support it.\nA new social order\nAutomation itself will undoubtedly cause a great in politics. This is because as previously established society will have to change and so will our priorities. And seeming as political order and systems, I descended from those governed as per defined by social contract theory (Rousseau, 1913). However, as our society changes rapidly our systems will quickly unfold and become unsuitable for the modern world. This will inevitably lead to the creation of new types of government such as Futarchy (Buterin, 2014) and liquid democracy (Jochmann, 2012). However, if not properly handled the opportunity maybe seized by the \u2018new radicals\u2019 such as Donald Trump and Heinz-Christian Strache (Carswell, 2017). However, if we can seize the opportunity then we have a chance like no other to make a real lasting impact on the world.\nConclusion\nRobotic automation will have a wide-ranging effect on society. The predicted levels of unemployment can only be described as catastrophic by today\u2019s standards. To cope with this change, we must find meaning in our lives and our existence. To cope we will take on new and exciting challenges such as founding a Martian colony and becoming more than human. Sadly, though the governments that have the power to enact the decisions required to help humanity cope with the turbulence of change, seem blissfully ignorant of the dire need for discussion and debate on this most important debate.\nBibliography\nAnsip, A. (2017, June 2). EU Commissioner Says No to Bill Gates\u2019 Robot Tax Idea. (CNBC, Interviewer)\napis-cor. (2018, January 7). Home apis-cor. Retrieved from apis-cor: http://apis-cor.com/en\nArntz, M., Gregory, T., & Ulrich, Z. (2016). The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis. OECD Social, Employment and Migration Working. Paris: OECD Publishing. doi:http://dx.doi.org/10.1787/5jlz9h56dvq7-en\nBasic Income Earth Network. (2017, December 28). BIEN: Basic Income Earth Network. Retrieved from About basic income: http://basicincome.org/basic-income/\nBBC News technology. (2012, April 10). BBC. Retrieved from BBC|News|Technology|Facebook buys Instagram photo sharing network for $1bn: http://www.bbc.co.uk/news/technology-17658264\nBerriman, R., & Hawksworth, J. (2017). Will robots steal our jobs? The potential impact of automation on the UK and other major economies. London: Price-waterhouse-Coopers LLP.\nButerin, V. (2014, August 21). An Introduction to Futarchy. Retrieved from Ethereum blog: https://blog.ethereum.org/2014/08/21/introduction-futarchy/\nCarson, E. (2015, August 3). How workers can retrain for careers in an automated world. Retrieved from ZDnet: http://www.zdnet.com/article/how-workers-can-retrain-for-careers-in-an-automated-world/\nCarvalho DO, M. A. (2015). Suppression of a Field Population of Aedes aegypti in Brazil by Sustained Release of Transgenic Male Mosquitoes. PLoS Negl Trop Dis, 1. Retrieved from https://doi.org/10.1371/journal.pntd.0003864\nCenter for Global Policy Solutions. (2017). Stick Shift: Autonomous Vehicles, Driving Jobs, and the Future of Work. Washington, DC: Center for Global Policy Solutions.\nCoindesk. (2017, November 30). Price page, 2017\u20132018. Retrieved from Coindesk: https://www.coindesk.com/price/\nDayoub, F., Dunbabin, M., & Corke, P. (2015). Robotic Detection and Tracking of Crown-of-Thorns Starfish. Queensland: Queensland University of Technology.\nDurden, T. (2017, Febuary 3). Rig Count Surges Again To 16-Month Highs (But Where\u2019s The Oil Industry Jobs). Retrieved from ZeroHedge: http://www.zerohedge.com/news/2017-02-03/rig-count-surges-again-16-month-highs-wheres-oil-industry-jobs\nEvans, D. K., & Popova, A. (2014). Cash transfers and remptation goods: a review of global evidence (English). Washington DC: World Bank. Retrieved from http://documents.worldbank.org/curated/en/617631468001808739/Cash-transfers-and-temptation-goods-a-review-of-global-evidence\nfarmbot. (2018, January 7). Home farmbot. Retrieved from Farmbot website: https://farm.bot/\nFrey, C. B., & Osborne, M. A. (2013). THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION? Oxford: Oxford University.\nFuture of Life Institute. (2015, July 28). Autonomous Weapons: an Open Letter from AI & Robotics Researchers. Retrieved from Future of Life Institute: https://futureoflife.org/open-letter-autonomous-weapons/\nGates, B. (2017, Febuary 17). Why Bill Gates would tax robots. (Quartz, Interviewer)\nGeron, T. (2012, September 6). Facebook Officially Closes Instagram Deal. Retrieved from Forbes: https://www.forbes.com/sites/tomiogeron/2012/09/06/facebook-officially-closes-instagram-deal/#6bed65c61d45\nGraeber, D. (2013, August 1). On the Phenomenon of Bullshit Jobs: A Work Rant. Retrieved from STRIKE! Magazine: https://strikemag.org/bullshit-jobs\nGross, B. (2016). Culture Clash. Investment Outlook, 2. Retrieved from https://17eb94422c7de298ec1b-8601c126654e9663374c173ae837a562.ssl.cf1.rackcdn.com/Documents/umbrella%2Fbill%20gross%2FBill%20Gross%20Investment%20Outlook_May%202016.pdf\nHM Treasury. (2017). Autumn Budget 2017. London: HM Treasury.\nHum, D., & Simpson, W. (1993). Economic Response to a Guaranteed Annual Income: Experience from Canada and the United States. Journal of Labor Economics, 11.\nIsaac, A., & Wallace, T. (2017, September 27). Return of the Luddites: why a robot tax could never work. Retrieved from The Telegraph: www.telegraph.co.uk/business/2017/09/27/return-luddites-robot-tax-could-never-work/\nJochmann, J. (2012, November 18). Liquid Democracy In Simple Terms. Youtube. Retrieved January 7, 2018, from https://www.youtube.com/watch?v=fg0_Vhldz-8\nKatz, L., & Verhage, J. (2017, November 27). Bloomberg Technology. Retrieved from Novogratz Says Crypto Will Be \u2018Biggest Bubble of Our Lifetimes\u2019: https://www.bloomberg.com/news/articles/2017-11-28/novogratz-says-bitcoin-to-win-out-over-other-digital-currencies\nMcKinsey Global Institute. (2017). A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY. London: McKinsey&Company.\nMusk, E. (2016, November 4). Elon Musk: Robots will take your jobs, government will have to pay your wage. (CNBC, Interviewer)\nPilkington, E. (2015, November 19). The Gaurdian. Retrieved from Life as a drone operator: \u2018Ever step on ants and never give it another thought?\u2019 : https://www.theguardian.com/world/2015/nov/18/life-as-a-drone-pilot-creech-air-force-base-nevada\nRobinson, K. S. (2013). 2312. London: Orbit.\nRobinson, K. S. (2015). The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars. New York City: Harper Voyager.\nRousseau, J. J. (1913). Social Contract & Discourses, Translated with Introduction by G. D. H. Cole. New York: Dutton&Co. Retrieved January 7, 2018, from http://www.bartleby.com/br/168.html\nThe Economist. (2014, Jannuary 18). The onrushing wave. Retrieved from The Economist: https://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\nVaroufakis, Y. (2017, Febuary 27). A Tax on Robots? Retrieved from Project Syndicate: https://www.project-syndicate.org/commentary/bill-gates-tax-on-robots-by-yanis-varoufakis-2017-02?barrier=accessreg\nYougov. (2015, August 12). Yougov|News|37% of British workers think their jobs are meaningless. Retrieved from Yougov: https://yougov.co.uk/news/2015/08/12/british-jobs-meaningless/\n\u000eX\n"
  },
  {
    "title": "EPQ draft 1 (4844 words)",
    "content": "EPQ draft 1 (4844 words)\nhttps://upload.wikimedia.org/wikipedia/commons/1/1f/Sanko_Seisakusyo_%28%E4%B8%89%E5%B9%B8%E8%A3%BD%E4%BD%9C%E6%89%80%29_%E2%80%93_Tin_Wind_Up_%E2%80%93_Tiny_Smoking_Spaceman_Robots_%E2%80%93_Close_Up.jpg\nIntroduction\nAutomation is set to un-employ people at a scale and rate never seen before, while simultaneously changing societies very nature on an epic scale; to mitigate its impact we must undertake projects and policies that push ourselves, humanity, and society to its limits. The future could take one of two shapes; a utopian wonderland where everyone is happy, or a dystopia where algorithms and machines run the world for maximum efficiency leaving humanity in the slums. However, despite the impending danger, we are seemingly unaware of it. This is because automation creeps in slowly, so we don\u2019t notice it, only once the teamsters, lawyers, and the CEO\u2019s start to lose their jobs will we notice the extent of what we have created. This is nature of automation you don\u2019t notice until it\u2019s your job, your income, your life that is affected.\nHowever, we might hope that our governments have foreseen this danger and are planning how to avoid it. Yet we do not see any real indication from the government (as of time of writing) that they need to do anything to prepare for the unemployed masses. On the contrary in the 2017 autumn budget the government announced that they wanted to see fully driverless cars by 2021 (HM Treasury, 2017). This is even though a CGPS study showed that over 4 million jobs will be lost to driverless cars in the US (Center for Global Policy Solutions., 2017). IN this report I aim to investigate three main key factors that need to be addressed by both policy makers and the public, to prepare ourselves for the future. These are; Too what extent will automation occur, how will this automation effect society and how should we mitigate its impact? By answering these three questions I hope to bring further clarity to a pressing issue that will affect society from top to bottom.\nToo what extent will automation happen\nThe first question that must be answered in this topic is how much automation will occur. There have been many studies that have attempted to estimate this, and their findings have varied considerably. The most recent study is one by PWC (Berriman & Hawksworth, 2017). By analyzing the other studies and improving upon their methods, they conducted a new survey which concluded that.\n\u201cOur analysis suggests that up to 30% of UK jobs could potentially be at high risk of automation by the early 2030s, lower than the US (38%) or Germany (35%), but higher than Japan (21%).\u201d (Berriman & Hawksworth, 2017) I have converted this data into a graph below along with other recent studies.\n\nAs we can see from the graph the results of automation studies vary greatly. The original study by FO classified jobs as automatable or not by looking at whether most of its tasks could be automated, this meant that they could develop an algorithm to predict what jobs could and could not be automated. AGZ on the other hand, claimed a job was only automatable if all its tasks where fully automatable. This however leads to a vastly reduced number of jobs being classed as automatable. If a job has ten parts and five can be automated surely you can still fire half the workers and maintain the same output. This meant that the results of the AGZ study underestimate the likely impact of automation. For this reason, I have chosen to use the most recent study (PwC) to base my study off.\nWill new jobs be created?\nIf we can have expected jobs to be lost surely, we should also expect new ones to be created to take their place? However, despite this logic the data suggests otherwise see the graph below (Durden, 2017).\n\nAs we can see quite clearly although rig count and therefore oil production has increased, the number of employers has stayed almost the same. This indicates that we are producing more oil with less and less energy required. What\u2019s more interesting if you look at the percentage of eligible workers employed over time (Gross, 2016).\n\nAs you can see from the graph, the percentage of people employed increases until a recession; at this point employment drops as business make cuts and increase automation, employment regains and then falls. Overtime this cycle reduces peak employment. Furthermore, we can see that the greater the recession the more jobs are irretrievably lost. Currently many believe that we could be in one of the biggest bubbles of all time. The crypto bubble. This term refers to the presumed bubble of cryptocurrencies such as bitcoin and Ethereum. The graph below shows the price of bitcoin over the last year alone (Coindesk, 2017).\n\nIt is widely assumed and even accepted that the crypto bubble will be the biggest of our lifetimes and that at some point it will almost certainly burst crashing everyone else with it. This conclusion is mainly drawn from its similarities to the dotcom bubble which burst in 2000\u20132002. In comparison to the crypto bubble the dot com bubble is expected to look almost reasonable. However, many technology enthusiasts point out that this is okay seeming as we do now all use the internet (Katz & Verhage, 2017). Either way if this is a bubble then we should expect to see job losses in the extremes, jobs that we should not expect to return.\nFinally, we must consider whether the new sectors will produce new jobs. Technologists often argue that despite jobs being automated its fine because new jobs such as software developers are being created. And yes, this is true. Whilst it would be unthinkable for the jobs \u2018Computer Software Engineer\u2019 or \u2018Computer Programmer\u2019 to have existed back in 1980 and now there is 1,300,000 of them. Does not deny the fact that one team of software engineers eleven can design, build, and deploy the next \u2018killer app\u2019 within two years and walk away with one billion dollars from its sale. This is the story of Instagram (BBC News technology, 2012). This is a classic case; one we can expect to see much more of. It demonstrates that you no longer need tons of workers to make tons of money. So yes while a few new jobs will be created, we should not rely on these new jobs to support people.\nIn conclusion we can expect to see lots of job losses within the next 30 years. This is due to the combined effect of automation enabling more jobs to be automated and an impending recession that will drive business to make cuts and improve their business efficiency, with an increasingly small number of people required to make a business successful. We can expect to see unemployment rise to 30% by 2030 and possibly even as high as 50% by 2050.\nWhy do we work?\nThroughout all of time humanity has been in a constant struggle to survive. From stone age man hunting the mighty mammoth, to office workers hunting the mighty pay rise. Humans have always had to strive to survive. Never have we been given the opportunity to simply have it provided to us, although yes, we do get our sustenance easier now than ever before we still must work to get it. But what if we didn\u2019t?\nThere are three main points of view on the meaning of work. Some people believe that we work because it gives us meaning, that without it we would be aimless with no purpose. The other group say that we work simply for the money and that if that wasn\u2019t an issue we could quite happily live our lives doing what we really wanted to do.\n\nSome people argue that we work to give meaning to our lives. If we did not work, we would all very quickly turn to violence and crime. To find out more about this I conducted a survey of 249 random subjects.\n\nFrom this we can see that people are clearly divided on the topic. But I was asking about work in general. If, however you ask someone whether their job has meaning you get a very different response. This is demonstrated by a 2015 YouGov poll. The poll showed that 37% of people do not believe that their job is contributing to the world (Yougov, 2015). This is a shocking statistic and makes us wonder quite what jobs these people are doing that they their jobs as pointless.\n\nBy analysing the data in the survey, we can conclude that working class people are more likely to believe that their job is not having a meaningful contribution to the world than middle class people. We can also see that some areas have significantly lower levels of meaningfulness than others such as London. Despite the elevated levels of meaninglessness in London less people said that they would be \u201cnot proud to tell a stranger what their job was\u201d, unlike in Scotland where there are elevated levels of meaningfulness and elevated levels of shame.\n\nSo, we can conclude that people in lower economic brackets are more likely to see themselves in pointless jobs. We can also see that people in areas of high population concentration such as London and the north are more likely to be not fulfilled by their job.\nIn August 2013 David Graeber wrote an influential article for STRIKE! Magazine (Graeber, 2013).In this article he argued that many modern jobs are \u2018bullshit jobs\u2019. They point out that in 1930 John Maynard Keynes (arguably the capitalist equivalent to Karl Marx), predicted that by the centuries end that developed countries such as Great Britain would be so technologically advanced that people who lived there would on average work only 15 hours a week. And yes, as predicted most of manufacturing jobs have been automated yet despite this we have not achieved the 15-hour week. Graeber argues that this is due to the creation of \u2018bullshit jobs\u2019. There has been a massive explosion in the services/administration sector. In fact, between 1948 and 2011 the services sector in the US has\nFigure 3: https ://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\ngone from 45% of total employment to 68% of total employment (not including government jobs) (The Economist, 2014)\nThe new services sector comprises many jobs such as:\n\u00b7 Financial services\n\u00b7 Telemarketing\n\u00b7 Corporate law\n\u00b7 Academic/health administration\n\u00b7 Human resources\n\u00b7 Public relations\nThese are what Graeber proposes are \u2018bullshit jobs\u2019. A bullshit hob is one that provides little or no meaning to society and the world. And yet even though the people doing these jobs find them pointless they continue to do them. And what\u2019s more they continue to be created.\nFigure 4: https://www.vice.com/en_uk/article/yvq9qg/david-graeber-pointless-jobs-tube-poster-interview-912\nIf bullshit jobs are pointless why are they created? Many would argue that society creates jobs to ensure that they can continue to partake in society. Some would argue that because of this if people did not have to work to have a good enough income to live on then they would not work. They argue that instead they would spend their time doing things they enjoy and getting the education required to do interesting jobs such as medicine or teaching. This is backed up by universal basic income studies. A universal basic income is a guaranteed income that is paid to all eligible members of society. This is often done by a negative income tax; this is where after earning below a certain point the state stats to give you a guaranteed income. Most importantly however this payment has no strings attached. This means that if people want to then they can and can do no work and just live of benefits. However, the statistics from the studies do not show that this happens. In 1974 a basic income study was carried out in Manitoba (Canada); it showed that people barely reduced their working hours, and those that did used it to spend more time with their families and or taking additional classes reaping untold benefits for the economy (Hum & Simpson, 1993).\nMany argue that even if automation does occur then people could continue to do jobs that give them meaning if they wish. Just because a job could be done by a robot does not necessarily mean it will be. If people find meaning in work, then they can continue to do so. However, if your job is mind bogglingly boring then why should you have to do it if you don\u2019t want to? As we enter the new automated age then we are going to have to realize that we should have fun in life and if that means not working then so be it. But the clear majority will find something to do be it inventing, painting, or pushing the boundaries we must accept that our society will change to accommodate our new-found freedom.\nHow can we mitigate its impact?\nWorking on the dual assumptions that; soon robotic automation will increase so that 30% of jobs become automated (with not enough being created to replace them), and that in our current state if we get rid of work then there would be large increases in crime and violence. We can conclude that preemptive measures need to take preemptive measures to mitigate the impact. I have split these preemptive measures into two main types.\n\nOnly by combining a variety of government policies and regulation with a collective societal move towards less work based system we can ensure that minimal damage is done. This is the main subject of this report. I will first discuss potential government policies and then the action that society must implement to make the most of automation.\nGovernment policies and responsibillities\nGovernment policies come in the form of taxes, benefits, regulation, or programs. A tax is designed to incite a behavior using negative reinforcement i.e. persuade someone or a company to do something otherwise they will lose more money. Benefits give money to people (typically working-class people), this provides them with an income to survive even if they lose their jobs. Regulation prevents the development \u2018bad robots\u2019 such as terminators. Programs run by governments help to retrain people to get them new jobs by giving them new skills such as programming.\nTax\nThe tax I am investigate is a robot tax. A robot tax is a system where cooperation\u2019s are taxed depending on how much of their workforce is automated. For instance, if you were a company that \u2018employed\u2019 a robot corporate lawyer you would pay robot tax equivalent to the income tax a corporate lawyer would have paid. This money could be used to fund other government initiatives such as new benefits and retraining programs (Varoufakis, 2017). Proponents for the tax are wide ranging and include tech giants such as Bill Gates (Gates, 2017) and futurists such as Elon Musk (Musk, 2016). However, some people such as Estonian politician Andrus Ansip believe that this is a bad idea (Ansip, 2017). It is argued that it would be difficult if not impossible to calculate the equivalent wage that the robot would have earned if a human where doing the same job. Furthermore, it is argued that this would reduce innovation as it would stop companies automating jobs, this is bad as some jobs a very dangerous and it is ethical to automate them even if it means someone loses their job (Isaac & Wallace, 2017).\nBenifits\nA common suggestion to mitigate the impact of robotics is the implementation of a new benefit called a Universal Basic Income (UBI), it is also known as basic income (BI), citizens income (CI) and negative income tax (NIT). But whatever its name (I shall use UBI) it involves giving all citizens a basic income (except in NIT where it is only the poorest) (Basic Income Earth Network, 2017). It has been studied in many studies in a range of situations for a variety of clients. It is argued that doing so would be cheaper than our current welfare system, this is because there would be very low administration costs. Furthermore, it is argued (and proven in studies) that a basic income gives better outcome than independent benefits (Hum & Simpson, 1993). It is also shown to increase personal development and entrepreneurship as people have a safety floor to stand on to achieve their aims be it setting up a company or training to get into a new profession. This is how UBI solves the issue of automation, it encourages personal retraining and entrepreneurship which in turn provides new jobs and bolsters the economy. Opponents argue that a UBI would encourage crime and antisocial behavior such as drug abuse. However, a report by the world bank that summarized the findings of 30 studies disproved this (Evans & Popova, 2014).\nRegulation\nOne big worry about robots is that they will rise and take over the world. Whilst this may at first seem like an unrealistic and reactionary response to automation. However, these fears are well founded. In 2015 a robot was released by Queensland university of technology that will patrol coral reefs, and autonomously make the decision to kill the deadly crown of thorns starfish that destroys reefs (Dayoub, Dunbabin, & Corke, 2015). Although this application is undeniably good as we need to protect corals; it sets a dangerous precedent. The same technology can easily be expanded into military drones. Drones have long been used by the military, however this has led to sometimes disastrous consequences. The pilots feel detached and say it is like stepping on an ant (Pilkington, 2015). Imagine how much that feeling of detachment will become when instead of pulling a trigger you just must sign a piece of paper to authorize the strike. Despite this and warnings from high profile critics such as Stephen Hawking, Elon Musk, and Steve Wozniak (Future of Life Institute, 2015). As such it is undeniable that we should enact legislation to prevent the development of AI that decides when to kill human to ensure that we do not lose control.\nprogrames\nOne proposed solution is retraining. This is where people who have been or will be made redundant due to automation are retrained to do new jobs. This retraining is funded by the government or previous employer and is usually in the form of a course or other qualification (Carson, 2015). These types of programs are useful and are a common way to mitigate impact when unemployment occurs on a mass scale. However, the type of unemployment that we will see might not end up being concentrated as it is normally. If all the manufacturing companies fired half their workers, yes there would be a lot of unemployment, but it would be widely dispersed; it is also harder to retrain people when they are dispersed as you cannot just set up one program. Therefore, these new courses will mostly have to be done online. But this again throws up another problem. The jobs that will be created/will not be automated are not manufacturing or laboring jobs, rather ones that require intelligence, independent/creative thinking, and human understanding (see next page) (McKinsey Global Institute, 2017). We can see that the jobs that will be automated the least are all degree level, education, management (less so with this one) and professionals. From this we can conclude that instead of providing standard retraining we need to other degree level retraining. To do this though the new students will have to pay tuition fees which are prohibitively high to some students let alone parents trying to support their own children going through uni who cannot access grants. In short if we want to mass retrain people at a degree level we need to get rid of tuition fees.\n\nSocietal action\nCurrently our society is geared to attain 100% employment. This full employment model creates pointless jobs just for the sake of keeping people working (Graeber, 2013). However, if 30% of people become unemployed this model will quickly fall apart. So undoubtedly retraining programs will appear and retraining some of the unemployed. But a large portion won\u2019t want to be. If you are a lawyer, you\u2019re not going to want to retrain into a teacher or a therapist because they\u2019re completely different fields that wouldn\u2019t interest you. And even if a UBI is implemented then we can\u2019t all be entrepreneurs. This is mostly because it costs a lot less to run a successful company in the modern day. For instance, Instagram was bought for $1 billion, at that time it only had 13 employees (Geron, 2012). As this clearly shows you now need a lot less people to have an even bigger impact than ever before. So, we need to find something to occupy ourselves with.\nInterplanatary colonisation\nOne suggestion is that we apply our newfound technological capabilities to undertaking a great task such as exploring space. This has several benefits.\n1. It would retrain people\na. This is because starting a colony will take many new skills from all backgrounds. We could gear the retraining programs to train people to build rockets\n2. It would produce employment\na. Yes, it might be much cheaper to build rockets by robot but why do that when you could employ people? On earth we could use the robots to do the mundane tasks that just have to be done such as; mass farming to feed everyone, building homes, treating illnesses.\n3. Life would be less likely to be wiped out\na. We might just be the only life in the entire universe. Maybe even all of time. So it would be a real shame if we were wiped out by a single asteroid or a territorial spat or a massive plague. But if we have a self-sufficient colony on another world the chances of ALL of humanity drop to practically zero.\nDespite these benefits there are some serous disadvantages. For instance we might accidently create a dystopia such as in Kim Stanley Robinsons Mars trilogy and 2312 (Robinson, The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars, 2015) (Robinson, 2312, 2013), if we want to avoid this we should ensure that the selection criteria for colonization is not financial but based on ability.\nElimination of the great killers\nThroughout human history life has been short and nasty. If you were lucky enough to be born and your mother to have survived the ordeal you lived through roughly 40 grueling years of work to end up dead. By comparison even the poorest person in the first world would not suffer that much. However, many people in LIC\u2019s (less industrialized countries) still live in this Malthusian misery trap. However, we now have the technological abilities to free them. We could use robots to mass farm to feed cheaply people (farmbot, 2018), we could use modified 3d printers with concrete to 3d print houses in areas with high homelessness (apis-cor, 2018), and we can release genetically engineered mosquitoes to crash the population of a certain type of mosquito (Carvalho DO, 2015). All these techniques use the latest in technology and robotics to solve the great problems of the world. However, to deploy we will need to work together with a large human fleet to support it.\nA new social order\nAutomation itself will undoubtedly cause a great in politics. This is because as previously established society will have to change and so will our priorities. And seeming as political order and systems, I descended from those governed as per defined by social contract theory (Rousseau, 1913). However, as our society changes rapidly our systems will quickly unfold and become unsuitable for the modern world. This will inevitably lead to the creation of new types of government such as Futarchy (Buterin, 2014) and liquid democracy (Jochmann, 2012). However, if not properly handled the opportunity maybe seized by the \u2018new radicals\u2019 such as Donald Trump and Heinz-Christian Strache (Carswell, 2017). However, if we can seize the opportunity then we have a chance like no other to make a real lasting impact on the world.\nConclusion\nRobotic automation will have a wide-ranging effect on society. The predicted levels of unemployment can only be described as catastrophic by today\u2019s standards. To cope with this change, we must find meaning in our lives and our existence. To cope we will take on new and exciting challenges such as founding a Martian colony and becoming more than human. Sadly, though the governments that have the power to enact the decisions required to help humanity cope with the turbulence of change, seem blissfully ignorant of the dire need for discussion and debate on this most important debate.\nBibliography\nAnsip, A. (2017, June 2). EU Commissioner Says No to Bill Gates\u2019 Robot Tax Idea. (CNBC, Interviewer)\napis-cor. (2018, January 7). Home apis-cor. Retrieved from apis-cor: http://apis-cor.com/en\nArntz, M., Gregory, T., & Ulrich, Z. (2016). The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis. OECD Social, Employment and Migration Working. Paris: OECD Publishing. doi:http://dx.doi.org/10.1787/5jlz9h56dvq7-en\nBasic Income Earth Network. (2017, December 28). BIEN: Basic Income Earth Network. Retrieved from About basic income: http://basicincome.org/basic-income/\nBBC News technology. (2012, April 10). BBC. Retrieved from BBC|News|Technology|Facebook buys Instagram photo sharing network for $1bn: http://www.bbc.co.uk/news/technology-17658264\nBerriman, R., & Hawksworth, J. (2017). Will robots steal our jobs? The potential impact of automation on the UK and other major economies. London: Price-waterhouse-Coopers LLP.\nButerin, V. (2014, August 21). An Introduction to Futarchy. Retrieved from Ethereum blog: https://blog.ethereum.org/2014/08/21/introduction-futarchy/\nCarson, E. (2015, August 3). How workers can retrain for careers in an automated world. Retrieved from ZDnet: http://www.zdnet.com/article/how-workers-can-retrain-for-careers-in-an-automated-world/\nCarvalho DO, M. A. (2015). Suppression of a Field Population of Aedes aegypti in Brazil by Sustained Release of Transgenic Male Mosquitoes. PLoS Negl Trop Dis, 1. Retrieved from https://doi.org/10.1371/journal.pntd.0003864\nCenter for Global Policy Solutions. (2017). Stick Shift: Autonomous Vehicles, Driving Jobs, and the Future of Work. Washington, DC: Center for Global Policy Solutions.\nCoindesk. (2017, November 30). Price page, 2017\u20132018. Retrieved from Coindesk: https://www.coindesk.com/price/\nDayoub, F., Dunbabin, M., & Corke, P. (2015). Robotic Detection and Tracking of Crown-of-Thorns Starfish. Queensland: Queensland University of Technology.\nDurden, T. (2017, Febuary 3). Rig Count Surges Again To 16-Month Highs (But Where\u2019s The Oil Industry Jobs). Retrieved from ZeroHedge: http://www.zerohedge.com/news/2017-02-03/rig-count-surges-again-16-month-highs-wheres-oil-industry-jobs\nEvans, D. K., & Popova, A. (2014). Cash transfers and remptation goods: a review of global evidence (English). Washington DC: World Bank. Retrieved from http://documents.worldbank.org/curated/en/617631468001808739/Cash-transfers-and-temptation-goods-a-review-of-global-evidence\nfarmbot. (2018, January 7). Home farmbot. Retrieved from Farmbot website: https://farm.bot/\nFrey, C. B., & Osborne, M. A. (2013). THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION? Oxford: Oxford University.\nFuture of Life Institute. (2015, July 28). Autonomous Weapons: an Open Letter from AI & Robotics Researchers. Retrieved from Future of Life Institute: https://futureoflife.org/open-letter-autonomous-weapons/\nGates, B. (2017, Febuary 17). Why Bill Gates would tax robots. (Quartz, Interviewer)\nGeron, T. (2012, September 6). Facebook Officially Closes Instagram Deal. Retrieved from Forbes: https://www.forbes.com/sites/tomiogeron/2012/09/06/facebook-officially-closes-instagram-deal/#6bed65c61d45\nGraeber, D. (2013, August 1). On the Phenomenon of Bullshit Jobs: A Work Rant. Retrieved from STRIKE! Magazine: https://strikemag.org/bullshit-jobs\nGross, B. (2016). Culture Clash. Investment Outlook, 2. Retrieved from https://17eb94422c7de298ec1b-8601c126654e9663374c173ae837a562.ssl.cf1.rackcdn.com/Documents/umbrella%2Fbill%20gross%2FBill%20Gross%20Investment%20Outlook_May%202016.pdf\nHM Treasury. (2017). Autumn Budget 2017. London: HM Treasury.\nHum, D., & Simpson, W. (1993). Economic Response to a Guaranteed Annual Income: Experience from Canada and the United States. Journal of Labor Economics, 11.\nIsaac, A., & Wallace, T. (2017, September 27). Return of the Luddites: why a robot tax could never work. Retrieved from The Telegraph: www.telegraph.co.uk/business/2017/09/27/return-luddites-robot-tax-could-never-work/\nJochmann, J. (2012, November 18). Liquid Democracy In Simple Terms. Youtube. Retrieved January 7, 2018, from https://www.youtube.com/watch?v=fg0_Vhldz-8\nKatz, L., & Verhage, J. (2017, November 27). Bloomberg Technology. Retrieved from Novogratz Says Crypto Will Be \u2018Biggest Bubble of Our Lifetimes\u2019: https://www.bloomberg.com/news/articles/2017-11-28/novogratz-says-bitcoin-to-win-out-over-other-digital-currencies\nMcKinsey Global Institute. (2017). A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY. London: McKinsey&Company.\nMusk, E. (2016, November 4). Elon Musk: Robots will take your jobs, government will have to pay your wage. (CNBC, Interviewer)\nPilkington, E. (2015, November 19). The Gaurdian. Retrieved from Life as a drone operator: \u2018Ever step on ants and never give it another thought?\u2019 : https://www.theguardian.com/world/2015/nov/18/life-as-a-drone-pilot-creech-air-force-base-nevada\nRobinson, K. S. (2013). 2312. London: Orbit.\nRobinson, K. S. (2015). The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars. New York City: Harper Voyager.\nRousseau, J. J. (1913). Social Contract & Discourses, Translated with Introduction by G. D. H. Cole. New York: Dutton&Co. Retrieved January 7, 2018, from http://www.bartleby.com/br/168.html\nThe Economist. (2014, Jannuary 18). The onrushing wave. Retrieved from The Economist: https://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\nVaroufakis, Y. (2017, Febuary 27). A Tax on Robots? Retrieved from Project Syndicate: https://www.project-syndicate.org/commentary/bill-gates-tax-on-robots-by-yanis-varoufakis-2017-02?barrier=accessreg\nYougov. (2015, August 12). Yougov|News|37% of British workers think their jobs are meaningless. Retrieved from Yougov: https://yougov.co.uk/news/2015/08/12/british-jobs-meaningless/\n\u000eX\n"
  },
  {
    "title": "EPQ draft 1 (4844 words)",
    "content": "EPQ draft 1 (4844 words)\nhttps://upload.wikimedia.org/wikipedia/commons/1/1f/Sanko_Seisakusyo_%28%E4%B8%89%E5%B9%B8%E8%A3%BD%E4%BD%9C%E6%89%80%29_%E2%80%93_Tin_Wind_Up_%E2%80%93_Tiny_Smoking_Spaceman_Robots_%E2%80%93_Close_Up.jpg\nIntroduction\nAutomation is set to un-employ people at a scale and rate never seen before, while simultaneously changing societies very nature on an epic scale; to mitigate its impact we must undertake projects and policies that push ourselves, humanity, and society to its limits. The future could take one of two shapes; a utopian wonderland where everyone is happy, or a dystopia where algorithms and machines run the world for maximum efficiency leaving humanity in the slums. However, despite the impending danger, we are seemingly unaware of it. This is because automation creeps in slowly, so we don\u2019t notice it, only once the teamsters, lawyers, and the CEO\u2019s start to lose their jobs will we notice the extent of what we have created. This is nature of automation you don\u2019t notice until it\u2019s your job, your income, your life that is affected.\nHowever, we might hope that our governments have foreseen this danger and are planning how to avoid it. Yet we do not see any real indication from the government (as of time of writing) that they need to do anything to prepare for the unemployed masses. On the contrary in the 2017 autumn budget the government announced that they wanted to see fully driverless cars by 2021 (HM Treasury, 2017). This is even though a CGPS study showed that over 4 million jobs will be lost to driverless cars in the US (Center for Global Policy Solutions., 2017). IN this report I aim to investigate three main key factors that need to be addressed by both policy makers and the public, to prepare ourselves for the future. These are; Too what extent will automation occur, how will this automation effect society and how should we mitigate its impact? By answering these three questions I hope to bring further clarity to a pressing issue that will affect society from top to bottom.\nToo what extent will automation happen\nThe first question that must be answered in this topic is how much automation will occur. There have been many studies that have attempted to estimate this, and their findings have varied considerably. The most recent study is one by PWC (Berriman & Hawksworth, 2017). By analyzing the other studies and improving upon their methods, they conducted a new survey which concluded that.\n\u201cOur analysis suggests that up to 30% of UK jobs could potentially be at high risk of automation by the early 2030s, lower than the US (38%) or Germany (35%), but higher than Japan (21%).\u201d (Berriman & Hawksworth, 2017) I have converted this data into a graph below along with other recent studies.\n\nAs we can see from the graph the results of automation studies vary greatly. The original study by FO classified jobs as automatable or not by looking at whether most of its tasks could be automated, this meant that they could develop an algorithm to predict what jobs could and could not be automated. AGZ on the other hand, claimed a job was only automatable if all its tasks where fully automatable. This however leads to a vastly reduced number of jobs being classed as automatable. If a job has ten parts and five can be automated surely you can still fire half the workers and maintain the same output. This meant that the results of the AGZ study underestimate the likely impact of automation. For this reason, I have chosen to use the most recent study (PwC) to base my study off.\nWill new jobs be created?\nIf we can have expected jobs to be lost surely, we should also expect new ones to be created to take their place? However, despite this logic the data suggests otherwise see the graph below (Durden, 2017).\n\nAs we can see quite clearly although rig count and therefore oil production has increased, the number of employers has stayed almost the same. This indicates that we are producing more oil with less and less energy required. What\u2019s more interesting if you look at the percentage of eligible workers employed over time (Gross, 2016).\n\nAs you can see from the graph, the percentage of people employed increases until a recession; at this point employment drops as business make cuts and increase automation, employment regains and then falls. Overtime this cycle reduces peak employment. Furthermore, we can see that the greater the recession the more jobs are irretrievably lost. Currently many believe that we could be in one of the biggest bubbles of all time. The crypto bubble. This term refers to the presumed bubble of cryptocurrencies such as bitcoin and Ethereum. The graph below shows the price of bitcoin over the last year alone (Coindesk, 2017).\n\nIt is widely assumed and even accepted that the crypto bubble will be the biggest of our lifetimes and that at some point it will almost certainly burst crashing everyone else with it. This conclusion is mainly drawn from its similarities to the dotcom bubble which burst in 2000\u20132002. In comparison to the crypto bubble the dot com bubble is expected to look almost reasonable. However, many technology enthusiasts point out that this is okay seeming as we do now all use the internet (Katz & Verhage, 2017). Either way if this is a bubble then we should expect to see job losses in the extremes, jobs that we should not expect to return.\nFinally, we must consider whether the new sectors will produce new jobs. Technologists often argue that despite jobs being automated its fine because new jobs such as software developers are being created. And yes, this is true. Whilst it would be unthinkable for the jobs \u2018Computer Software Engineer\u2019 or \u2018Computer Programmer\u2019 to have existed back in 1980 and now there is 1,300,000 of them. Does not deny the fact that one team of software engineers eleven can design, build, and deploy the next \u2018killer app\u2019 within two years and walk away with one billion dollars from its sale. This is the story of Instagram (BBC News technology, 2012). This is a classic case; one we can expect to see much more of. It demonstrates that you no longer need tons of workers to make tons of money. So yes while a few new jobs will be created, we should not rely on these new jobs to support people.\nIn conclusion we can expect to see lots of job losses within the next 30 years. This is due to the combined effect of automation enabling more jobs to be automated and an impending recession that will drive business to make cuts and improve their business efficiency, with an increasingly small number of people required to make a business successful. We can expect to see unemployment rise to 30% by 2030 and possibly even as high as 50% by 2050.\nWhy do we work?\nThroughout all of time humanity has been in a constant struggle to survive. From stone age man hunting the mighty mammoth, to office workers hunting the mighty pay rise. Humans have always had to strive to survive. Never have we been given the opportunity to simply have it provided to us, although yes, we do get our sustenance easier now than ever before we still must work to get it. But what if we didn\u2019t?\nThere are three main points of view on the meaning of work. Some people believe that we work because it gives us meaning, that without it we would be aimless with no purpose. The other group say that we work simply for the money and that if that wasn\u2019t an issue we could quite happily live our lives doing what we really wanted to do.\n\nSome people argue that we work to give meaning to our lives. If we did not work, we would all very quickly turn to violence and crime. To find out more about this I conducted a survey of 249 random subjects.\n\nFrom this we can see that people are clearly divided on the topic. But I was asking about work in general. If, however you ask someone whether their job has meaning you get a very different response. This is demonstrated by a 2015 YouGov poll. The poll showed that 37% of people do not believe that their job is contributing to the world (Yougov, 2015). This is a shocking statistic and makes us wonder quite what jobs these people are doing that they their jobs as pointless.\n\nBy analysing the data in the survey, we can conclude that working class people are more likely to believe that their job is not having a meaningful contribution to the world than middle class people. We can also see that some areas have significantly lower levels of meaningfulness than others such as London. Despite the elevated levels of meaninglessness in London less people said that they would be \u201cnot proud to tell a stranger what their job was\u201d, unlike in Scotland where there are elevated levels of meaningfulness and elevated levels of shame.\n\nSo, we can conclude that people in lower economic brackets are more likely to see themselves in pointless jobs. We can also see that people in areas of high population concentration such as London and the north are more likely to be not fulfilled by their job.\nIn August 2013 David Graeber wrote an influential article for STRIKE! Magazine (Graeber, 2013).In this article he argued that many modern jobs are \u2018bullshit jobs\u2019. They point out that in 1930 John Maynard Keynes (arguably the capitalist equivalent to Karl Marx), predicted that by the centuries end that developed countries such as Great Britain would be so technologically advanced that people who lived there would on average work only 15 hours a week. And yes, as predicted most of manufacturing jobs have been automated yet despite this we have not achieved the 15-hour week. Graeber argues that this is due to the creation of \u2018bullshit jobs\u2019. There has been a massive explosion in the services/administration sector. In fact, between 1948 and 2011 the services sector in the US has\nFigure 3: https ://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\ngone from 45% of total employment to 68% of total employment (not including government jobs) (The Economist, 2014)\nThe new services sector comprises many jobs such as:\n\u00b7 Financial services\n\u00b7 Telemarketing\n\u00b7 Corporate law\n\u00b7 Academic/health administration\n\u00b7 Human resources\n\u00b7 Public relations\nThese are what Graeber proposes are \u2018bullshit jobs\u2019. A bullshit hob is one that provides little or no meaning to society and the world. And yet even though the people doing these jobs find them pointless they continue to do them. And what\u2019s more they continue to be created.\nFigure 4: https://www.vice.com/en_uk/article/yvq9qg/david-graeber-pointless-jobs-tube-poster-interview-912\nIf bullshit jobs are pointless why are they created? Many would argue that society creates jobs to ensure that they can continue to partake in society. Some would argue that because of this if people did not have to work to have a good enough income to live on then they would not work. They argue that instead they would spend their time doing things they enjoy and getting the education required to do interesting jobs such as medicine or teaching. This is backed up by universal basic income studies. A universal basic income is a guaranteed income that is paid to all eligible members of society. This is often done by a negative income tax; this is where after earning below a certain point the state stats to give you a guaranteed income. Most importantly however this payment has no strings attached. This means that if people want to then they can and can do no work and just live of benefits. However, the statistics from the studies do not show that this happens. In 1974 a basic income study was carried out in Manitoba (Canada); it showed that people barely reduced their working hours, and those that did used it to spend more time with their families and or taking additional classes reaping untold benefits for the economy (Hum & Simpson, 1993).\nMany argue that even if automation does occur then people could continue to do jobs that give them meaning if they wish. Just because a job could be done by a robot does not necessarily mean it will be. If people find meaning in work, then they can continue to do so. However, if your job is mind bogglingly boring then why should you have to do it if you don\u2019t want to? As we enter the new automated age then we are going to have to realize that we should have fun in life and if that means not working then so be it. But the clear majority will find something to do be it inventing, painting, or pushing the boundaries we must accept that our society will change to accommodate our new-found freedom.\nHow can we mitigate its impact?\nWorking on the dual assumptions that; soon robotic automation will increase so that 30% of jobs become automated (with not enough being created to replace them), and that in our current state if we get rid of work then there would be large increases in crime and violence. We can conclude that preemptive measures need to take preemptive measures to mitigate the impact. I have split these preemptive measures into two main types.\n\nOnly by combining a variety of government policies and regulation with a collective societal move towards less work based system we can ensure that minimal damage is done. This is the main subject of this report. I will first discuss potential government policies and then the action that society must implement to make the most of automation.\nGovernment policies and responsibillities\nGovernment policies come in the form of taxes, benefits, regulation, or programs. A tax is designed to incite a behavior using negative reinforcement i.e. persuade someone or a company to do something otherwise they will lose more money. Benefits give money to people (typically working-class people), this provides them with an income to survive even if they lose their jobs. Regulation prevents the development \u2018bad robots\u2019 such as terminators. Programs run by governments help to retrain people to get them new jobs by giving them new skills such as programming.\nTax\nThe tax I am investigate is a robot tax. A robot tax is a system where cooperation\u2019s are taxed depending on how much of their workforce is automated. For instance, if you were a company that \u2018employed\u2019 a robot corporate lawyer you would pay robot tax equivalent to the income tax a corporate lawyer would have paid. This money could be used to fund other government initiatives such as new benefits and retraining programs (Varoufakis, 2017). Proponents for the tax are wide ranging and include tech giants such as Bill Gates (Gates, 2017) and futurists such as Elon Musk (Musk, 2016). However, some people such as Estonian politician Andrus Ansip believe that this is a bad idea (Ansip, 2017). It is argued that it would be difficult if not impossible to calculate the equivalent wage that the robot would have earned if a human where doing the same job. Furthermore, it is argued that this would reduce innovation as it would stop companies automating jobs, this is bad as some jobs a very dangerous and it is ethical to automate them even if it means someone loses their job (Isaac & Wallace, 2017).\nBenifits\nA common suggestion to mitigate the impact of robotics is the implementation of a new benefit called a Universal Basic Income (UBI), it is also known as basic income (BI), citizens income (CI) and negative income tax (NIT). But whatever its name (I shall use UBI) it involves giving all citizens a basic income (except in NIT where it is only the poorest) (Basic Income Earth Network, 2017). It has been studied in many studies in a range of situations for a variety of clients. It is argued that doing so would be cheaper than our current welfare system, this is because there would be very low administration costs. Furthermore, it is argued (and proven in studies) that a basic income gives better outcome than independent benefits (Hum & Simpson, 1993). It is also shown to increase personal development and entrepreneurship as people have a safety floor to stand on to achieve their aims be it setting up a company or training to get into a new profession. This is how UBI solves the issue of automation, it encourages personal retraining and entrepreneurship which in turn provides new jobs and bolsters the economy. Opponents argue that a UBI would encourage crime and antisocial behavior such as drug abuse. However, a report by the world bank that summarized the findings of 30 studies disproved this (Evans & Popova, 2014).\nRegulation\nOne big worry about robots is that they will rise and take over the world. Whilst this may at first seem like an unrealistic and reactionary response to automation. However, these fears are well founded. In 2015 a robot was released by Queensland university of technology that will patrol coral reefs, and autonomously make the decision to kill the deadly crown of thorns starfish that destroys reefs (Dayoub, Dunbabin, & Corke, 2015). Although this application is undeniably good as we need to protect corals; it sets a dangerous precedent. The same technology can easily be expanded into military drones. Drones have long been used by the military, however this has led to sometimes disastrous consequences. The pilots feel detached and say it is like stepping on an ant (Pilkington, 2015). Imagine how much that feeling of detachment will become when instead of pulling a trigger you just must sign a piece of paper to authorize the strike. Despite this and warnings from high profile critics such as Stephen Hawking, Elon Musk, and Steve Wozniak (Future of Life Institute, 2015). As such it is undeniable that we should enact legislation to prevent the development of AI that decides when to kill human to ensure that we do not lose control.\nprogrames\nOne proposed solution is retraining. This is where people who have been or will be made redundant due to automation are retrained to do new jobs. This retraining is funded by the government or previous employer and is usually in the form of a course or other qualification (Carson, 2015). These types of programs are useful and are a common way to mitigate impact when unemployment occurs on a mass scale. However, the type of unemployment that we will see might not end up being concentrated as it is normally. If all the manufacturing companies fired half their workers, yes there would be a lot of unemployment, but it would be widely dispersed; it is also harder to retrain people when they are dispersed as you cannot just set up one program. Therefore, these new courses will mostly have to be done online. But this again throws up another problem. The jobs that will be created/will not be automated are not manufacturing or laboring jobs, rather ones that require intelligence, independent/creative thinking, and human understanding (see next page) (McKinsey Global Institute, 2017). We can see that the jobs that will be automated the least are all degree level, education, management (less so with this one) and professionals. From this we can conclude that instead of providing standard retraining we need to other degree level retraining. To do this though the new students will have to pay tuition fees which are prohibitively high to some students let alone parents trying to support their own children going through uni who cannot access grants. In short if we want to mass retrain people at a degree level we need to get rid of tuition fees.\n\nSocietal action\nCurrently our society is geared to attain 100% employment. This full employment model creates pointless jobs just for the sake of keeping people working (Graeber, 2013). However, if 30% of people become unemployed this model will quickly fall apart. So undoubtedly retraining programs will appear and retraining some of the unemployed. But a large portion won\u2019t want to be. If you are a lawyer, you\u2019re not going to want to retrain into a teacher or a therapist because they\u2019re completely different fields that wouldn\u2019t interest you. And even if a UBI is implemented then we can\u2019t all be entrepreneurs. This is mostly because it costs a lot less to run a successful company in the modern day. For instance, Instagram was bought for $1 billion, at that time it only had 13 employees (Geron, 2012). As this clearly shows you now need a lot less people to have an even bigger impact than ever before. So, we need to find something to occupy ourselves with.\nInterplanatary colonisation\nOne suggestion is that we apply our newfound technological capabilities to undertaking a great task such as exploring space. This has several benefits.\n1. It would retrain people\na. This is because starting a colony will take many new skills from all backgrounds. We could gear the retraining programs to train people to build rockets\n2. It would produce employment\na. Yes, it might be much cheaper to build rockets by robot but why do that when you could employ people? On earth we could use the robots to do the mundane tasks that just have to be done such as; mass farming to feed everyone, building homes, treating illnesses.\n3. Life would be less likely to be wiped out\na. We might just be the only life in the entire universe. Maybe even all of time. So it would be a real shame if we were wiped out by a single asteroid or a territorial spat or a massive plague. But if we have a self-sufficient colony on another world the chances of ALL of humanity drop to practically zero.\nDespite these benefits there are some serous disadvantages. For instance we might accidently create a dystopia such as in Kim Stanley Robinsons Mars trilogy and 2312 (Robinson, The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars, 2015) (Robinson, 2312, 2013), if we want to avoid this we should ensure that the selection criteria for colonization is not financial but based on ability.\nElimination of the great killers\nThroughout human history life has been short and nasty. If you were lucky enough to be born and your mother to have survived the ordeal you lived through roughly 40 grueling years of work to end up dead. By comparison even the poorest person in the first world would not suffer that much. However, many people in LIC\u2019s (less industrialized countries) still live in this Malthusian misery trap. However, we now have the technological abilities to free them. We could use robots to mass farm to feed cheaply people (farmbot, 2018), we could use modified 3d printers with concrete to 3d print houses in areas with high homelessness (apis-cor, 2018), and we can release genetically engineered mosquitoes to crash the population of a certain type of mosquito (Carvalho DO, 2015). All these techniques use the latest in technology and robotics to solve the great problems of the world. However, to deploy we will need to work together with a large human fleet to support it.\nA new social order\nAutomation itself will undoubtedly cause a great in politics. This is because as previously established society will have to change and so will our priorities. And seeming as political order and systems, I descended from those governed as per defined by social contract theory (Rousseau, 1913). However, as our society changes rapidly our systems will quickly unfold and become unsuitable for the modern world. This will inevitably lead to the creation of new types of government such as Futarchy (Buterin, 2014) and liquid democracy (Jochmann, 2012). However, if not properly handled the opportunity maybe seized by the \u2018new radicals\u2019 such as Donald Trump and Heinz-Christian Strache (Carswell, 2017). However, if we can seize the opportunity then we have a chance like no other to make a real lasting impact on the world.\nConclusion\nRobotic automation will have a wide-ranging effect on society. The predicted levels of unemployment can only be described as catastrophic by today\u2019s standards. To cope with this change, we must find meaning in our lives and our existence. To cope we will take on new and exciting challenges such as founding a Martian colony and becoming more than human. Sadly, though the governments that have the power to enact the decisions required to help humanity cope with the turbulence of change, seem blissfully ignorant of the dire need for discussion and debate on this most important debate.\nBibliography\nAnsip, A. (2017, June 2). EU Commissioner Says No to Bill Gates\u2019 Robot Tax Idea. (CNBC, Interviewer)\napis-cor. (2018, January 7). Home apis-cor. Retrieved from apis-cor: http://apis-cor.com/en\nArntz, M., Gregory, T., & Ulrich, Z. (2016). The Risk of Automation for Jobs in OECD Countries: A Comparative Analysis. OECD Social, Employment and Migration Working. Paris: OECD Publishing. doi:http://dx.doi.org/10.1787/5jlz9h56dvq7-en\nBasic Income Earth Network. (2017, December 28). BIEN: Basic Income Earth Network. Retrieved from About basic income: http://basicincome.org/basic-income/\nBBC News technology. (2012, April 10). BBC. Retrieved from BBC|News|Technology|Facebook buys Instagram photo sharing network for $1bn: http://www.bbc.co.uk/news/technology-17658264\nBerriman, R., & Hawksworth, J. (2017). Will robots steal our jobs? The potential impact of automation on the UK and other major economies. London: Price-waterhouse-Coopers LLP.\nButerin, V. (2014, August 21). An Introduction to Futarchy. Retrieved from Ethereum blog: https://blog.ethereum.org/2014/08/21/introduction-futarchy/\nCarson, E. (2015, August 3). How workers can retrain for careers in an automated world. Retrieved from ZDnet: http://www.zdnet.com/article/how-workers-can-retrain-for-careers-in-an-automated-world/\nCarvalho DO, M. A. (2015). Suppression of a Field Population of Aedes aegypti in Brazil by Sustained Release of Transgenic Male Mosquitoes. PLoS Negl Trop Dis, 1. Retrieved from https://doi.org/10.1371/journal.pntd.0003864\nCenter for Global Policy Solutions. (2017). Stick Shift: Autonomous Vehicles, Driving Jobs, and the Future of Work. Washington, DC: Center for Global Policy Solutions.\nCoindesk. (2017, November 30). Price page, 2017\u20132018. Retrieved from Coindesk: https://www.coindesk.com/price/\nDayoub, F., Dunbabin, M., & Corke, P. (2015). Robotic Detection and Tracking of Crown-of-Thorns Starfish. Queensland: Queensland University of Technology.\nDurden, T. (2017, Febuary 3). Rig Count Surges Again To 16-Month Highs (But Where\u2019s The Oil Industry Jobs). Retrieved from ZeroHedge: http://www.zerohedge.com/news/2017-02-03/rig-count-surges-again-16-month-highs-wheres-oil-industry-jobs\nEvans, D. K., & Popova, A. (2014). Cash transfers and remptation goods: a review of global evidence (English). Washington DC: World Bank. Retrieved from http://documents.worldbank.org/curated/en/617631468001808739/Cash-transfers-and-temptation-goods-a-review-of-global-evidence\nfarmbot. (2018, January 7). Home farmbot. Retrieved from Farmbot website: https://farm.bot/\nFrey, C. B., & Osborne, M. A. (2013). THE FUTURE OF EMPLOYMENT: HOW SUSCEPTIBLE ARE JOBS TO COMPUTERISATION? Oxford: Oxford University.\nFuture of Life Institute. (2015, July 28). Autonomous Weapons: an Open Letter from AI & Robotics Researchers. Retrieved from Future of Life Institute: https://futureoflife.org/open-letter-autonomous-weapons/\nGates, B. (2017, Febuary 17). Why Bill Gates would tax robots. (Quartz, Interviewer)\nGeron, T. (2012, September 6). Facebook Officially Closes Instagram Deal. Retrieved from Forbes: https://www.forbes.com/sites/tomiogeron/2012/09/06/facebook-officially-closes-instagram-deal/#6bed65c61d45\nGraeber, D. (2013, August 1). On the Phenomenon of Bullshit Jobs: A Work Rant. Retrieved from STRIKE! Magazine: https://strikemag.org/bullshit-jobs\nGross, B. (2016). Culture Clash. Investment Outlook, 2. Retrieved from https://17eb94422c7de298ec1b-8601c126654e9663374c173ae837a562.ssl.cf1.rackcdn.com/Documents/umbrella%2Fbill%20gross%2FBill%20Gross%20Investment%20Outlook_May%202016.pdf\nHM Treasury. (2017). Autumn Budget 2017. London: HM Treasury.\nHum, D., & Simpson, W. (1993). Economic Response to a Guaranteed Annual Income: Experience from Canada and the United States. Journal of Labor Economics, 11.\nIsaac, A., & Wallace, T. (2017, September 27). Return of the Luddites: why a robot tax could never work. Retrieved from The Telegraph: www.telegraph.co.uk/business/2017/09/27/return-luddites-robot-tax-could-never-work/\nJochmann, J. (2012, November 18). Liquid Democracy In Simple Terms. Youtube. Retrieved January 7, 2018, from https://www.youtube.com/watch?v=fg0_Vhldz-8\nKatz, L., & Verhage, J. (2017, November 27). Bloomberg Technology. Retrieved from Novogratz Says Crypto Will Be \u2018Biggest Bubble of Our Lifetimes\u2019: https://www.bloomberg.com/news/articles/2017-11-28/novogratz-says-bitcoin-to-win-out-over-other-digital-currencies\nMcKinsey Global Institute. (2017). A FUTURE THAT WORKS: AUTOMATION, EMPLOYMENT, AND PRODUCTIVITY. London: McKinsey&Company.\nMusk, E. (2016, November 4). Elon Musk: Robots will take your jobs, government will have to pay your wage. (CNBC, Interviewer)\nPilkington, E. (2015, November 19). The Gaurdian. Retrieved from Life as a drone operator: \u2018Ever step on ants and never give it another thought?\u2019 : https://www.theguardian.com/world/2015/nov/18/life-as-a-drone-pilot-creech-air-force-base-nevada\nRobinson, K. S. (2013). 2312. London: Orbit.\nRobinson, K. S. (2015). The Complete Mars Trilogy: Red Mars, Green Mars, Blue Mars. New York City: Harper Voyager.\nRousseau, J. J. (1913). Social Contract & Discourses, Translated with Introduction by G. D. H. Cole. New York: Dutton&Co. Retrieved January 7, 2018, from http://www.bartleby.com/br/168.html\nThe Economist. (2014, Jannuary 18). The onrushing wave. Retrieved from The Economist: https://www.economist.com/news/briefing/21594264-previous-technological-innovation-has-always-delivered-more-long-run-employment-not-less\nVaroufakis, Y. (2017, Febuary 27). A Tax on Robots? Retrieved from Project Syndicate: https://www.project-syndicate.org/commentary/bill-gates-tax-on-robots-by-yanis-varoufakis-2017-02?barrier=accessreg\nYougov. (2015, August 12). Yougov|News|37% of British workers think their jobs are meaningless. Retrieved from Yougov: https://yougov.co.uk/news/2015/08/12/british-jobs-meaningless/\n\u000eX\n"
  },
  {
    "title": "Ascent of data Science, SAS and Big data Analyst Trainings Programs",
    "content": "Ascent of data Science, SAS and Big data Analyst Trainings Programs\n\nVarious associations in the present days are opening entryways for huge information. So as to open the power, Data Science Training in Mumbai assumes an irreplaceable part. They have the capacity of driving a plenty of data which exists inside the foundation. An Data Science researcher is helpful with regards to dissecting and preparing information.\nA Data Scientist who has an accomplished in the business will fill in as vital accomplice and confided in counselor in the administration of a business association and ensure that the workers upgrade the examination abilities of their own. An information science courses in pune assumes an irreplaceable part in the correspondence and exhibit of the estimation of the investigation of a foundation for the encouraging ad libbed method of taking choices crosswise over various phases of a business through following, estimating and additionally recording distinctive execution measurements.\nFor what motivation to pick Big Data Analytics?\nThis Big Data Analytics takes various arranged parts and distinctive capacities that make a motivation from data. Information science preparing in Mumbai is the right calling route for the social occasion of individuals to put in unprecedented demand in the slanting stage.\nCourse Overview\nData Analytics Training makes the gathering of spectators utilize aptitudes from major to front line level in each and every module to comprehend all the business challenges. Affirmation is passed on to the wannabes toward the complete of Big Data Analytics Course that puts in exceptional demand to secure a work in reputed associations.\nFeatures\n\u2022 Division and Clustering\n\u2022 Display Building and Validation\n\u2022 Machine Learning: Unsupervised Learning\n\u2022 Characterization Models\n\u2022 Making an Analytical Dataset\n\u2022 Feel straightforwardness to arrive a position\nWhat will you understand in this course?\nInterminable supply of Big data Hadoop training in Mumbai, hopefuls will lay a magnificent charge over each and every module to go up against genuine challenges.\n\u2022 Deploying of Data Analysis Life cycle to address gigantic data examination wanders\n\u2022 Reframing of business challenges as a demonstrative test\n\u2022 Enhances capacities in various coherent strategies and mechanical assemblies to dismember enormous data and arrangement of quantifiable models and perceiving of bits of learning that can incite huge results\nSAS Training in Pune, the course stays for quantifiable examination structure, which is an item game plan used for front line examination inside the work put. It is moreover used for data organization game plans, business learning, judicious examination and that is only the start. It can be an important gadget to empower you to manage your data more feasibly and to empower you to build up your business later on.\nAccording to the present market circumstance, the void of data specialist fulfills with each passing day. However in the meantime, associations scan for the proficient data specialists as the stock system of understudies from this master course limits after a particular point in time. In any case, foundations that give these courses guarantee position straightforwardly after the course gets over. You require not scan for any movement consultancy firm to get a game plan. Associations search for you straightforwardly after you get the confirmation from the establishments.\n"
  },
  {
    "title": "Ascent of data Science, SAS and Big data Analyst Trainings Programs",
    "content": "Ascent of data Science, SAS and Big data Analyst Trainings Programs\n\nVarious associations in the present days are opening entryways for huge information. So as to open the power, Data Science Training in Mumbai assumes an irreplaceable part. They have the capacity of driving a plenty of data which exists inside the foundation. An Data Science researcher is helpful with regards to dissecting and preparing information.\nA Data Scientist who has an accomplished in the business will fill in as vital accomplice and confided in counselor in the administration of a business association and ensure that the workers upgrade the examination abilities of their own. An information science courses in pune assumes an irreplaceable part in the correspondence and exhibit of the estimation of the investigation of a foundation for the encouraging ad libbed method of taking choices crosswise over various phases of a business through following, estimating and additionally recording distinctive execution measurements.\nFor what motivation to pick Big Data Analytics?\nThis Big Data Analytics takes various arranged parts and distinctive capacities that make a motivation from data. Information science preparing in Mumbai is the right calling route for the social occasion of individuals to put in unprecedented demand in the slanting stage.\nCourse Overview\nData Analytics Training makes the gathering of spectators utilize aptitudes from major to front line level in each and every module to comprehend all the business challenges. Affirmation is passed on to the wannabes toward the complete of Big Data Analytics Course that puts in exceptional demand to secure a work in reputed associations.\nFeatures\n\u2022 Division and Clustering\n\u2022 Display Building and Validation\n\u2022 Machine Learning: Unsupervised Learning\n\u2022 Characterization Models\n\u2022 Making an Analytical Dataset\n\u2022 Feel straightforwardness to arrive a position\nWhat will you understand in this course?\nInterminable supply of Big data Hadoop training in Mumbai, hopefuls will lay a magnificent charge over each and every module to go up against genuine challenges.\n\u2022 Deploying of Data Analysis Life cycle to address gigantic data examination wanders\n\u2022 Reframing of business challenges as a demonstrative test\n\u2022 Enhances capacities in various coherent strategies and mechanical assemblies to dismember enormous data and arrangement of quantifiable models and perceiving of bits of learning that can incite huge results\nSAS Training in Pune, the course stays for quantifiable examination structure, which is an item game plan used for front line examination inside the work put. It is moreover used for data organization game plans, business learning, judicious examination and that is only the start. It can be an important gadget to empower you to manage your data more feasibly and to empower you to build up your business later on.\nAccording to the present market circumstance, the void of data specialist fulfills with each passing day. However in the meantime, associations scan for the proficient data specialists as the stock system of understudies from this master course limits after a particular point in time. In any case, foundations that give these courses guarantee position straightforwardly after the course gets over. You require not scan for any movement consultancy firm to get a game plan. Associations search for you straightforwardly after you get the confirmation from the establishments.\n"
  },
  {
    "title": "Ascent of data Science, SAS and Big data Analyst Trainings Programs",
    "content": "Ascent of data Science, SAS and Big data Analyst Trainings Programs\n\nVarious associations in the present days are opening entryways for huge information. So as to open the power, Data Science Training in Mumbai assumes an irreplaceable part. They have the capacity of driving a plenty of data which exists inside the foundation. An Data Science researcher is helpful with regards to dissecting and preparing information.\nA Data Scientist who has an accomplished in the business will fill in as vital accomplice and confided in counselor in the administration of a business association and ensure that the workers upgrade the examination abilities of their own. An information science courses in pune assumes an irreplaceable part in the correspondence and exhibit of the estimation of the investigation of a foundation for the encouraging ad libbed method of taking choices crosswise over various phases of a business through following, estimating and additionally recording distinctive execution measurements.\nFor what motivation to pick Big Data Analytics?\nThis Big Data Analytics takes various arranged parts and distinctive capacities that make a motivation from data. Information science preparing in Mumbai is the right calling route for the social occasion of individuals to put in unprecedented demand in the slanting stage.\nCourse Overview\nData Analytics Training makes the gathering of spectators utilize aptitudes from major to front line level in each and every module to comprehend all the business challenges. Affirmation is passed on to the wannabes toward the complete of Big Data Analytics Course that puts in exceptional demand to secure a work in reputed associations.\nFeatures\n\u2022 Division and Clustering\n\u2022 Display Building and Validation\n\u2022 Machine Learning: Unsupervised Learning\n\u2022 Characterization Models\n\u2022 Making an Analytical Dataset\n\u2022 Feel straightforwardness to arrive a position\nWhat will you understand in this course?\nInterminable supply of Big data Hadoop training in Mumbai, hopefuls will lay a magnificent charge over each and every module to go up against genuine challenges.\n\u2022 Deploying of Data Analysis Life cycle to address gigantic data examination wanders\n\u2022 Reframing of business challenges as a demonstrative test\n\u2022 Enhances capacities in various coherent strategies and mechanical assemblies to dismember enormous data and arrangement of quantifiable models and perceiving of bits of learning that can incite huge results\nSAS Training in Pune, the course stays for quantifiable examination structure, which is an item game plan used for front line examination inside the work put. It is moreover used for data organization game plans, business learning, judicious examination and that is only the start. It can be an important gadget to empower you to manage your data more feasibly and to empower you to build up your business later on.\nAccording to the present market circumstance, the void of data specialist fulfills with each passing day. However in the meantime, associations scan for the proficient data specialists as the stock system of understudies from this master course limits after a particular point in time. In any case, foundations that give these courses guarantee position straightforwardly after the course gets over. You require not scan for any movement consultancy firm to get a game plan. Associations search for you straightforwardly after you get the confirmation from the establishments.\n"
  },
  {
    "title": "Ascent of data Science, SAS and Big data Analyst Trainings Programs",
    "content": "Ascent of data Science, SAS and Big data Analyst Trainings Programs\n\nVarious associations in the present days are opening entryways for huge information. So as to open the power, Data Science Training in Mumbai assumes an irreplaceable part. They have the capacity of driving a plenty of data which exists inside the foundation. An Data Science researcher is helpful with regards to dissecting and preparing information.\nA Data Scientist who has an accomplished in the business will fill in as vital accomplice and confided in counselor in the administration of a business association and ensure that the workers upgrade the examination abilities of their own. An information science courses in pune assumes an irreplaceable part in the correspondence and exhibit of the estimation of the investigation of a foundation for the encouraging ad libbed method of taking choices crosswise over various phases of a business through following, estimating and additionally recording distinctive execution measurements.\nFor what motivation to pick Big Data Analytics?\nThis Big Data Analytics takes various arranged parts and distinctive capacities that make a motivation from data. Information science preparing in Mumbai is the right calling route for the social occasion of individuals to put in unprecedented demand in the slanting stage.\nCourse Overview\nData Analytics Training makes the gathering of spectators utilize aptitudes from major to front line level in each and every module to comprehend all the business challenges. Affirmation is passed on to the wannabes toward the complete of Big Data Analytics Course that puts in exceptional demand to secure a work in reputed associations.\nFeatures\n\u2022 Division and Clustering\n\u2022 Display Building and Validation\n\u2022 Machine Learning: Unsupervised Learning\n\u2022 Characterization Models\n\u2022 Making an Analytical Dataset\n\u2022 Feel straightforwardness to arrive a position\nWhat will you understand in this course?\nInterminable supply of Big data Hadoop training in Mumbai, hopefuls will lay a magnificent charge over each and every module to go up against genuine challenges.\n\u2022 Deploying of Data Analysis Life cycle to address gigantic data examination wanders\n\u2022 Reframing of business challenges as a demonstrative test\n\u2022 Enhances capacities in various coherent strategies and mechanical assemblies to dismember enormous data and arrangement of quantifiable models and perceiving of bits of learning that can incite huge results\nSAS Training in Pune, the course stays for quantifiable examination structure, which is an item game plan used for front line examination inside the work put. It is moreover used for data organization game plans, business learning, judicious examination and that is only the start. It can be an important gadget to empower you to manage your data more feasibly and to empower you to build up your business later on.\nAccording to the present market circumstance, the void of data specialist fulfills with each passing day. However in the meantime, associations scan for the proficient data specialists as the stock system of understudies from this master course limits after a particular point in time. In any case, foundations that give these courses guarantee position straightforwardly after the course gets over. You require not scan for any movement consultancy firm to get a game plan. Associations search for you straightforwardly after you get the confirmation from the establishments.\n"
  },
  {
    "title": "Can a robot love us better than another human can?",
    "content": "Can a robot love us better than another human can?\n\nI discussed this with Michelle Tsng on my Podcast \u201cCrazy Wisdom\u201d.\nShe says that a robot can love us better than a human being because there is no judgement. Human beings, particularly ones who have been traumatized can subconsciously detect when someone is judging them. They know when to keep their true feelings hidden from people who judge them and thus the best guide they can find is someone who can withhold judgmental thoughts and just express a safe, warm, and loving connection.\nAs robots become more sophisticated they might be able to provide this loving and warm connection. In this audio clip, Michelle discusses her experiences talking with Sofia, a robotic companion to human beings. She says that soon we will build robots who are better at love than humans are.\nWhat do you think? Would you ever feel comfortable sharing your most intimate experiences or seeking therapeutic treatment from a robot?\nYou can check out the full interview on my website.\n"
  },
  {
    "title": "Can a robot love us better than another human can?",
    "content": "Can a robot love us better than another human can?\n\nI discussed this with Michelle Tsng on my Podcast \u201cCrazy Wisdom\u201d.\nShe says that a robot can love us better than a human being because there is no judgement. Human beings, particularly ones who have been traumatized can subconsciously detect when someone is judging them. They know when to keep their true feelings hidden from people who judge them and thus the best guide they can find is someone who can withhold judgmental thoughts and just express a safe, warm, and loving connection.\nAs robots become more sophisticated they might be able to provide this loving and warm connection. In this audio clip, Michelle discusses her experiences talking with Sofia, a robotic companion to human beings. She says that soon we will build robots who are better at love than humans are.\nWhat do you think? Would you ever feel comfortable sharing your most intimate experiences or seeking therapeutic treatment from a robot?\nYou can check out the full interview on my website.\n"
  },
  {
    "title": "Can a robot love us better than another human can?",
    "content": "Can a robot love us better than another human can?\n\nI discussed this with Michelle Tsng on my Podcast \u201cCrazy Wisdom\u201d.\nShe says that a robot can love us better than a human being because there is no judgement. Human beings, particularly ones who have been traumatized can subconsciously detect when someone is judging them. They know when to keep their true feelings hidden from people who judge them and thus the best guide they can find is someone who can withhold judgmental thoughts and just express a safe, warm, and loving connection.\nAs robots become more sophisticated they might be able to provide this loving and warm connection. In this audio clip, Michelle discusses her experiences talking with Sofia, a robotic companion to human beings. She says that soon we will build robots who are better at love than humans are.\nWhat do you think? Would you ever feel comfortable sharing your most intimate experiences or seeking therapeutic treatment from a robot?\nYou can check out the full interview on my website.\n"
  },
  {
    "title": "Can a robot love us better than another human can?",
    "content": "Can a robot love us better than another human can?\n\nI discussed this with Michelle Tsng on my Podcast \u201cCrazy Wisdom\u201d.\nShe says that a robot can love us better than a human being because there is no judgement. Human beings, particularly ones who have been traumatized can subconsciously detect when someone is judging them. They know when to keep their true feelings hidden from people who judge them and thus the best guide they can find is someone who can withhold judgmental thoughts and just express a safe, warm, and loving connection.\nAs robots become more sophisticated they might be able to provide this loving and warm connection. In this audio clip, Michelle discusses her experiences talking with Sofia, a robotic companion to human beings. She says that soon we will build robots who are better at love than humans are.\nWhat do you think? Would you ever feel comfortable sharing your most intimate experiences or seeking therapeutic treatment from a robot?\nYou can check out the full interview on my website.\n"
  },
  {
    "title": "Can a robot love us better than another human can?",
    "content": "Can a robot love us better than another human can?\n\nI discussed this with Michelle Tsng on my Podcast \u201cCrazy Wisdom\u201d.\nShe says that a robot can love us better than a human being because there is no judgement. Human beings, particularly ones who have been traumatized can subconsciously detect when someone is judging them. They know when to keep their true feelings hidden from people who judge them and thus the best guide they can find is someone who can withhold judgmental thoughts and just express a safe, warm, and loving connection.\nAs robots become more sophisticated they might be able to provide this loving and warm connection. In this audio clip, Michelle discusses her experiences talking with Sofia, a robotic companion to human beings. She says that soon we will build robots who are better at love than humans are.\nWhat do you think? Would you ever feel comfortable sharing your most intimate experiences or seeking therapeutic treatment from a robot?\nYou can check out the full interview on my website.\n"
  },
  {
    "title": "2017 Big Data, AI and IOT Use Cases",
    "content": "2017 Big Data, AI and IOT Use Cases\nAn Active List of Interesting Use Cases Mentioned In Class\nImage Source: Randstad Article\nI\u2019ve heard more use cases of Big Data in the last 10 days, than ever before. Therefore, I\u2019ve decided to start a post where I compiled all the examples \u2014 with additional sources for all of us to learn more about them. I plan on updating this on a daily/weekly basis \u2014 so please follow me to stay on the loop.\nThe Big Data Professors at IE are all working professionals or researchers in the field, so they use countless examples to show us how the concepts taught in class are being applied in the real world.\nUse cases will be divided by \u201cfunction\u201d, but you can expect to see examples of big companies, startups, NGOS, and individuals. The focus is to understand not just the impact, but also the Ripple Effect of AI and IOT innovations.\nIf you have any use cases that should be added, additional resources, or observations feel free to comment below. I want this to be a reference guide for all!\nUse Cases were last updated on: October 30, 2017\n>> Solving the Water Scarcity Problem\nThe UN predicts that half the world\u2019s population will live in a water-stressed area by 2030. Therefore, private and public organizations are coming together to find solutions. Due to the improvement of network connectivity and accuracy of sensors, the challenge seems like an addressable one.Whether it is in major cities like San Francisco, or developing countries like Africa, smart sensors are being installed in water wells and pumps in order to track its quality and quantity. Equitable Allocation of clean water is the main priority for the next decades. It is proven that every $1 spent on water and sanitation generates $8 as a result of saved time, increased productivity and reduced healthcare costs.The current complexity of water systems and budget limitations are the largest obstacle to faster adoption of smart water meters.\nLearn more:\nWPDx | The Water Point Data Exchange is the global platform for sharing water point data\nThe amount of water point data being collected is growing rapidly as governments and development partners increasingly\u2026www.waterpointdata.org\nAccess to data could be vital in addressing the global water crisis\nTwo hundred miles from the nearest town, a farmer in Tanzania picks up his phone and notices an alert. Thanks to an app\u2026www.theguardian.com\nThe Internet of everything water\nImagine a world where your spice cabinet reminds you to buy salt, or your cell phone sends a text message about the\u2026www.un.org\n>> Detecting Defective Genomes & Saving Lives\nDeep Genomics is leveraging artificial intelligence, specifically deep learning to help decode the meaning of the genome. Their learning software is developing the ability to try and predict the effects of a particular mutation based on its analyses of hundreds of thousands of examples of other mutations; even if there\u2019s not already a record of what those mutations do. So far, Deep Genomics has used their computational system to develop a database that provides predictions for how more than 300 million genetic variations could affect a genetic code. For this reason, their findings are used for genome-based therapeutic development, molecular diagnostics, targeting biomarker discovery and assessing risks for genetic disorders.\nLearn More:\nCompany\nTHE NEXT-FRONTIER GENETIC MEDICINE COMPANY Our mission at Deep Genomics is to create a new universe of life-saving\u2026www.deepgenomics.com\nTop Artificial Intelligence Companies in Healthcare to Keep an Eye On - The Medical Futurist\nNo one doubts that artificial intelligence has unimaginable potential. Within the next couple of years, it will\u2026medicalfuturist.com\n>> Training Neurons to Detect Bombs\nAll of the big tech firms, from Google to Microsoft, are rushing to create artificial intelligence modelled on the human brain. Mr Agabi is attempting to reverse-engineer biology and emphasizes how \u201cour deep learning networks are all copying the brain\u2026you can give the neurons instructions about what to do \u2014 in our case we tell it to provide a receptor that can detect explosives.\u201d He launched his start-up Koniku over a year ago, has raised $1m (\u00a3800,000) in funding and claims it is already making profits of $10m in deals with the security industry.\nLearn More:\nThe man teaching a computer to smell\nNigerian Oshi Agabi has unveiled a computer based not on silicon but on mice neurons at the TEDGlobal conference in\u2026www.bbc.com\n>> Influencing Elections\nOn November 9, it became clear what Big Data can do. The company behind Trump\u2019s online campaign \u2014 the same company that had worked for Leave.EU in the very early stages of its \u201cBrexit\u201d campaign \u2014 was a Big Data company: Cambridge Analytica. \u201cPretty much every message that Trump put out was data-driven,\u201d says Cambridge Analytica CEO Alexander Nix\nLearn More:\nThe Data That Turned the World Upside Down\nOn November 9 at around 8.30 AM., Michal Kosinski woke up in the Hotel Sunnehus in Zurich. The 34-year-old researcher\u2026motherboard.vice.com\n>> Saving Billions in Energy Costs\nThe General Services Administration, for example, has found a way to save $13 million a year in energy costs across 180 buildings \u2014 all thanks to a proprietary algorithm developed and monitored from many states away, in Massachusetts. Among the problems discovered: malfunctioning exhaust fans. Much of the leaps in energy efficiency are possible due to the widespread adoption of networked and highly sophisticated energy meters around the country over the last 10 years. Energy meters used to be checked onsite once a month, generating 12 basic data points a year, read and logged by humans. Now, meters register a raft of data every 15 minutes, accessible anywhere remotely, generating 36,000 data points a year.\nLearn More:\n'Big data' is solving the problem of $200 billion of wasted energy\nAt its best, technology is able to tackle huge problems with remarkable ease. The General Services Administration, for\u2026www.businessinsider.com\n>> Predict Wealth from Space\nPenny is a free tool built using high-resolution imagery from DigitalGlobe, income data from the US census, neural network expertise from Carnegie Mellon and intuitive visualizations from Stamen Design. It\u2019s a virtual cityscape (for New York City and St. Louis, so far), where AI has been trained to recognize patterns of neighborhood wealth (trees, parking lots, brownstones and freeways) by correlating census data with satellite imagery. You don\u2019t just extract information from this tool though, click on the link below and drop a grove of trees into the middle of Harlem to see the neighborhoods virtual income level rise or fall. What is impressive about this tool is that it doesn't just look at the urban features you add, it\u2019s the features and the context into which they\u2019re placed that matters.\nLearn More:\nMeet Penny, an AI to predict wealth from space\nPenny is a simple tool to help us understand what wealth and poverty look like to an artificial intelligence built on\u2026penny.digitalglobe.com\nWhat is Penny?\nA technical guide for the busy CEO\nNEEDS EDITING & CLEANUP, ERIC WORKING ON IThi.stamen.com\n>> Justifying Billboard Pricing\nOutdoor marketing company Route is using big data to define and justify its pricing model for advertising space on billboards, benches and the sides of busses. Traditionally, outdoor media pricing was priced \u201cper impression\u201d based on an estimate of how many eyes would see the ad in a given day. No more! Now they\u2019re using sophisticated GPS, eye-tracking software, and analysis of traffic patterns to have a much more realistic idea of which advertisements will be seen the most \u2014 and therefore be the most effective.\nLearn More:\nHow big data is changing outdoor media\nSeeing an ad outdoors has a greater impact on us than one served to our laptop or phone. We come across it, 'discover\u2026econsultancy.com\n>> Turning Neighborhoods into Farmers Markets\nFalling Fruit\u00b4s stated goal is to remind urban people that agriculture and natural foods do exist in the city \u2014but that you might just have to access a website to find it. It combined public information from the U.S. Department of Agriculture, municipal tree inventories, foraging maps and street tree databases to provide an interactive map to tell you where the trees in your neighborhood might be dropping fruit.\nLearn More:\nFalling Fruit\nA massive, collaborative map of the urban harvest uniting the efforts of foragers, freegans, and foresters around the\u2026fallingfruit.org\n>> Rescue you from under the snow\nSki resorts are even getting into the data game. RFID tags inserted into lift tickets can help optimize operations, collect data on skier performance, personalize offerings to customers, and gamifying the experience. In many cases though, the technology is being used to identify the individual movements of the skiers that get lost.\nLearn More:\nEven Ski Resorts Are Benefiting From The Big Data Explosion | Articles | Big Data\nEven Ski Resorts are Benefiting From the Big Data Explosionchannels.theinnovationenterprise.com\n>> Find Lost Relatives\nConsider the millions of Ancestry family trees. How valuable would it be to link to those trees via DNA? You\u2019d be able to determine genetic connections and uncover new family lines, deep relationships, and insights like you never have before. The first thing Ancestry.com does with your autosomal test results is compare them with other DNA samples on their database to look for family matches. They compare the over 700,000 markers examined on your genome to every other person in their database. The more markers you share in common with another person, the more likely you are to be related. The probable relationship between any two people is calculated based on the percentage of markers they have in common. Next, they sort the matches by relationship and send you a list of your DNA family.\nLearn More:\nAncestryDNA\u2122 | Learn How DNA Tests Work & More\nLearn more about the science and technology behind our most advanced DNA test at AncestryDNA\u2122.www.ancestry.com\n>> Financial Inclusion in Africa\nAnalysis of mobile phone data can help increase subscribers\u2019 use of banking services, boosting their economic resilience and inclusion.\nLearn More:\nhttps://olc.worldbank.org/sites/default/files/WBG_BD_CS_FinancialInclusion_0.pdf\nTo be Continued\u2026\nIf you learned something new about Big Data from this guide, please share it with your friends. It is up to us to encourage people to join this field, and be part of building the future.\nSpeaking of which, I\u2019d love to hear from you. Reach out to me on Linkedin or email at melodyannucros@gmail.com\u2709\ufe0f .\n#bigdata #ai #iot #machinelearning #startups #digitaltransformations #impact #agile #newworld #graduateprogram #sharingknowledge\n\nAuthor: Melody Ann Ucros\nI\u2019m a Masters in Big Data & Business Analytics Candidate @ IEBusinessSchool, and an Entrepreneurship Evangelist wherever I go. Oh, and I love chocolate! \u2026 Follow Me \u2764\n"
  },
  {
    "title": "2017 Big Data, AI and IOT Use Cases",
    "content": "2017 Big Data, AI and IOT Use Cases\nAn Active List of Interesting Use Cases Mentioned In Class\nImage Source: Randstad Article\nI\u2019ve heard more use cases of Big Data in the last 10 days, than ever before. Therefore, I\u2019ve decided to start a post where I compiled all the examples \u2014 with additional sources for all of us to learn more about them. I plan on updating this on a daily/weekly basis \u2014 so please follow me to stay on the loop.\nThe Big Data Professors at IE are all working professionals or researchers in the field, so they use countless examples to show us how the concepts taught in class are being applied in the real world.\nUse cases will be divided by \u201cfunction\u201d, but you can expect to see examples of big companies, startups, NGOS, and individuals. The focus is to understand not just the impact, but also the Ripple Effect of AI and IOT innovations.\nIf you have any use cases that should be added, additional resources, or observations feel free to comment below. I want this to be a reference guide for all!\nUse Cases were last updated on: October 30, 2017\n>> Solving the Water Scarcity Problem\nThe UN predicts that half the world\u2019s population will live in a water-stressed area by 2030. Therefore, private and public organizations are coming together to find solutions. Due to the improvement of network connectivity and accuracy of sensors, the challenge seems like an addressable one.Whether it is in major cities like San Francisco, or developing countries like Africa, smart sensors are being installed in water wells and pumps in order to track its quality and quantity. Equitable Allocation of clean water is the main priority for the next decades. It is proven that every $1 spent on water and sanitation generates $8 as a result of saved time, increased productivity and reduced healthcare costs.The current complexity of water systems and budget limitations are the largest obstacle to faster adoption of smart water meters.\nLearn more:\nWPDx | The Water Point Data Exchange is the global platform for sharing water point data\nThe amount of water point data being collected is growing rapidly as governments and development partners increasingly\u2026www.waterpointdata.org\nAccess to data could be vital in addressing the global water crisis\nTwo hundred miles from the nearest town, a farmer in Tanzania picks up his phone and notices an alert. Thanks to an app\u2026www.theguardian.com\nThe Internet of everything water\nImagine a world where your spice cabinet reminds you to buy salt, or your cell phone sends a text message about the\u2026www.un.org\n>> Detecting Defective Genomes & Saving Lives\nDeep Genomics is leveraging artificial intelligence, specifically deep learning to help decode the meaning of the genome. Their learning software is developing the ability to try and predict the effects of a particular mutation based on its analyses of hundreds of thousands of examples of other mutations; even if there\u2019s not already a record of what those mutations do. So far, Deep Genomics has used their computational system to develop a database that provides predictions for how more than 300 million genetic variations could affect a genetic code. For this reason, their findings are used for genome-based therapeutic development, molecular diagnostics, targeting biomarker discovery and assessing risks for genetic disorders.\nLearn More:\nCompany\nTHE NEXT-FRONTIER GENETIC MEDICINE COMPANY Our mission at Deep Genomics is to create a new universe of life-saving\u2026www.deepgenomics.com\nTop Artificial Intelligence Companies in Healthcare to Keep an Eye On - The Medical Futurist\nNo one doubts that artificial intelligence has unimaginable potential. Within the next couple of years, it will\u2026medicalfuturist.com\n>> Training Neurons to Detect Bombs\nAll of the big tech firms, from Google to Microsoft, are rushing to create artificial intelligence modelled on the human brain. Mr Agabi is attempting to reverse-engineer biology and emphasizes how \u201cour deep learning networks are all copying the brain\u2026you can give the neurons instructions about what to do \u2014 in our case we tell it to provide a receptor that can detect explosives.\u201d He launched his start-up Koniku over a year ago, has raised $1m (\u00a3800,000) in funding and claims it is already making profits of $10m in deals with the security industry.\nLearn More:\nThe man teaching a computer to smell\nNigerian Oshi Agabi has unveiled a computer based not on silicon but on mice neurons at the TEDGlobal conference in\u2026www.bbc.com\n>> Influencing Elections\nOn November 9, it became clear what Big Data can do. The company behind Trump\u2019s online campaign \u2014 the same company that had worked for Leave.EU in the very early stages of its \u201cBrexit\u201d campaign \u2014 was a Big Data company: Cambridge Analytica. \u201cPretty much every message that Trump put out was data-driven,\u201d says Cambridge Analytica CEO Alexander Nix\nLearn More:\nThe Data That Turned the World Upside Down\nOn November 9 at around 8.30 AM., Michal Kosinski woke up in the Hotel Sunnehus in Zurich. The 34-year-old researcher\u2026motherboard.vice.com\n>> Saving Billions in Energy Costs\nThe General Services Administration, for example, has found a way to save $13 million a year in energy costs across 180 buildings \u2014 all thanks to a proprietary algorithm developed and monitored from many states away, in Massachusetts. Among the problems discovered: malfunctioning exhaust fans. Much of the leaps in energy efficiency are possible due to the widespread adoption of networked and highly sophisticated energy meters around the country over the last 10 years. Energy meters used to be checked onsite once a month, generating 12 basic data points a year, read and logged by humans. Now, meters register a raft of data every 15 minutes, accessible anywhere remotely, generating 36,000 data points a year.\nLearn More:\n'Big data' is solving the problem of $200 billion of wasted energy\nAt its best, technology is able to tackle huge problems with remarkable ease. The General Services Administration, for\u2026www.businessinsider.com\n>> Predict Wealth from Space\nPenny is a free tool built using high-resolution imagery from DigitalGlobe, income data from the US census, neural network expertise from Carnegie Mellon and intuitive visualizations from Stamen Design. It\u2019s a virtual cityscape (for New York City and St. Louis, so far), where AI has been trained to recognize patterns of neighborhood wealth (trees, parking lots, brownstones and freeways) by correlating census data with satellite imagery. You don\u2019t just extract information from this tool though, click on the link below and drop a grove of trees into the middle of Harlem to see the neighborhoods virtual income level rise or fall. What is impressive about this tool is that it doesn't just look at the urban features you add, it\u2019s the features and the context into which they\u2019re placed that matters.\nLearn More:\nMeet Penny, an AI to predict wealth from space\nPenny is a simple tool to help us understand what wealth and poverty look like to an artificial intelligence built on\u2026penny.digitalglobe.com\nWhat is Penny?\nA technical guide for the busy CEO\nNEEDS EDITING & CLEANUP, ERIC WORKING ON IThi.stamen.com\n>> Justifying Billboard Pricing\nOutdoor marketing company Route is using big data to define and justify its pricing model for advertising space on billboards, benches and the sides of busses. Traditionally, outdoor media pricing was priced \u201cper impression\u201d based on an estimate of how many eyes would see the ad in a given day. No more! Now they\u2019re using sophisticated GPS, eye-tracking software, and analysis of traffic patterns to have a much more realistic idea of which advertisements will be seen the most \u2014 and therefore be the most effective.\nLearn More:\nHow big data is changing outdoor media\nSeeing an ad outdoors has a greater impact on us than one served to our laptop or phone. We come across it, 'discover\u2026econsultancy.com\n>> Turning Neighborhoods into Farmers Markets\nFalling Fruit\u00b4s stated goal is to remind urban people that agriculture and natural foods do exist in the city \u2014but that you might just have to access a website to find it. It combined public information from the U.S. Department of Agriculture, municipal tree inventories, foraging maps and street tree databases to provide an interactive map to tell you where the trees in your neighborhood might be dropping fruit.\nLearn More:\nFalling Fruit\nA massive, collaborative map of the urban harvest uniting the efforts of foragers, freegans, and foresters around the\u2026fallingfruit.org\n>> Rescue you from under the snow\nSki resorts are even getting into the data game. RFID tags inserted into lift tickets can help optimize operations, collect data on skier performance, personalize offerings to customers, and gamifying the experience. In many cases though, the technology is being used to identify the individual movements of the skiers that get lost.\nLearn More:\nEven Ski Resorts Are Benefiting From The Big Data Explosion | Articles | Big Data\nEven Ski Resorts are Benefiting From the Big Data Explosionchannels.theinnovationenterprise.com\n>> Find Lost Relatives\nConsider the millions of Ancestry family trees. How valuable would it be to link to those trees via DNA? You\u2019d be able to determine genetic connections and uncover new family lines, deep relationships, and insights like you never have before. The first thing Ancestry.com does with your autosomal test results is compare them with other DNA samples on their database to look for family matches. They compare the over 700,000 markers examined on your genome to every other person in their database. The more markers you share in common with another person, the more likely you are to be related. The probable relationship between any two people is calculated based on the percentage of markers they have in common. Next, they sort the matches by relationship and send you a list of your DNA family.\nLearn More:\nAncestryDNA\u2122 | Learn How DNA Tests Work & More\nLearn more about the science and technology behind our most advanced DNA test at AncestryDNA\u2122.www.ancestry.com\n>> Financial Inclusion in Africa\nAnalysis of mobile phone data can help increase subscribers\u2019 use of banking services, boosting their economic resilience and inclusion.\nLearn More:\nhttps://olc.worldbank.org/sites/default/files/WBG_BD_CS_FinancialInclusion_0.pdf\nTo be Continued\u2026\nIf you learned something new about Big Data from this guide, please share it with your friends. It is up to us to encourage people to join this field, and be part of building the future.\nSpeaking of which, I\u2019d love to hear from you. Reach out to me on Linkedin or email at melodyannucros@gmail.com\u2709\ufe0f .\n#bigdata #ai #iot #machinelearning #startups #digitaltransformations #impact #agile #newworld #graduateprogram #sharingknowledge\n\nAuthor: Melody Ann Ucros\nI\u2019m a Masters in Big Data & Business Analytics Candidate @ IEBusinessSchool, and an Entrepreneurship Evangelist wherever I go. Oh, and I love chocolate! \u2026 Follow Me \u2764\n"
  },
  {
    "title": "2017 Big Data, AI and IOT Use Cases",
    "content": "2017 Big Data, AI and IOT Use Cases\nAn Active List of Interesting Use Cases Mentioned In Class\nImage Source: Randstad Article\nI\u2019ve heard more use cases of Big Data in the last 10 days, than ever before. Therefore, I\u2019ve decided to start a post where I compiled all the examples \u2014 with additional sources for all of us to learn more about them. I plan on updating this on a daily/weekly basis \u2014 so please follow me to stay on the loop.\nThe Big Data Professors at IE are all working professionals or researchers in the field, so they use countless examples to show us how the concepts taught in class are being applied in the real world.\nUse cases will be divided by \u201cfunction\u201d, but you can expect to see examples of big companies, startups, NGOS, and individuals. The focus is to understand not just the impact, but also the Ripple Effect of AI and IOT innovations.\nIf you have any use cases that should be added, additional resources, or observations feel free to comment below. I want this to be a reference guide for all!\nUse Cases were last updated on: October 30, 2017\n>> Solving the Water Scarcity Problem\nThe UN predicts that half the world\u2019s population will live in a water-stressed area by 2030. Therefore, private and public organizations are coming together to find solutions. Due to the improvement of network connectivity and accuracy of sensors, the challenge seems like an addressable one.Whether it is in major cities like San Francisco, or developing countries like Africa, smart sensors are being installed in water wells and pumps in order to track its quality and quantity. Equitable Allocation of clean water is the main priority for the next decades. It is proven that every $1 spent on water and sanitation generates $8 as a result of saved time, increased productivity and reduced healthcare costs.The current complexity of water systems and budget limitations are the largest obstacle to faster adoption of smart water meters.\nLearn more:\nWPDx | The Water Point Data Exchange is the global platform for sharing water point data\nThe amount of water point data being collected is growing rapidly as governments and development partners increasingly\u2026www.waterpointdata.org\nAccess to data could be vital in addressing the global water crisis\nTwo hundred miles from the nearest town, a farmer in Tanzania picks up his phone and notices an alert. Thanks to an app\u2026www.theguardian.com\nThe Internet of everything water\nImagine a world where your spice cabinet reminds you to buy salt, or your cell phone sends a text message about the\u2026www.un.org\n>> Detecting Defective Genomes & Saving Lives\nDeep Genomics is leveraging artificial intelligence, specifically deep learning to help decode the meaning of the genome. Their learning software is developing the ability to try and predict the effects of a particular mutation based on its analyses of hundreds of thousands of examples of other mutations; even if there\u2019s not already a record of what those mutations do. So far, Deep Genomics has used their computational system to develop a database that provides predictions for how more than 300 million genetic variations could affect a genetic code. For this reason, their findings are used for genome-based therapeutic development, molecular diagnostics, targeting biomarker discovery and assessing risks for genetic disorders.\nLearn More:\nCompany\nTHE NEXT-FRONTIER GENETIC MEDICINE COMPANY Our mission at Deep Genomics is to create a new universe of life-saving\u2026www.deepgenomics.com\nTop Artificial Intelligence Companies in Healthcare to Keep an Eye On - The Medical Futurist\nNo one doubts that artificial intelligence has unimaginable potential. Within the next couple of years, it will\u2026medicalfuturist.com\n>> Training Neurons to Detect Bombs\nAll of the big tech firms, from Google to Microsoft, are rushing to create artificial intelligence modelled on the human brain. Mr Agabi is attempting to reverse-engineer biology and emphasizes how \u201cour deep learning networks are all copying the brain\u2026you can give the neurons instructions about what to do \u2014 in our case we tell it to provide a receptor that can detect explosives.\u201d He launched his start-up Koniku over a year ago, has raised $1m (\u00a3800,000) in funding and claims it is already making profits of $10m in deals with the security industry.\nLearn More:\nThe man teaching a computer to smell\nNigerian Oshi Agabi has unveiled a computer based not on silicon but on mice neurons at the TEDGlobal conference in\u2026www.bbc.com\n>> Influencing Elections\nOn November 9, it became clear what Big Data can do. The company behind Trump\u2019s online campaign \u2014 the same company that had worked for Leave.EU in the very early stages of its \u201cBrexit\u201d campaign \u2014 was a Big Data company: Cambridge Analytica. \u201cPretty much every message that Trump put out was data-driven,\u201d says Cambridge Analytica CEO Alexander Nix\nLearn More:\nThe Data That Turned the World Upside Down\nOn November 9 at around 8.30 AM., Michal Kosinski woke up in the Hotel Sunnehus in Zurich. The 34-year-old researcher\u2026motherboard.vice.com\n>> Saving Billions in Energy Costs\nThe General Services Administration, for example, has found a way to save $13 million a year in energy costs across 180 buildings \u2014 all thanks to a proprietary algorithm developed and monitored from many states away, in Massachusetts. Among the problems discovered: malfunctioning exhaust fans. Much of the leaps in energy efficiency are possible due to the widespread adoption of networked and highly sophisticated energy meters around the country over the last 10 years. Energy meters used to be checked onsite once a month, generating 12 basic data points a year, read and logged by humans. Now, meters register a raft of data every 15 minutes, accessible anywhere remotely, generating 36,000 data points a year.\nLearn More:\n'Big data' is solving the problem of $200 billion of wasted energy\nAt its best, technology is able to tackle huge problems with remarkable ease. The General Services Administration, for\u2026www.businessinsider.com\n>> Predict Wealth from Space\nPenny is a free tool built using high-resolution imagery from DigitalGlobe, income data from the US census, neural network expertise from Carnegie Mellon and intuitive visualizations from Stamen Design. It\u2019s a virtual cityscape (for New York City and St. Louis, so far), where AI has been trained to recognize patterns of neighborhood wealth (trees, parking lots, brownstones and freeways) by correlating census data with satellite imagery. You don\u2019t just extract information from this tool though, click on the link below and drop a grove of trees into the middle of Harlem to see the neighborhoods virtual income level rise or fall. What is impressive about this tool is that it doesn't just look at the urban features you add, it\u2019s the features and the context into which they\u2019re placed that matters.\nLearn More:\nMeet Penny, an AI to predict wealth from space\nPenny is a simple tool to help us understand what wealth and poverty look like to an artificial intelligence built on\u2026penny.digitalglobe.com\nWhat is Penny?\nA technical guide for the busy CEO\nNEEDS EDITING & CLEANUP, ERIC WORKING ON IThi.stamen.com\n>> Justifying Billboard Pricing\nOutdoor marketing company Route is using big data to define and justify its pricing model for advertising space on billboards, benches and the sides of busses. Traditionally, outdoor media pricing was priced \u201cper impression\u201d based on an estimate of how many eyes would see the ad in a given day. No more! Now they\u2019re using sophisticated GPS, eye-tracking software, and analysis of traffic patterns to have a much more realistic idea of which advertisements will be seen the most \u2014 and therefore be the most effective.\nLearn More:\nHow big data is changing outdoor media\nSeeing an ad outdoors has a greater impact on us than one served to our laptop or phone. We come across it, 'discover\u2026econsultancy.com\n>> Turning Neighborhoods into Farmers Markets\nFalling Fruit\u00b4s stated goal is to remind urban people that agriculture and natural foods do exist in the city \u2014but that you might just have to access a website to find it. It combined public information from the U.S. Department of Agriculture, municipal tree inventories, foraging maps and street tree databases to provide an interactive map to tell you where the trees in your neighborhood might be dropping fruit.\nLearn More:\nFalling Fruit\nA massive, collaborative map of the urban harvest uniting the efforts of foragers, freegans, and foresters around the\u2026fallingfruit.org\n>> Rescue you from under the snow\nSki resorts are even getting into the data game. RFID tags inserted into lift tickets can help optimize operations, collect data on skier performance, personalize offerings to customers, and gamifying the experience. In many cases though, the technology is being used to identify the individual movements of the skiers that get lost.\nLearn More:\nEven Ski Resorts Are Benefiting From The Big Data Explosion | Articles | Big Data\nEven Ski Resorts are Benefiting From the Big Data Explosionchannels.theinnovationenterprise.com\n>> Find Lost Relatives\nConsider the millions of Ancestry family trees. How valuable would it be to link to those trees via DNA? You\u2019d be able to determine genetic connections and uncover new family lines, deep relationships, and insights like you never have before. The first thing Ancestry.com does with your autosomal test results is compare them with other DNA samples on their database to look for family matches. They compare the over 700,000 markers examined on your genome to every other person in their database. The more markers you share in common with another person, the more likely you are to be related. The probable relationship between any two people is calculated based on the percentage of markers they have in common. Next, they sort the matches by relationship and send you a list of your DNA family.\nLearn More:\nAncestryDNA\u2122 | Learn How DNA Tests Work & More\nLearn more about the science and technology behind our most advanced DNA test at AncestryDNA\u2122.www.ancestry.com\n>> Financial Inclusion in Africa\nAnalysis of mobile phone data can help increase subscribers\u2019 use of banking services, boosting their economic resilience and inclusion.\nLearn More:\nhttps://olc.worldbank.org/sites/default/files/WBG_BD_CS_FinancialInclusion_0.pdf\nTo be Continued\u2026\nIf you learned something new about Big Data from this guide, please share it with your friends. It is up to us to encourage people to join this field, and be part of building the future.\nSpeaking of which, I\u2019d love to hear from you. Reach out to me on Linkedin or email at melodyannucros@gmail.com\u2709\ufe0f .\n#bigdata #ai #iot #machinelearning #startups #digitaltransformations #impact #agile #newworld #graduateprogram #sharingknowledge\n\nAuthor: Melody Ann Ucros\nI\u2019m a Masters in Big Data & Business Analytics Candidate @ IEBusinessSchool, and an Entrepreneurship Evangelist wherever I go. Oh, and I love chocolate! \u2026 Follow Me \u2764\n"
  },
  {
    "title": "2017 Big Data, AI and IOT Use Cases",
    "content": "2017 Big Data, AI and IOT Use Cases\nAn Active List of Interesting Use Cases Mentioned In Class\nImage Source: Randstad Article\nI\u2019ve heard more use cases of Big Data in the last 10 days, than ever before. Therefore, I\u2019ve decided to start a post where I compiled all the examples \u2014 with additional sources for all of us to learn more about them. I plan on updating this on a daily/weekly basis \u2014 so please follow me to stay on the loop.\nThe Big Data Professors at IE are all working professionals or researchers in the field, so they use countless examples to show us how the concepts taught in class are being applied in the real world.\nUse cases will be divided by \u201cfunction\u201d, but you can expect to see examples of big companies, startups, NGOS, and individuals. The focus is to understand not just the impact, but also the Ripple Effect of AI and IOT innovations.\nIf you have any use cases that should be added, additional resources, or observations feel free to comment below. I want this to be a reference guide for all!\nUse Cases were last updated on: October 30, 2017\n>> Solving the Water Scarcity Problem\nThe UN predicts that half the world\u2019s population will live in a water-stressed area by 2030. Therefore, private and public organizations are coming together to find solutions. Due to the improvement of network connectivity and accuracy of sensors, the challenge seems like an addressable one.Whether it is in major cities like San Francisco, or developing countries like Africa, smart sensors are being installed in water wells and pumps in order to track its quality and quantity. Equitable Allocation of clean water is the main priority for the next decades. It is proven that every $1 spent on water and sanitation generates $8 as a result of saved time, increased productivity and reduced healthcare costs.The current complexity of water systems and budget limitations are the largest obstacle to faster adoption of smart water meters.\nLearn more:\nWPDx | The Water Point Data Exchange is the global platform for sharing water point data\nThe amount of water point data being collected is growing rapidly as governments and development partners increasingly\u2026www.waterpointdata.org\nAccess to data could be vital in addressing the global water crisis\nTwo hundred miles from the nearest town, a farmer in Tanzania picks up his phone and notices an alert. Thanks to an app\u2026www.theguardian.com\nThe Internet of everything water\nImagine a world where your spice cabinet reminds you to buy salt, or your cell phone sends a text message about the\u2026www.un.org\n>> Detecting Defective Genomes & Saving Lives\nDeep Genomics is leveraging artificial intelligence, specifically deep learning to help decode the meaning of the genome. Their learning software is developing the ability to try and predict the effects of a particular mutation based on its analyses of hundreds of thousands of examples of other mutations; even if there\u2019s not already a record of what those mutations do. So far, Deep Genomics has used their computational system to develop a database that provides predictions for how more than 300 million genetic variations could affect a genetic code. For this reason, their findings are used for genome-based therapeutic development, molecular diagnostics, targeting biomarker discovery and assessing risks for genetic disorders.\nLearn More:\nCompany\nTHE NEXT-FRONTIER GENETIC MEDICINE COMPANY Our mission at Deep Genomics is to create a new universe of life-saving\u2026www.deepgenomics.com\nTop Artificial Intelligence Companies in Healthcare to Keep an Eye On - The Medical Futurist\nNo one doubts that artificial intelligence has unimaginable potential. Within the next couple of years, it will\u2026medicalfuturist.com\n>> Training Neurons to Detect Bombs\nAll of the big tech firms, from Google to Microsoft, are rushing to create artificial intelligence modelled on the human brain. Mr Agabi is attempting to reverse-engineer biology and emphasizes how \u201cour deep learning networks are all copying the brain\u2026you can give the neurons instructions about what to do \u2014 in our case we tell it to provide a receptor that can detect explosives.\u201d He launched his start-up Koniku over a year ago, has raised $1m (\u00a3800,000) in funding and claims it is already making profits of $10m in deals with the security industry.\nLearn More:\nThe man teaching a computer to smell\nNigerian Oshi Agabi has unveiled a computer based not on silicon but on mice neurons at the TEDGlobal conference in\u2026www.bbc.com\n>> Influencing Elections\nOn November 9, it became clear what Big Data can do. The company behind Trump\u2019s online campaign \u2014 the same company that had worked for Leave.EU in the very early stages of its \u201cBrexit\u201d campaign \u2014 was a Big Data company: Cambridge Analytica. \u201cPretty much every message that Trump put out was data-driven,\u201d says Cambridge Analytica CEO Alexander Nix\nLearn More:\nThe Data That Turned the World Upside Down\nOn November 9 at around 8.30 AM., Michal Kosinski woke up in the Hotel Sunnehus in Zurich. The 34-year-old researcher\u2026motherboard.vice.com\n>> Saving Billions in Energy Costs\nThe General Services Administration, for example, has found a way to save $13 million a year in energy costs across 180 buildings \u2014 all thanks to a proprietary algorithm developed and monitored from many states away, in Massachusetts. Among the problems discovered: malfunctioning exhaust fans. Much of the leaps in energy efficiency are possible due to the widespread adoption of networked and highly sophisticated energy meters around the country over the last 10 years. Energy meters used to be checked onsite once a month, generating 12 basic data points a year, read and logged by humans. Now, meters register a raft of data every 15 minutes, accessible anywhere remotely, generating 36,000 data points a year.\nLearn More:\n'Big data' is solving the problem of $200 billion of wasted energy\nAt its best, technology is able to tackle huge problems with remarkable ease. The General Services Administration, for\u2026www.businessinsider.com\n>> Predict Wealth from Space\nPenny is a free tool built using high-resolution imagery from DigitalGlobe, income data from the US census, neural network expertise from Carnegie Mellon and intuitive visualizations from Stamen Design. It\u2019s a virtual cityscape (for New York City and St. Louis, so far), where AI has been trained to recognize patterns of neighborhood wealth (trees, parking lots, brownstones and freeways) by correlating census data with satellite imagery. You don\u2019t just extract information from this tool though, click on the link below and drop a grove of trees into the middle of Harlem to see the neighborhoods virtual income level rise or fall. What is impressive about this tool is that it doesn't just look at the urban features you add, it\u2019s the features and the context into which they\u2019re placed that matters.\nLearn More:\nMeet Penny, an AI to predict wealth from space\nPenny is a simple tool to help us understand what wealth and poverty look like to an artificial intelligence built on\u2026penny.digitalglobe.com\nWhat is Penny?\nA technical guide for the busy CEO\nNEEDS EDITING & CLEANUP, ERIC WORKING ON IThi.stamen.com\n>> Justifying Billboard Pricing\nOutdoor marketing company Route is using big data to define and justify its pricing model for advertising space on billboards, benches and the sides of busses. Traditionally, outdoor media pricing was priced \u201cper impression\u201d based on an estimate of how many eyes would see the ad in a given day. No more! Now they\u2019re using sophisticated GPS, eye-tracking software, and analysis of traffic patterns to have a much more realistic idea of which advertisements will be seen the most \u2014 and therefore be the most effective.\nLearn More:\nHow big data is changing outdoor media\nSeeing an ad outdoors has a greater impact on us than one served to our laptop or phone. We come across it, 'discover\u2026econsultancy.com\n>> Turning Neighborhoods into Farmers Markets\nFalling Fruit\u00b4s stated goal is to remind urban people that agriculture and natural foods do exist in the city \u2014but that you might just have to access a website to find it. It combined public information from the U.S. Department of Agriculture, municipal tree inventories, foraging maps and street tree databases to provide an interactive map to tell you where the trees in your neighborhood might be dropping fruit.\nLearn More:\nFalling Fruit\nA massive, collaborative map of the urban harvest uniting the efforts of foragers, freegans, and foresters around the\u2026fallingfruit.org\n>> Rescue you from under the snow\nSki resorts are even getting into the data game. RFID tags inserted into lift tickets can help optimize operations, collect data on skier performance, personalize offerings to customers, and gamifying the experience. In many cases though, the technology is being used to identify the individual movements of the skiers that get lost.\nLearn More:\nEven Ski Resorts Are Benefiting From The Big Data Explosion | Articles | Big Data\nEven Ski Resorts are Benefiting From the Big Data Explosionchannels.theinnovationenterprise.com\n>> Find Lost Relatives\nConsider the millions of Ancestry family trees. How valuable would it be to link to those trees via DNA? You\u2019d be able to determine genetic connections and uncover new family lines, deep relationships, and insights like you never have before. The first thing Ancestry.com does with your autosomal test results is compare them with other DNA samples on their database to look for family matches. They compare the over 700,000 markers examined on your genome to every other person in their database. The more markers you share in common with another person, the more likely you are to be related. The probable relationship between any two people is calculated based on the percentage of markers they have in common. Next, they sort the matches by relationship and send you a list of your DNA family.\nLearn More:\nAncestryDNA\u2122 | Learn How DNA Tests Work & More\nLearn more about the science and technology behind our most advanced DNA test at AncestryDNA\u2122.www.ancestry.com\n>> Financial Inclusion in Africa\nAnalysis of mobile phone data can help increase subscribers\u2019 use of banking services, boosting their economic resilience and inclusion.\nLearn More:\nhttps://olc.worldbank.org/sites/default/files/WBG_BD_CS_FinancialInclusion_0.pdf\nTo be Continued\u2026\nIf you learned something new about Big Data from this guide, please share it with your friends. It is up to us to encourage people to join this field, and be part of building the future.\nSpeaking of which, I\u2019d love to hear from you. Reach out to me on Linkedin or email at melodyannucros@gmail.com\u2709\ufe0f .\n#bigdata #ai #iot #machinelearning #startups #digitaltransformations #impact #agile #newworld #graduateprogram #sharingknowledge\n\nAuthor: Melody Ann Ucros\nI\u2019m a Masters in Big Data & Business Analytics Candidate @ IEBusinessSchool, and an Entrepreneurship Evangelist wherever I go. Oh, and I love chocolate! \u2026 Follow Me \u2764\n"
  },
  {
    "title": "2017 Big Data, AI and IOT Use Cases",
    "content": "2017 Big Data, AI and IOT Use Cases\nAn Active List of Interesting Use Cases Mentioned In Class\nImage Source: Randstad Article\nI\u2019ve heard more use cases of Big Data in the last 10 days, than ever before. Therefore, I\u2019ve decided to start a post where I compiled all the examples \u2014 with additional sources for all of us to learn more about them. I plan on updating this on a daily/weekly basis \u2014 so please follow me to stay on the loop.\nThe Big Data Professors at IE are all working professionals or researchers in the field, so they use countless examples to show us how the concepts taught in class are being applied in the real world.\nUse cases will be divided by \u201cfunction\u201d, but you can expect to see examples of big companies, startups, NGOS, and individuals. The focus is to understand not just the impact, but also the Ripple Effect of AI and IOT innovations.\nIf you have any use cases that should be added, additional resources, or observations feel free to comment below. I want this to be a reference guide for all!\nUse Cases were last updated on: October 30, 2017\n>> Solving the Water Scarcity Problem\nThe UN predicts that half the world\u2019s population will live in a water-stressed area by 2030. Therefore, private and public organizations are coming together to find solutions. Due to the improvement of network connectivity and accuracy of sensors, the challenge seems like an addressable one.Whether it is in major cities like San Francisco, or developing countries like Africa, smart sensors are being installed in water wells and pumps in order to track its quality and quantity. Equitable Allocation of clean water is the main priority for the next decades. It is proven that every $1 spent on water and sanitation generates $8 as a result of saved time, increased productivity and reduced healthcare costs.The current complexity of water systems and budget limitations are the largest obstacle to faster adoption of smart water meters.\nLearn more:\nWPDx | The Water Point Data Exchange is the global platform for sharing water point data\nThe amount of water point data being collected is growing rapidly as governments and development partners increasingly\u2026www.waterpointdata.org\nAccess to data could be vital in addressing the global water crisis\nTwo hundred miles from the nearest town, a farmer in Tanzania picks up his phone and notices an alert. Thanks to an app\u2026www.theguardian.com\nThe Internet of everything water\nImagine a world where your spice cabinet reminds you to buy salt, or your cell phone sends a text message about the\u2026www.un.org\n>> Detecting Defective Genomes & Saving Lives\nDeep Genomics is leveraging artificial intelligence, specifically deep learning to help decode the meaning of the genome. Their learning software is developing the ability to try and predict the effects of a particular mutation based on its analyses of hundreds of thousands of examples of other mutations; even if there\u2019s not already a record of what those mutations do. So far, Deep Genomics has used their computational system to develop a database that provides predictions for how more than 300 million genetic variations could affect a genetic code. For this reason, their findings are used for genome-based therapeutic development, molecular diagnostics, targeting biomarker discovery and assessing risks for genetic disorders.\nLearn More:\nCompany\nTHE NEXT-FRONTIER GENETIC MEDICINE COMPANY Our mission at Deep Genomics is to create a new universe of life-saving\u2026www.deepgenomics.com\nTop Artificial Intelligence Companies in Healthcare to Keep an Eye On - The Medical Futurist\nNo one doubts that artificial intelligence has unimaginable potential. Within the next couple of years, it will\u2026medicalfuturist.com\n>> Training Neurons to Detect Bombs\nAll of the big tech firms, from Google to Microsoft, are rushing to create artificial intelligence modelled on the human brain. Mr Agabi is attempting to reverse-engineer biology and emphasizes how \u201cour deep learning networks are all copying the brain\u2026you can give the neurons instructions about what to do \u2014 in our case we tell it to provide a receptor that can detect explosives.\u201d He launched his start-up Koniku over a year ago, has raised $1m (\u00a3800,000) in funding and claims it is already making profits of $10m in deals with the security industry.\nLearn More:\nThe man teaching a computer to smell\nNigerian Oshi Agabi has unveiled a computer based not on silicon but on mice neurons at the TEDGlobal conference in\u2026www.bbc.com\n>> Influencing Elections\nOn November 9, it became clear what Big Data can do. The company behind Trump\u2019s online campaign \u2014 the same company that had worked for Leave.EU in the very early stages of its \u201cBrexit\u201d campaign \u2014 was a Big Data company: Cambridge Analytica. \u201cPretty much every message that Trump put out was data-driven,\u201d says Cambridge Analytica CEO Alexander Nix\nLearn More:\nThe Data That Turned the World Upside Down\nOn November 9 at around 8.30 AM., Michal Kosinski woke up in the Hotel Sunnehus in Zurich. The 34-year-old researcher\u2026motherboard.vice.com\n>> Saving Billions in Energy Costs\nThe General Services Administration, for example, has found a way to save $13 million a year in energy costs across 180 buildings \u2014 all thanks to a proprietary algorithm developed and monitored from many states away, in Massachusetts. Among the problems discovered: malfunctioning exhaust fans. Much of the leaps in energy efficiency are possible due to the widespread adoption of networked and highly sophisticated energy meters around the country over the last 10 years. Energy meters used to be checked onsite once a month, generating 12 basic data points a year, read and logged by humans. Now, meters register a raft of data every 15 minutes, accessible anywhere remotely, generating 36,000 data points a year.\nLearn More:\n'Big data' is solving the problem of $200 billion of wasted energy\nAt its best, technology is able to tackle huge problems with remarkable ease. The General Services Administration, for\u2026www.businessinsider.com\n>> Predict Wealth from Space\nPenny is a free tool built using high-resolution imagery from DigitalGlobe, income data from the US census, neural network expertise from Carnegie Mellon and intuitive visualizations from Stamen Design. It\u2019s a virtual cityscape (for New York City and St. Louis, so far), where AI has been trained to recognize patterns of neighborhood wealth (trees, parking lots, brownstones and freeways) by correlating census data with satellite imagery. You don\u2019t just extract information from this tool though, click on the link below and drop a grove of trees into the middle of Harlem to see the neighborhoods virtual income level rise or fall. What is impressive about this tool is that it doesn't just look at the urban features you add, it\u2019s the features and the context into which they\u2019re placed that matters.\nLearn More:\nMeet Penny, an AI to predict wealth from space\nPenny is a simple tool to help us understand what wealth and poverty look like to an artificial intelligence built on\u2026penny.digitalglobe.com\nWhat is Penny?\nA technical guide for the busy CEO\nNEEDS EDITING & CLEANUP, ERIC WORKING ON IThi.stamen.com\n>> Justifying Billboard Pricing\nOutdoor marketing company Route is using big data to define and justify its pricing model for advertising space on billboards, benches and the sides of busses. Traditionally, outdoor media pricing was priced \u201cper impression\u201d based on an estimate of how many eyes would see the ad in a given day. No more! Now they\u2019re using sophisticated GPS, eye-tracking software, and analysis of traffic patterns to have a much more realistic idea of which advertisements will be seen the most \u2014 and therefore be the most effective.\nLearn More:\nHow big data is changing outdoor media\nSeeing an ad outdoors has a greater impact on us than one served to our laptop or phone. We come across it, 'discover\u2026econsultancy.com\n>> Turning Neighborhoods into Farmers Markets\nFalling Fruit\u00b4s stated goal is to remind urban people that agriculture and natural foods do exist in the city \u2014but that you might just have to access a website to find it. It combined public information from the U.S. Department of Agriculture, municipal tree inventories, foraging maps and street tree databases to provide an interactive map to tell you where the trees in your neighborhood might be dropping fruit.\nLearn More:\nFalling Fruit\nA massive, collaborative map of the urban harvest uniting the efforts of foragers, freegans, and foresters around the\u2026fallingfruit.org\n>> Rescue you from under the snow\nSki resorts are even getting into the data game. RFID tags inserted into lift tickets can help optimize operations, collect data on skier performance, personalize offerings to customers, and gamifying the experience. In many cases though, the technology is being used to identify the individual movements of the skiers that get lost.\nLearn More:\nEven Ski Resorts Are Benefiting From The Big Data Explosion | Articles | Big Data\nEven Ski Resorts are Benefiting From the Big Data Explosionchannels.theinnovationenterprise.com\n>> Find Lost Relatives\nConsider the millions of Ancestry family trees. How valuable would it be to link to those trees via DNA? You\u2019d be able to determine genetic connections and uncover new family lines, deep relationships, and insights like you never have before. The first thing Ancestry.com does with your autosomal test results is compare them with other DNA samples on their database to look for family matches. They compare the over 700,000 markers examined on your genome to every other person in their database. The more markers you share in common with another person, the more likely you are to be related. The probable relationship between any two people is calculated based on the percentage of markers they have in common. Next, they sort the matches by relationship and send you a list of your DNA family.\nLearn More:\nAncestryDNA\u2122 | Learn How DNA Tests Work & More\nLearn more about the science and technology behind our most advanced DNA test at AncestryDNA\u2122.www.ancestry.com\n>> Financial Inclusion in Africa\nAnalysis of mobile phone data can help increase subscribers\u2019 use of banking services, boosting their economic resilience and inclusion.\nLearn More:\nhttps://olc.worldbank.org/sites/default/files/WBG_BD_CS_FinancialInclusion_0.pdf\nTo be Continued\u2026\nIf you learned something new about Big Data from this guide, please share it with your friends. It is up to us to encourage people to join this field, and be part of building the future.\nSpeaking of which, I\u2019d love to hear from you. Reach out to me on Linkedin or email at melodyannucros@gmail.com\u2709\ufe0f .\n#bigdata #ai #iot #machinelearning #startups #digitaltransformations #impact #agile #newworld #graduateprogram #sharingknowledge\n\nAuthor: Melody Ann Ucros\nI\u2019m a Masters in Big Data & Business Analytics Candidate @ IEBusinessSchool, and an Entrepreneurship Evangelist wherever I go. Oh, and I love chocolate! \u2026 Follow Me \u2764\n"
  },
  {
    "title": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018",
    "content": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018\n\n\u0e43\u0e19\u0e17\u0e38\u0e01\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49 \u0e18\u0e38\u0e23\u0e01\u0e34\u0e08\u0e15\u0e48\u0e32\u0e07\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e49\u0e32\u0e27\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e42\u0e25\u0e01\u0e14\u0e34\u0e08\u0e34\u0e17\u0e31\u0e25\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e17\u0e35\u0e48\u0e04\u0e38\u0e19\u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e23\u0e39\u0e49\u0e08\u0e31\u0e01\u0e41\u0e25\u0e30\u0e43\u0e0a\u0e49\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\nOracle \u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e01\u0e23\u0e30\u0e1a\u0e27\u0e19\u0e01\u0e32\u0e23\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e02\u0e2d\u0e07\u0e04\u0e38\u0e13\u0e07\u0e48\u0e32\u0e22\u0e14\u0e32\u0e22\u0e22\u0e34\u0e48\u0e07\u0e02\u0e36\u0e49\u0e19\u0e14\u0e49\u0e27\u0e22\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\u0e0a\u0e31\u0e49\u0e19\u0e19\u0e33\u0e17\u0e35\u0e48\u0e2d\u0e2d\u0e01\u0e41\u0e1a\u0e1a\u0e21\u0e32\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e42\u0e14\u0e22\u0e40\u0e09\u0e1e\u0e32\u0e30\u0e0b\u0e36\u0e48\u0e07\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e19\u0e2d\u0e19\u0e32\u0e04\u0e15 \u0e2d\u0e22\u0e48\u0e32\u0e07\u0e40\u0e0a\u0e48\u0e19 AI \u0e41\u0e25\u0e30\u0e41\u0e0a\u0e17\u0e1a\u0e2d\u0e17\u0e2d\u0e37\u0e48\u0e19 \u0e46 \u0e2d\u0e35\u0e01\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22\nOracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day2018\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e42\u0e2d\u0e01\u0e32\u0e2a\u0e2d\u0e31\u0e19\u0e14\u0e35\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e43\u0e0a\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e08\u0e32\u0e01\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21\u0e25\u0e48\u0e32\u0e2a\u0e38\u0e14\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u0e27\u0e31\u0e19 : \u0e1e\u0e38\u0e18\u0e17\u0e35\u0e48 4 \u0e40\u0e21\u0e29\u0e32\u0e22\u0e19 2561\n\u0e40\u0e27\u0e25\u0e32 : 08:30 \u0e19. -17:30 \u0e19.\n\u0e2a\u0e16\u0e32\u0e19\u0e17\u0e35\u0e48 : \u0e42\u0e23\u0e07\u0e41\u0e23\u0e21\u0e40\u0e08\u0e14\u0e31\u0e1a\u0e1a\u0e25\u0e34\u0e27\u0e41\u0e21\u0e23\u0e34\u0e2d\u0e2d\u0e17 (\u0e2a\u0e38\u0e02\u0e38\u0e21\u0e27\u0e34\u0e17\u0e0b\u0e2d\u0e22 2)\n\u0e2b\u0e49\u0e2d\u0e07 : \u0e41\u0e01\u0e23\u0e19\u0e14\u0e4c\u0e1a\u0e2d\u0e25\u0e23\u0e39\u0e21 \u0e0a\u0e31\u0e49\u0e19 3\n\u0e20\u0e32\u0e22\u0e43\u0e19\u0e07\u0e32\u0e19\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e23\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e2d\u0e32\u0e17\u0e34\n\u00b7 \u0e0b\u0e35\u0e40\u0e04\u0e35\u0e22\u0e27\u0e23\u0e34\u0e15\u0e35\u0e49\u0e1a\u0e19\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u00b7 \u0e27\u0e34\u0e18\u0e35\u0e1b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e38\u0e07\u0e23\u0e30\u0e1a\u0e1a\u0e44\u0e2d\u0e17\u0e35\u0e43\u0e2b\u0e49\u0e17\u0e31\u0e19\u0e2a\u0e21\u0e31\u0e22\u0e41\u0e25\u0e30\u0e25\u0e14\u0e15\u0e49\u0e19\u0e17\u0e38\u0e19\u0e41\u0e25\u0e30\u0e01\u0e32\u0e23\u0e22\u0e01\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e2d\u0e22\u0e39\u0e48\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22 \u0e40\u0e02\u0e49\u0e32\u0e44\u0e1b\u0e44\u0e27\u0e49\u0e43\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\n\u00b7 \u0e1e\u0e1a\u0e01\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e02\u0e2d\u0e07 Oracle Cloud \u0e17\u0e35\u0e48\u0e0a\u0e48\u0e27\u0e22\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e2b\u0e21\u0e48\u0e46 \u0e41\u0e25\u0e30\u0e40\u0e0a\u0e37\u0e48\u0e2d\u0e21\u0e15\u0e48\u0e2d\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e01\u0e31\u0e1a\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e0a\u0e31\u0e48\u0e19\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e43\u0e0a\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e1b\u0e31\u0e08\u0e08\u0e38\u0e1a\u0e31\u0e19\n\u00b7 \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e28\u0e31\u0e01\u0e22\u0e20\u0e32\u0e1e\u0e41\u0e25\u0e30\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21 Next Generation\n\u00b7 \u0e44\u0e02\u0e02\u0e49\u0e2d\u0e2a\u0e07\u0e2a\u0e31\u0e22\u0e01\u0e31\u0e1a\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46\n\u0e19\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e19\u0e35\u0e49 \u0e22\u0e31\u0e07\u0e21\u0e35\u0e40\u0e27\u0e17\u0e35\u0e2d\u0e20\u0e34\u0e1b\u0e23\u0e32\u0e22\u0e43\u0e2b\u0e49\u0e17\u0e48\u0e32\u0e19\u0e44\u0e14\u0e49\u0e1f\u0e31\u0e07\u0e27\u0e34\u0e2a\u0e31\u0e22\u0e17\u0e31\u0e28\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46 \u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e08\u0e30\u0e41\u0e22\u0e01\u0e01\u0e25\u0e38\u0e48\u0e21\u0e22\u0e48\u0e2d\u0e22\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e44\u0e1b\u0e1f\u0e31\u0e07\u0e2a\u0e31\u0e21\u0e21\u0e19\u0e32 \u0e1f\u0e31\u0e07\u0e15\u0e31\u0e27\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e01\u0e23\u0e13\u0e35\u0e28\u0e36\u0e01\u0e29\u0e32\u0e2b\u0e23\u0e37\u0e2d\u0e23\u0e31\u0e1a\u0e0a\u0e21\u0e01\u0e32\u0e23\u0e2a\u0e32\u0e18\u0e34\u0e15\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\n\u0e1c\u0e39\u0e49\u0e17\u0e35\u0e48\u0e2a\u0e19\u0e43\u0e08\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19\u0e1f\u0e23\u0e35 \u0e42\u0e14\u0e22\u0e25\u0e07\u0e17\u0e30\u0e40\u0e1a\u0e35\u0e22\u0e19\u0e43\u0e19\u0e17\u0e35\u0e48 http://reminder.chiq-511.co.th/oracle.php\u0e2b\u0e23\u0e37\u0e2d \u0e2a\u0e2d\u0e1a\u0e16\u0e32\u0e21\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e44\u0e14\u0e49\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13 \u0e0a\u0e32\u0e15\u0e34\u0e23\u0e2a \u0e2d\u0e34\u0e19\u0e40\u0e02\u0e15\u0e19\u0e4c (\u0e41\u0e01\u0e49\u0e21)\n\u0e42\u0e17\u0e23. 02\u2013408\u20138770 \u0e2d\u0e35\u0e40\u0e21\u0e25 : INFOR2@CHIQ-511.CO.TH\n"
  },
  {
    "title": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018",
    "content": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018\n\n\u0e43\u0e19\u0e17\u0e38\u0e01\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49 \u0e18\u0e38\u0e23\u0e01\u0e34\u0e08\u0e15\u0e48\u0e32\u0e07\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e49\u0e32\u0e27\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e42\u0e25\u0e01\u0e14\u0e34\u0e08\u0e34\u0e17\u0e31\u0e25\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e17\u0e35\u0e48\u0e04\u0e38\u0e19\u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e23\u0e39\u0e49\u0e08\u0e31\u0e01\u0e41\u0e25\u0e30\u0e43\u0e0a\u0e49\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\nOracle \u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e01\u0e23\u0e30\u0e1a\u0e27\u0e19\u0e01\u0e32\u0e23\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e02\u0e2d\u0e07\u0e04\u0e38\u0e13\u0e07\u0e48\u0e32\u0e22\u0e14\u0e32\u0e22\u0e22\u0e34\u0e48\u0e07\u0e02\u0e36\u0e49\u0e19\u0e14\u0e49\u0e27\u0e22\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\u0e0a\u0e31\u0e49\u0e19\u0e19\u0e33\u0e17\u0e35\u0e48\u0e2d\u0e2d\u0e01\u0e41\u0e1a\u0e1a\u0e21\u0e32\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e42\u0e14\u0e22\u0e40\u0e09\u0e1e\u0e32\u0e30\u0e0b\u0e36\u0e48\u0e07\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e19\u0e2d\u0e19\u0e32\u0e04\u0e15 \u0e2d\u0e22\u0e48\u0e32\u0e07\u0e40\u0e0a\u0e48\u0e19 AI \u0e41\u0e25\u0e30\u0e41\u0e0a\u0e17\u0e1a\u0e2d\u0e17\u0e2d\u0e37\u0e48\u0e19 \u0e46 \u0e2d\u0e35\u0e01\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22\nOracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day2018\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e42\u0e2d\u0e01\u0e32\u0e2a\u0e2d\u0e31\u0e19\u0e14\u0e35\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e43\u0e0a\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e08\u0e32\u0e01\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21\u0e25\u0e48\u0e32\u0e2a\u0e38\u0e14\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u0e27\u0e31\u0e19 : \u0e1e\u0e38\u0e18\u0e17\u0e35\u0e48 4 \u0e40\u0e21\u0e29\u0e32\u0e22\u0e19 2561\n\u0e40\u0e27\u0e25\u0e32 : 08:30 \u0e19. -17:30 \u0e19.\n\u0e2a\u0e16\u0e32\u0e19\u0e17\u0e35\u0e48 : \u0e42\u0e23\u0e07\u0e41\u0e23\u0e21\u0e40\u0e08\u0e14\u0e31\u0e1a\u0e1a\u0e25\u0e34\u0e27\u0e41\u0e21\u0e23\u0e34\u0e2d\u0e2d\u0e17 (\u0e2a\u0e38\u0e02\u0e38\u0e21\u0e27\u0e34\u0e17\u0e0b\u0e2d\u0e22 2)\n\u0e2b\u0e49\u0e2d\u0e07 : \u0e41\u0e01\u0e23\u0e19\u0e14\u0e4c\u0e1a\u0e2d\u0e25\u0e23\u0e39\u0e21 \u0e0a\u0e31\u0e49\u0e19 3\n\u0e20\u0e32\u0e22\u0e43\u0e19\u0e07\u0e32\u0e19\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e23\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e2d\u0e32\u0e17\u0e34\n\u00b7 \u0e0b\u0e35\u0e40\u0e04\u0e35\u0e22\u0e27\u0e23\u0e34\u0e15\u0e35\u0e49\u0e1a\u0e19\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u00b7 \u0e27\u0e34\u0e18\u0e35\u0e1b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e38\u0e07\u0e23\u0e30\u0e1a\u0e1a\u0e44\u0e2d\u0e17\u0e35\u0e43\u0e2b\u0e49\u0e17\u0e31\u0e19\u0e2a\u0e21\u0e31\u0e22\u0e41\u0e25\u0e30\u0e25\u0e14\u0e15\u0e49\u0e19\u0e17\u0e38\u0e19\u0e41\u0e25\u0e30\u0e01\u0e32\u0e23\u0e22\u0e01\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e2d\u0e22\u0e39\u0e48\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22 \u0e40\u0e02\u0e49\u0e32\u0e44\u0e1b\u0e44\u0e27\u0e49\u0e43\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\n\u00b7 \u0e1e\u0e1a\u0e01\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e02\u0e2d\u0e07 Oracle Cloud \u0e17\u0e35\u0e48\u0e0a\u0e48\u0e27\u0e22\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e2b\u0e21\u0e48\u0e46 \u0e41\u0e25\u0e30\u0e40\u0e0a\u0e37\u0e48\u0e2d\u0e21\u0e15\u0e48\u0e2d\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e01\u0e31\u0e1a\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e0a\u0e31\u0e48\u0e19\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e43\u0e0a\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e1b\u0e31\u0e08\u0e08\u0e38\u0e1a\u0e31\u0e19\n\u00b7 \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e28\u0e31\u0e01\u0e22\u0e20\u0e32\u0e1e\u0e41\u0e25\u0e30\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21 Next Generation\n\u00b7 \u0e44\u0e02\u0e02\u0e49\u0e2d\u0e2a\u0e07\u0e2a\u0e31\u0e22\u0e01\u0e31\u0e1a\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46\n\u0e19\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e19\u0e35\u0e49 \u0e22\u0e31\u0e07\u0e21\u0e35\u0e40\u0e27\u0e17\u0e35\u0e2d\u0e20\u0e34\u0e1b\u0e23\u0e32\u0e22\u0e43\u0e2b\u0e49\u0e17\u0e48\u0e32\u0e19\u0e44\u0e14\u0e49\u0e1f\u0e31\u0e07\u0e27\u0e34\u0e2a\u0e31\u0e22\u0e17\u0e31\u0e28\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46 \u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e08\u0e30\u0e41\u0e22\u0e01\u0e01\u0e25\u0e38\u0e48\u0e21\u0e22\u0e48\u0e2d\u0e22\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e44\u0e1b\u0e1f\u0e31\u0e07\u0e2a\u0e31\u0e21\u0e21\u0e19\u0e32 \u0e1f\u0e31\u0e07\u0e15\u0e31\u0e27\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e01\u0e23\u0e13\u0e35\u0e28\u0e36\u0e01\u0e29\u0e32\u0e2b\u0e23\u0e37\u0e2d\u0e23\u0e31\u0e1a\u0e0a\u0e21\u0e01\u0e32\u0e23\u0e2a\u0e32\u0e18\u0e34\u0e15\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\n\u0e1c\u0e39\u0e49\u0e17\u0e35\u0e48\u0e2a\u0e19\u0e43\u0e08\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19\u0e1f\u0e23\u0e35 \u0e42\u0e14\u0e22\u0e25\u0e07\u0e17\u0e30\u0e40\u0e1a\u0e35\u0e22\u0e19\u0e43\u0e19\u0e17\u0e35\u0e48 http://reminder.chiq-511.co.th/oracle.php\u0e2b\u0e23\u0e37\u0e2d \u0e2a\u0e2d\u0e1a\u0e16\u0e32\u0e21\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e44\u0e14\u0e49\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13 \u0e0a\u0e32\u0e15\u0e34\u0e23\u0e2a \u0e2d\u0e34\u0e19\u0e40\u0e02\u0e15\u0e19\u0e4c (\u0e41\u0e01\u0e49\u0e21)\n\u0e42\u0e17\u0e23. 02\u2013408\u20138770 \u0e2d\u0e35\u0e40\u0e21\u0e25 : INFOR2@CHIQ-511.CO.TH\n"
  },
  {
    "title": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018",
    "content": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018\n\n\u0e43\u0e19\u0e17\u0e38\u0e01\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49 \u0e18\u0e38\u0e23\u0e01\u0e34\u0e08\u0e15\u0e48\u0e32\u0e07\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e49\u0e32\u0e27\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e42\u0e25\u0e01\u0e14\u0e34\u0e08\u0e34\u0e17\u0e31\u0e25\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e17\u0e35\u0e48\u0e04\u0e38\u0e19\u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e23\u0e39\u0e49\u0e08\u0e31\u0e01\u0e41\u0e25\u0e30\u0e43\u0e0a\u0e49\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\nOracle \u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e01\u0e23\u0e30\u0e1a\u0e27\u0e19\u0e01\u0e32\u0e23\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e02\u0e2d\u0e07\u0e04\u0e38\u0e13\u0e07\u0e48\u0e32\u0e22\u0e14\u0e32\u0e22\u0e22\u0e34\u0e48\u0e07\u0e02\u0e36\u0e49\u0e19\u0e14\u0e49\u0e27\u0e22\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\u0e0a\u0e31\u0e49\u0e19\u0e19\u0e33\u0e17\u0e35\u0e48\u0e2d\u0e2d\u0e01\u0e41\u0e1a\u0e1a\u0e21\u0e32\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e42\u0e14\u0e22\u0e40\u0e09\u0e1e\u0e32\u0e30\u0e0b\u0e36\u0e48\u0e07\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e19\u0e2d\u0e19\u0e32\u0e04\u0e15 \u0e2d\u0e22\u0e48\u0e32\u0e07\u0e40\u0e0a\u0e48\u0e19 AI \u0e41\u0e25\u0e30\u0e41\u0e0a\u0e17\u0e1a\u0e2d\u0e17\u0e2d\u0e37\u0e48\u0e19 \u0e46 \u0e2d\u0e35\u0e01\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22\nOracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day2018\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e42\u0e2d\u0e01\u0e32\u0e2a\u0e2d\u0e31\u0e19\u0e14\u0e35\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e43\u0e0a\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e08\u0e32\u0e01\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21\u0e25\u0e48\u0e32\u0e2a\u0e38\u0e14\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u0e27\u0e31\u0e19 : \u0e1e\u0e38\u0e18\u0e17\u0e35\u0e48 4 \u0e40\u0e21\u0e29\u0e32\u0e22\u0e19 2561\n\u0e40\u0e27\u0e25\u0e32 : 08:30 \u0e19. -17:30 \u0e19.\n\u0e2a\u0e16\u0e32\u0e19\u0e17\u0e35\u0e48 : \u0e42\u0e23\u0e07\u0e41\u0e23\u0e21\u0e40\u0e08\u0e14\u0e31\u0e1a\u0e1a\u0e25\u0e34\u0e27\u0e41\u0e21\u0e23\u0e34\u0e2d\u0e2d\u0e17 (\u0e2a\u0e38\u0e02\u0e38\u0e21\u0e27\u0e34\u0e17\u0e0b\u0e2d\u0e22 2)\n\u0e2b\u0e49\u0e2d\u0e07 : \u0e41\u0e01\u0e23\u0e19\u0e14\u0e4c\u0e1a\u0e2d\u0e25\u0e23\u0e39\u0e21 \u0e0a\u0e31\u0e49\u0e19 3\n\u0e20\u0e32\u0e22\u0e43\u0e19\u0e07\u0e32\u0e19\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e23\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e2d\u0e32\u0e17\u0e34\n\u00b7 \u0e0b\u0e35\u0e40\u0e04\u0e35\u0e22\u0e27\u0e23\u0e34\u0e15\u0e35\u0e49\u0e1a\u0e19\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u00b7 \u0e27\u0e34\u0e18\u0e35\u0e1b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e38\u0e07\u0e23\u0e30\u0e1a\u0e1a\u0e44\u0e2d\u0e17\u0e35\u0e43\u0e2b\u0e49\u0e17\u0e31\u0e19\u0e2a\u0e21\u0e31\u0e22\u0e41\u0e25\u0e30\u0e25\u0e14\u0e15\u0e49\u0e19\u0e17\u0e38\u0e19\u0e41\u0e25\u0e30\u0e01\u0e32\u0e23\u0e22\u0e01\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e2d\u0e22\u0e39\u0e48\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22 \u0e40\u0e02\u0e49\u0e32\u0e44\u0e1b\u0e44\u0e27\u0e49\u0e43\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\n\u00b7 \u0e1e\u0e1a\u0e01\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e02\u0e2d\u0e07 Oracle Cloud \u0e17\u0e35\u0e48\u0e0a\u0e48\u0e27\u0e22\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e2b\u0e21\u0e48\u0e46 \u0e41\u0e25\u0e30\u0e40\u0e0a\u0e37\u0e48\u0e2d\u0e21\u0e15\u0e48\u0e2d\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e01\u0e31\u0e1a\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e0a\u0e31\u0e48\u0e19\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e43\u0e0a\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e1b\u0e31\u0e08\u0e08\u0e38\u0e1a\u0e31\u0e19\n\u00b7 \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e28\u0e31\u0e01\u0e22\u0e20\u0e32\u0e1e\u0e41\u0e25\u0e30\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21 Next Generation\n\u00b7 \u0e44\u0e02\u0e02\u0e49\u0e2d\u0e2a\u0e07\u0e2a\u0e31\u0e22\u0e01\u0e31\u0e1a\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46\n\u0e19\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e19\u0e35\u0e49 \u0e22\u0e31\u0e07\u0e21\u0e35\u0e40\u0e27\u0e17\u0e35\u0e2d\u0e20\u0e34\u0e1b\u0e23\u0e32\u0e22\u0e43\u0e2b\u0e49\u0e17\u0e48\u0e32\u0e19\u0e44\u0e14\u0e49\u0e1f\u0e31\u0e07\u0e27\u0e34\u0e2a\u0e31\u0e22\u0e17\u0e31\u0e28\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46 \u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e08\u0e30\u0e41\u0e22\u0e01\u0e01\u0e25\u0e38\u0e48\u0e21\u0e22\u0e48\u0e2d\u0e22\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e44\u0e1b\u0e1f\u0e31\u0e07\u0e2a\u0e31\u0e21\u0e21\u0e19\u0e32 \u0e1f\u0e31\u0e07\u0e15\u0e31\u0e27\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e01\u0e23\u0e13\u0e35\u0e28\u0e36\u0e01\u0e29\u0e32\u0e2b\u0e23\u0e37\u0e2d\u0e23\u0e31\u0e1a\u0e0a\u0e21\u0e01\u0e32\u0e23\u0e2a\u0e32\u0e18\u0e34\u0e15\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\n\u0e1c\u0e39\u0e49\u0e17\u0e35\u0e48\u0e2a\u0e19\u0e43\u0e08\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19\u0e1f\u0e23\u0e35 \u0e42\u0e14\u0e22\u0e25\u0e07\u0e17\u0e30\u0e40\u0e1a\u0e35\u0e22\u0e19\u0e43\u0e19\u0e17\u0e35\u0e48 http://reminder.chiq-511.co.th/oracle.php\u0e2b\u0e23\u0e37\u0e2d \u0e2a\u0e2d\u0e1a\u0e16\u0e32\u0e21\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e44\u0e14\u0e49\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13 \u0e0a\u0e32\u0e15\u0e34\u0e23\u0e2a \u0e2d\u0e34\u0e19\u0e40\u0e02\u0e15\u0e19\u0e4c (\u0e41\u0e01\u0e49\u0e21)\n\u0e42\u0e17\u0e23. 02\u2013408\u20138770 \u0e2d\u0e35\u0e40\u0e21\u0e25 : INFOR2@CHIQ-511.CO.TH\n"
  },
  {
    "title": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018",
    "content": "Oracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day 2018\n\n\u0e43\u0e19\u0e17\u0e38\u0e01\u0e27\u0e31\u0e19\u0e19\u0e35\u0e49 \u0e18\u0e38\u0e23\u0e01\u0e34\u0e08\u0e15\u0e48\u0e32\u0e07\u0e15\u0e49\u0e2d\u0e07\u0e01\u0e49\u0e32\u0e27\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e42\u0e25\u0e01\u0e14\u0e34\u0e08\u0e34\u0e17\u0e31\u0e25\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e1e\u0e37\u0e49\u0e19\u0e10\u0e32\u0e19\u0e15\u0e48\u0e32\u0e07 \u0e46 \u0e17\u0e35\u0e48\u0e04\u0e38\u0e19\u0e15\u0e49\u0e2d\u0e07\u0e17\u0e33\u0e04\u0e27\u0e32\u0e21\u0e23\u0e39\u0e49\u0e08\u0e31\u0e01\u0e41\u0e25\u0e30\u0e43\u0e0a\u0e49\u0e43\u0e2b\u0e49\u0e40\u0e1b\u0e47\u0e19\nOracle \u0e08\u0e36\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e15\u0e31\u0e27\u0e0a\u0e48\u0e27\u0e22\u0e43\u0e2b\u0e49\u0e01\u0e23\u0e30\u0e1a\u0e27\u0e19\u0e01\u0e32\u0e23\u0e19\u0e33\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e02\u0e49\u0e32\u0e2a\u0e39\u0e48\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e02\u0e2d\u0e07\u0e04\u0e38\u0e13\u0e07\u0e48\u0e32\u0e22\u0e14\u0e32\u0e22\u0e22\u0e34\u0e48\u0e07\u0e02\u0e36\u0e49\u0e19\u0e14\u0e49\u0e27\u0e22\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\u0e0a\u0e31\u0e49\u0e19\u0e19\u0e33\u0e17\u0e35\u0e48\u0e2d\u0e2d\u0e01\u0e41\u0e1a\u0e1a\u0e21\u0e32\u0e2a\u0e33\u0e2b\u0e23\u0e31\u0e1a\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e42\u0e14\u0e22\u0e40\u0e09\u0e1e\u0e32\u0e30\u0e0b\u0e36\u0e48\u0e07\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e16\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e19\u0e2d\u0e19\u0e32\u0e04\u0e15 \u0e2d\u0e22\u0e48\u0e32\u0e07\u0e40\u0e0a\u0e48\u0e19 AI \u0e41\u0e25\u0e30\u0e41\u0e0a\u0e17\u0e1a\u0e2d\u0e17\u0e2d\u0e37\u0e48\u0e19 \u0e46 \u0e2d\u0e35\u0e01\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22\nOracle \u0e08\u0e36\u0e07\u0e02\u0e2d\u0e40\u0e0a\u0e34\u0e0d\u0e0a\u0e32\u0e27\u0e44\u0e2d\u0e17\u0e35\u0e17\u0e31\u0e49\u0e07\u0e2b\u0e25\u0e32\u0e22\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19 Oracle Could Day2018\u0e0b\u0e36\u0e48\u0e07\u0e40\u0e1b\u0e47\u0e19\u0e42\u0e2d\u0e01\u0e32\u0e2a\u0e2d\u0e31\u0e19\u0e14\u0e35\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e43\u0e0a\u0e49\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e08\u0e32\u0e01\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21\u0e25\u0e48\u0e32\u0e2a\u0e38\u0e14\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u0e27\u0e31\u0e19 : \u0e1e\u0e38\u0e18\u0e17\u0e35\u0e48 4 \u0e40\u0e21\u0e29\u0e32\u0e22\u0e19 2561\n\u0e40\u0e27\u0e25\u0e32 : 08:30 \u0e19. -17:30 \u0e19.\n\u0e2a\u0e16\u0e32\u0e19\u0e17\u0e35\u0e48 : \u0e42\u0e23\u0e07\u0e41\u0e23\u0e21\u0e40\u0e08\u0e14\u0e31\u0e1a\u0e1a\u0e25\u0e34\u0e27\u0e41\u0e21\u0e23\u0e34\u0e2d\u0e2d\u0e17 (\u0e2a\u0e38\u0e02\u0e38\u0e21\u0e27\u0e34\u0e17\u0e0b\u0e2d\u0e22 2)\n\u0e2b\u0e49\u0e2d\u0e07 : \u0e41\u0e01\u0e23\u0e19\u0e14\u0e4c\u0e1a\u0e2d\u0e25\u0e23\u0e39\u0e21 \u0e0a\u0e31\u0e49\u0e19 3\n\u0e20\u0e32\u0e22\u0e43\u0e19\u0e07\u0e32\u0e19\u0e04\u0e38\u0e13\u0e08\u0e30\u0e44\u0e14\u0e49\u0e23\u0e31\u0e1a\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25 \u0e2d\u0e32\u0e17\u0e34\n\u00b7 \u0e0b\u0e35\u0e40\u0e04\u0e35\u0e22\u0e27\u0e23\u0e34\u0e15\u0e35\u0e49\u0e1a\u0e19\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\n\u00b7 \u0e27\u0e34\u0e18\u0e35\u0e1b\u0e23\u0e31\u0e1a\u0e1b\u0e23\u0e38\u0e07\u0e23\u0e30\u0e1a\u0e1a\u0e44\u0e2d\u0e17\u0e35\u0e43\u0e2b\u0e49\u0e17\u0e31\u0e19\u0e2a\u0e21\u0e31\u0e22\u0e41\u0e25\u0e30\u0e25\u0e14\u0e15\u0e49\u0e19\u0e17\u0e38\u0e19\u0e41\u0e25\u0e30\u0e01\u0e32\u0e23\u0e22\u0e01\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e17\u0e35\u0e48\u0e21\u0e35\u0e2d\u0e22\u0e39\u0e48\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e21\u0e32\u0e01\u0e21\u0e32\u0e22 \u0e40\u0e02\u0e49\u0e32\u0e44\u0e1b\u0e44\u0e27\u0e49\u0e43\u0e19\u0e23\u0e30\u0e1a\u0e1a\u0e04\u0e25\u0e32\u0e27\u0e14\u0e4c\u0e40\u0e14\u0e35\u0e22\u0e27\u0e01\u0e31\u0e19\n\u00b7 \u0e1e\u0e1a\u0e01\u0e31\u0e1a\u0e04\u0e27\u0e32\u0e21\u0e2a\u0e32\u0e21\u0e32\u0e23\u0e02\u0e2d\u0e07 Oracle Cloud \u0e17\u0e35\u0e48\u0e0a\u0e48\u0e27\u0e22\u0e23\u0e2d\u0e07\u0e23\u0e31\u0e1a\u0e40\u0e17\u0e04\u0e42\u0e19\u0e42\u0e25\u0e22\u0e35\u0e43\u0e2b\u0e21\u0e48\u0e46 \u0e41\u0e25\u0e30\u0e40\u0e0a\u0e37\u0e48\u0e2d\u0e21\u0e15\u0e48\u0e2d\u0e01\u0e32\u0e23\u0e17\u0e33\u0e07\u0e32\u0e19\u0e01\u0e31\u0e1a\u0e41\u0e2d\u0e1e\u0e1e\u0e25\u0e34\u0e0a\u0e31\u0e48\u0e19\u0e2d\u0e07\u0e04\u0e4c\u0e01\u0e23\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13\u0e43\u0e0a\u0e49\u0e2d\u0e22\u0e39\u0e48\u0e43\u0e19\u0e1b\u0e31\u0e08\u0e08\u0e38\u0e1a\u0e31\u0e19\n\u00b7 \u0e40\u0e23\u0e35\u0e22\u0e19\u0e23\u0e39\u0e49\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e40\u0e01\u0e35\u0e48\u0e22\u0e27\u0e01\u0e31\u0e1a\u0e28\u0e31\u0e01\u0e22\u0e20\u0e32\u0e1e\u0e41\u0e25\u0e30\u0e1b\u0e23\u0e30\u0e42\u0e22\u0e0a\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e19\u0e27\u0e31\u0e15\u0e01\u0e23\u0e23\u0e21 Next Generation\n\u00b7 \u0e44\u0e02\u0e02\u0e49\u0e2d\u0e2a\u0e07\u0e2a\u0e31\u0e22\u0e01\u0e31\u0e1a\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46\n\u0e19\u0e2d\u0e01\u0e08\u0e32\u0e01\u0e19\u0e35\u0e49 \u0e22\u0e31\u0e07\u0e21\u0e35\u0e40\u0e27\u0e17\u0e35\u0e2d\u0e20\u0e34\u0e1b\u0e23\u0e32\u0e22\u0e43\u0e2b\u0e49\u0e17\u0e48\u0e32\u0e19\u0e44\u0e14\u0e49\u0e1f\u0e31\u0e07\u0e27\u0e34\u0e2a\u0e31\u0e22\u0e17\u0e31\u0e28\u0e19\u0e4c\u0e02\u0e2d\u0e07\u0e1c\u0e39\u0e49\u0e1a\u0e23\u0e34\u0e2b\u0e32\u0e23 Oracle \u0e41\u0e25\u0e30\u0e1c\u0e39\u0e49\u0e40\u0e0a\u0e35\u0e48\u0e22\u0e27\u0e0a\u0e32\u0e0d\u0e43\u0e19\u0e2d\u0e38\u0e15\u0e2a\u0e32\u0e2b\u0e01\u0e23\u0e23\u0e21\u0e17\u0e48\u0e32\u0e19\u0e2d\u0e37\u0e48\u0e19\u0e46 \u0e01\u0e48\u0e2d\u0e19\u0e17\u0e35\u0e48\u0e08\u0e30\u0e41\u0e22\u0e01\u0e01\u0e25\u0e38\u0e48\u0e21\u0e22\u0e48\u0e2d\u0e22\u0e40\u0e1e\u0e37\u0e48\u0e2d\u0e44\u0e1b\u0e1f\u0e31\u0e07\u0e2a\u0e31\u0e21\u0e21\u0e19\u0e32 \u0e1f\u0e31\u0e07\u0e15\u0e31\u0e27\u0e2d\u0e22\u0e48\u0e32\u0e07\u0e01\u0e23\u0e13\u0e35\u0e28\u0e36\u0e01\u0e29\u0e32\u0e2b\u0e23\u0e37\u0e2d\u0e23\u0e31\u0e1a\u0e0a\u0e21\u0e01\u0e32\u0e23\u0e2a\u0e32\u0e18\u0e34\u0e15\u0e1c\u0e25\u0e34\u0e15\u0e20\u0e31\u0e13\u0e11\u0e4c\n\u0e1c\u0e39\u0e49\u0e17\u0e35\u0e48\u0e2a\u0e19\u0e43\u0e08\u0e40\u0e02\u0e49\u0e32\u0e23\u0e48\u0e27\u0e21\u0e07\u0e32\u0e19\u0e1f\u0e23\u0e35 \u0e42\u0e14\u0e22\u0e25\u0e07\u0e17\u0e30\u0e40\u0e1a\u0e35\u0e22\u0e19\u0e43\u0e19\u0e17\u0e35\u0e48 http://reminder.chiq-511.co.th/oracle.php\u0e2b\u0e23\u0e37\u0e2d \u0e2a\u0e2d\u0e1a\u0e16\u0e32\u0e21\u0e02\u0e49\u0e2d\u0e21\u0e39\u0e25\u0e40\u0e1e\u0e34\u0e48\u0e21\u0e40\u0e15\u0e34\u0e21\u0e44\u0e14\u0e49\u0e17\u0e35\u0e48\u0e04\u0e38\u0e13 \u0e0a\u0e32\u0e15\u0e34\u0e23\u0e2a \u0e2d\u0e34\u0e19\u0e40\u0e02\u0e15\u0e19\u0e4c (\u0e41\u0e01\u0e49\u0e21)\n\u0e42\u0e17\u0e23. 02\u2013408\u20138770 \u0e2d\u0e35\u0e40\u0e21\u0e25 : INFOR2@CHIQ-511.CO.TH\n"
  },
  {
    "title": "Artificial Intelligence is the Next Frontier",
    "content": "Artificial Intelligence is the Next Frontier\n\nIf your company hasn\u2019t already considered integrating artificial intelligence or its satellite technologies into its current processes, you might begin to find yourself significantly behind in the game by the end of the year.\nWho adopts AI\n\nCurrently there are huge amounts of dollars being invested in AI, but studies done by McKinsey Global reveal that adoption is very low. In 2016, the hundreds of surveyed companies invested between $25\u201339 billion in artificial intelligence. Of the investing companies, 75% were tech giants in the industry. The other 25% were start-ups. That amount has tripled since 2013. Adoption nevertheless is low. 41% of the surveyed companies were uncertain about the benefits that AI could bring them. Only about 20% said they already adopted AI into their company. 40% said they are contemplating it, and only 9% found themselves simply experimenting with it.\nWhen to begin adopting AI\n\nThe challenge for new adopters of AI seems to be their current familiarity with the tech world and tech systems integrated into their business processes and workflows.\nAccording to McKinsey\u2019s studies, those companies who adopted AI were already strong in the digital sector (telecommunications, high tech, automotive and assembly, and financial services). Those companies with less adoption were typically in the education sector, health care, and travel and tourism. Early adopters have usually been larger businesses, adopting AI in core activities, focusing on growth over savings, and adopting multiple technologies.\nSuccessful AI adoption experiences\n\nThere appear to be five successful transformations that source value for AI adoption in companies. Case analyses have brought about more precise results and diagnoses through AI. AI has been effective at creating data ecosystems for businesses that manage large volumes of data. Applying tools and techniques into established systems has been an added value of AI, as well as developing workflow integration. Ultimately, AI has aided businesses in fostering an open culture and organization.\nAI has created value already in smarter forecasting, optimizing production and maintenance, targeted sales and marketing, and providing enhanced user experiences.\n2018 will be a year of significant investing in AI. Hopefully companies are looking into cost/benefit analyses and deciding early on how to begin integrating AI into their business.\nOriginally published at avoncourtpartners.com on March 19, 2018.\n"
  },
  {
    "title": "Aidoc Gets CE Mark for Deep Learning Solution",
    "content": "Aidoc Gets CE Mark for Deep Learning Solution\n\nAidoc, a leading AI startup utilizing deep learning to augment radiologists\u2019 workflow and highlight anomalous cases, which are often highly urgent, today announced that it received CE (Conformit\u00e9 Europ\u00e9enne) marking for the world\u2019s first commercial head and neck deep learning medical imaging solution. CE marking allows for widespread commercialization of Aidoc\u2019s solution in Europe.\nAidoc\u2019s solution augments radiologists\u2019 workflow through its unique ability to comprehensively detect abnormalities in imaging of both the head and neck, an anatomical area responsible for a major portion of medical images. Providing significant value for day-to-day diagnosis, time saved by Aidoc\u2019s solution could be extremely impactful in trauma cases, where time can be the difference between the patient\u2019s life and death.\nAidoc\u2019s deep learning technology highlights a vast array of medical findings to help radiologists prioritize readings, aimed at facilitating interpretation and reducing time to decision when it matters most. Radiologists can now perform smart optimization of their worklist by prioritizing cases based on AI medical image analysis in conjunction with other clinically available data. Aidoc\u2019s solution is agnostic to radiologists\u2019 incumbent software, integrating seamlessly and providing immediate results.\n\u201cThe amount of medical imaging \u2014 especially CT and MR scans \u2014 is increasing dramatically, but the number of radiologists has plateaued, creating unsustainable bottlenecks and making the radiologist\u2019s already complex work even more challenging,\u201d said Aidoc CEO Elad Walach. \u201cOur technology can have a monumental impact augmenting the radiology workflow, aimed at more cost-effective treatment for medical centers and practices, and the healthcare system as a whole. With the CE mark, we have a unique opportunity to update outdated technology for the benefit of hundreds of millions of Europeans.\u201d\nThe CE marking was based on data collected in clinical trials validating Aidoc\u2019s precision, which compared the solution\u2019s results to unassisted radiologists\u2019 review of those cases. Cedars-Sinai Medical Center in Los Angeles also assessed Aidoc\u2019s solution earlier this year and that study resulted in impressive accuracy in scan analysis.\n\u201cIn our clinical trial, Aidoc\u2019s technology has demonstrated its ability to enhance our radiologists\u2019 workflow, as abnormal scans can be prioritized and more carefully reviewed,\u201d said Dr. Barry D. Pressman, MD, Chairman of Imaging at Cedars-Sinai Medical Center. \u201cOur firsthand experience has led me to believe in the technology\u2019s potential to achieve a significant increase in our radiologists\u2019 productivity and accuracy. It\u2019s a win both for our physicians and our patients. Aidoc\u2019s AI powered solution will help our radiologists be their best, and streamline their workflow.\u201d\nFor the original press release, click here\n"
  },
  {
    "title": "Aidoc Gets CE Mark for Deep Learning Solution",
    "content": "Aidoc Gets CE Mark for Deep Learning Solution\n\nAidoc, a leading AI startup utilizing deep learning to augment radiologists\u2019 workflow and highlight anomalous cases, which are often highly urgent, today announced that it received CE (Conformit\u00e9 Europ\u00e9enne) marking for the world\u2019s first commercial head and neck deep learning medical imaging solution. CE marking allows for widespread commercialization of Aidoc\u2019s solution in Europe.\nAidoc\u2019s solution augments radiologists\u2019 workflow through its unique ability to comprehensively detect abnormalities in imaging of both the head and neck, an anatomical area responsible for a major portion of medical images. Providing significant value for day-to-day diagnosis, time saved by Aidoc\u2019s solution could be extremely impactful in trauma cases, where time can be the difference between the patient\u2019s life and death.\nAidoc\u2019s deep learning technology highlights a vast array of medical findings to help radiologists prioritize readings, aimed at facilitating interpretation and reducing time to decision when it matters most. Radiologists can now perform smart optimization of their worklist by prioritizing cases based on AI medical image analysis in conjunction with other clinically available data. Aidoc\u2019s solution is agnostic to radiologists\u2019 incumbent software, integrating seamlessly and providing immediate results.\n\u201cThe amount of medical imaging \u2014 especially CT and MR scans \u2014 is increasing dramatically, but the number of radiologists has plateaued, creating unsustainable bottlenecks and making the radiologist\u2019s already complex work even more challenging,\u201d said Aidoc CEO Elad Walach. \u201cOur technology can have a monumental impact augmenting the radiology workflow, aimed at more cost-effective treatment for medical centers and practices, and the healthcare system as a whole. With the CE mark, we have a unique opportunity to update outdated technology for the benefit of hundreds of millions of Europeans.\u201d\nThe CE marking was based on data collected in clinical trials validating Aidoc\u2019s precision, which compared the solution\u2019s results to unassisted radiologists\u2019 review of those cases. Cedars-Sinai Medical Center in Los Angeles also assessed Aidoc\u2019s solution earlier this year and that study resulted in impressive accuracy in scan analysis.\n\u201cIn our clinical trial, Aidoc\u2019s technology has demonstrated its ability to enhance our radiologists\u2019 workflow, as abnormal scans can be prioritized and more carefully reviewed,\u201d said Dr. Barry D. Pressman, MD, Chairman of Imaging at Cedars-Sinai Medical Center. \u201cOur firsthand experience has led me to believe in the technology\u2019s potential to achieve a significant increase in our radiologists\u2019 productivity and accuracy. It\u2019s a win both for our physicians and our patients. Aidoc\u2019s AI powered solution will help our radiologists be their best, and streamline their workflow.\u201d\nFor the original press release, click here\n"
  },
  {
    "title": "Aidoc Gets CE Mark for Deep Learning Solution",
    "content": "Aidoc Gets CE Mark for Deep Learning Solution\n\nAidoc, a leading AI startup utilizing deep learning to augment radiologists\u2019 workflow and highlight anomalous cases, which are often highly urgent, today announced that it received CE (Conformit\u00e9 Europ\u00e9enne) marking for the world\u2019s first commercial head and neck deep learning medical imaging solution. CE marking allows for widespread commercialization of Aidoc\u2019s solution in Europe.\nAidoc\u2019s solution augments radiologists\u2019 workflow through its unique ability to comprehensively detect abnormalities in imaging of both the head and neck, an anatomical area responsible for a major portion of medical images. Providing significant value for day-to-day diagnosis, time saved by Aidoc\u2019s solution could be extremely impactful in trauma cases, where time can be the difference between the patient\u2019s life and death.\nAidoc\u2019s deep learning technology highlights a vast array of medical findings to help radiologists prioritize readings, aimed at facilitating interpretation and reducing time to decision when it matters most. Radiologists can now perform smart optimization of their worklist by prioritizing cases based on AI medical image analysis in conjunction with other clinically available data. Aidoc\u2019s solution is agnostic to radiologists\u2019 incumbent software, integrating seamlessly and providing immediate results.\n\u201cThe amount of medical imaging \u2014 especially CT and MR scans \u2014 is increasing dramatically, but the number of radiologists has plateaued, creating unsustainable bottlenecks and making the radiologist\u2019s already complex work even more challenging,\u201d said Aidoc CEO Elad Walach. \u201cOur technology can have a monumental impact augmenting the radiology workflow, aimed at more cost-effective treatment for medical centers and practices, and the healthcare system as a whole. With the CE mark, we have a unique opportunity to update outdated technology for the benefit of hundreds of millions of Europeans.\u201d\nThe CE marking was based on data collected in clinical trials validating Aidoc\u2019s precision, which compared the solution\u2019s results to unassisted radiologists\u2019 review of those cases. Cedars-Sinai Medical Center in Los Angeles also assessed Aidoc\u2019s solution earlier this year and that study resulted in impressive accuracy in scan analysis.\n\u201cIn our clinical trial, Aidoc\u2019s technology has demonstrated its ability to enhance our radiologists\u2019 workflow, as abnormal scans can be prioritized and more carefully reviewed,\u201d said Dr. Barry D. Pressman, MD, Chairman of Imaging at Cedars-Sinai Medical Center. \u201cOur firsthand experience has led me to believe in the technology\u2019s potential to achieve a significant increase in our radiologists\u2019 productivity and accuracy. It\u2019s a win both for our physicians and our patients. Aidoc\u2019s AI powered solution will help our radiologists be their best, and streamline their workflow.\u201d\nFor the original press release, click here\n"
  },
  {
    "title": "Aidoc Gets CE Mark for Deep Learning Solution",
    "content": "Aidoc Gets CE Mark for Deep Learning Solution\n\nAidoc, a leading AI startup utilizing deep learning to augment radiologists\u2019 workflow and highlight anomalous cases, which are often highly urgent, today announced that it received CE (Conformit\u00e9 Europ\u00e9enne) marking for the world\u2019s first commercial head and neck deep learning medical imaging solution. CE marking allows for widespread commercialization of Aidoc\u2019s solution in Europe.\nAidoc\u2019s solution augments radiologists\u2019 workflow through its unique ability to comprehensively detect abnormalities in imaging of both the head and neck, an anatomical area responsible for a major portion of medical images. Providing significant value for day-to-day diagnosis, time saved by Aidoc\u2019s solution could be extremely impactful in trauma cases, where time can be the difference between the patient\u2019s life and death.\nAidoc\u2019s deep learning technology highlights a vast array of medical findings to help radiologists prioritize readings, aimed at facilitating interpretation and reducing time to decision when it matters most. Radiologists can now perform smart optimization of their worklist by prioritizing cases based on AI medical image analysis in conjunction with other clinically available data. Aidoc\u2019s solution is agnostic to radiologists\u2019 incumbent software, integrating seamlessly and providing immediate results.\n\u201cThe amount of medical imaging \u2014 especially CT and MR scans \u2014 is increasing dramatically, but the number of radiologists has plateaued, creating unsustainable bottlenecks and making the radiologist\u2019s already complex work even more challenging,\u201d said Aidoc CEO Elad Walach. \u201cOur technology can have a monumental impact augmenting the radiology workflow, aimed at more cost-effective treatment for medical centers and practices, and the healthcare system as a whole. With the CE mark, we have a unique opportunity to update outdated technology for the benefit of hundreds of millions of Europeans.\u201d\nThe CE marking was based on data collected in clinical trials validating Aidoc\u2019s precision, which compared the solution\u2019s results to unassisted radiologists\u2019 review of those cases. Cedars-Sinai Medical Center in Los Angeles also assessed Aidoc\u2019s solution earlier this year and that study resulted in impressive accuracy in scan analysis.\n\u201cIn our clinical trial, Aidoc\u2019s technology has demonstrated its ability to enhance our radiologists\u2019 workflow, as abnormal scans can be prioritized and more carefully reviewed,\u201d said Dr. Barry D. Pressman, MD, Chairman of Imaging at Cedars-Sinai Medical Center. \u201cOur firsthand experience has led me to believe in the technology\u2019s potential to achieve a significant increase in our radiologists\u2019 productivity and accuracy. It\u2019s a win both for our physicians and our patients. Aidoc\u2019s AI powered solution will help our radiologists be their best, and streamline their workflow.\u201d\nFor the original press release, click here\n"
  },
  {
    "title": "Aidoc Gets CE Mark for Deep Learning Solution",
    "content": "Aidoc Gets CE Mark for Deep Learning Solution\n\nAidoc, a leading AI startup utilizing deep learning to augment radiologists\u2019 workflow and highlight anomalous cases, which are often highly urgent, today announced that it received CE (Conformit\u00e9 Europ\u00e9enne) marking for the world\u2019s first commercial head and neck deep learning medical imaging solution. CE marking allows for widespread commercialization of Aidoc\u2019s solution in Europe.\nAidoc\u2019s solution augments radiologists\u2019 workflow through its unique ability to comprehensively detect abnormalities in imaging of both the head and neck, an anatomical area responsible for a major portion of medical images. Providing significant value for day-to-day diagnosis, time saved by Aidoc\u2019s solution could be extremely impactful in trauma cases, where time can be the difference between the patient\u2019s life and death.\nAidoc\u2019s deep learning technology highlights a vast array of medical findings to help radiologists prioritize readings, aimed at facilitating interpretation and reducing time to decision when it matters most. Radiologists can now perform smart optimization of their worklist by prioritizing cases based on AI medical image analysis in conjunction with other clinically available data. Aidoc\u2019s solution is agnostic to radiologists\u2019 incumbent software, integrating seamlessly and providing immediate results.\n\u201cThe amount of medical imaging \u2014 especially CT and MR scans \u2014 is increasing dramatically, but the number of radiologists has plateaued, creating unsustainable bottlenecks and making the radiologist\u2019s already complex work even more challenging,\u201d said Aidoc CEO Elad Walach. \u201cOur technology can have a monumental impact augmenting the radiology workflow, aimed at more cost-effective treatment for medical centers and practices, and the healthcare system as a whole. With the CE mark, we have a unique opportunity to update outdated technology for the benefit of hundreds of millions of Europeans.\u201d\nThe CE marking was based on data collected in clinical trials validating Aidoc\u2019s precision, which compared the solution\u2019s results to unassisted radiologists\u2019 review of those cases. Cedars-Sinai Medical Center in Los Angeles also assessed Aidoc\u2019s solution earlier this year and that study resulted in impressive accuracy in scan analysis.\n\u201cIn our clinical trial, Aidoc\u2019s technology has demonstrated its ability to enhance our radiologists\u2019 workflow, as abnormal scans can be prioritized and more carefully reviewed,\u201d said Dr. Barry D. Pressman, MD, Chairman of Imaging at Cedars-Sinai Medical Center. \u201cOur firsthand experience has led me to believe in the technology\u2019s potential to achieve a significant increase in our radiologists\u2019 productivity and accuracy. It\u2019s a win both for our physicians and our patients. Aidoc\u2019s AI powered solution will help our radiologists be their best, and streamline their workflow.\u201d\nFor the original press release, click here\n"
  },
  {
    "title": "Ai and it\u2019s impact on the world",
    "content": "Ai and it\u2019s impact on the world\n\n\nActually ai is efiicting our world in a very good way, efficient way though it\u2019s gonna kill a no. Of different jobs in the world of today and it\u2019s gonna automate some of them but it also opens opens up a no of opportunity of different jobs Jobs for people like in the current world it saves us all that complex statistics, Mathematics that we would otherwise have to be doing if we didn\u2019t had ai do that for us and ai also gets us new features like now machines can talk like humans someday we might have machines that are not only machines but they are human like an d that could solve a no of current problem and if you fear an ai apoocylapse so you should not if you have usedsny of command line, server side languages or you are a programmer you might have known by now that machines are way dumber that humans.\n"
  },
  {
    "title": "The Meta Model and Meta Meta-Model of Deep Learning",
    "content": "The Meta Model and Meta Meta-Model of Deep Learning\nCredit: Inception (2010) http://www.imdb.com/title/tt1375666/\nThe model for deep learning consists of a computational graph that are most conveniently constructed by composing layers with other layers. Most introductory texts emphasize the individual neuron, but in practice it is the collective behavior of a layer of neurons that is important. So from an abstraction perspective, the layer is the right level to think about.\nUnderneath these layers are the computational graph, it\u2019s main purpose is to orchestrate the computation of the forward and backward phases of the network. From the perspective of optimizing the performance, this is an important abstraction to have. However, it is not at the ideal level to reason how it all should work.\nDeep Learning frameworks have evolved to develop models that ease construction of DL architectures. Theano has Blocks, Lasagne and Keras. Tensorflow has Keras and TF-Slim. Keras was originally inspired by the simplicity of Torch, so by default has a high-level modular API. Many other less popular frameworks like Nervana, CNTK, MXNet and Chainer do have high level model APIs. All these APIs however describe models. What then is a Deep Learning meta-model? Is there even a meta meta-model?\nFigure: This is what a Deep Learning model looks like.\nLet\u2019s explore first how a meta-model looks like. A good example is in the UML domain of Object Oriented Design. This is the UML metal model:\nCredit: Eclipse ATL project\nThis makes it clear that Layers, Objectives, Activations, Optimizers, Metrics in the Keras APIs are the meta-models for Deep Learning. That\u2019s not too difficult a concept to understand.\nFigure. Deep Learning Meta Model\nConventionally, an Objective is a function and an Optimizer is an algorithm. However, what if we think of them instead as also being models. In that case we have the following:\nFigure. Make everything into networks\nThis definitely is getting a whole lot more complicated. The objective function has become a neural network and the optimizer has also become a neural network. The first reaction to this is, has this kind of architecture been tested before? It\u2019s possible someone is already writing this paper. That\u2019s because an objective function that is a neural network is equivalent to the Discriminator in a Generative Adversarial Network (GAN) and an Optimizer being a neural network is precisely what a meta-learner is about. So this idea is not fantastically out of mainstream research.\nThe second reaction to this is, shouldn\u2019t we make everything neural networks and be done? There are still boxes in the diagram that are still functions and algorithms. The Objective\u2019s optimizer is one and there are 3 others. Once you do that, there\u2019s nothing else left that a designer needs to define! There are no functions, everything is learned from scratch!!\nSo a meta-model where everything is a neural network looks this:\nFigure. Deep Learning Meta-Model\nWhere the mode is broken apart into 3 parts just for clarity. Alternatively, it looks like this:\nFigure. Deep Learning Meta-Model\nWhat this makes abundantly clear however is that the kinds of layers that are available come from a fixed set (i.e. fully connected, convolution, LSTM etc.). There are in fact research papers that exploit this notion of selecting different kinds of layers to generate DL architectures( see: \u201cThe Unreasonable Effectiveness of Randomness\u201d ). A DL meta-model language serves as the lego blocks of an exploratory RL based system. This can generate multiple DL meta-model instances to optimize for the best architecture. That is a reflection of the importance of Deep Learning Patterns. Before you can generate architectures, you have to know what building blocks are available for exploitation.\nNow, if we make a quantum leap into meta meta-model of Deep Learning. What should that look like?\nLet\u2019s look at how OMG\u2019s UML specification describes the meta meta-model level (i.e. M3):\nhttps://en.wikipedia.org/wiki/Meta-Object_Facility\nThe M3 level has a simplified structure that only includes the class. Following an analogous prescription, we thus have the meta meta-model of Deep Learning defined by the following:\nDeep Learning Meta Meta-Model\nDespite the simpleness of the depiction, the interpretation of this is quite interesting. You see, this is a meta object that an instance of which is the conventional DL meta-model. These are the abstract concepts that define how to generate new DL architectures. More specifically, it is the language that defines the creation of new DL models such as a convolution network or a autoregressive network. When you work at this level, you essentially generate new kinds of DL architectures. This is what many DL researchers actually do for a living, designing new novel models.\nThere is one important concept to remember here though, the instance, model, meta-model and meta meta-model distinction are concepts that we\u2019ve invented to better understand the nature of language and specification. This concept that is not essentially and likely does not exists in separate form in reality. As an example, there are many programming languages that do not have a distinction between instance data and model data. Languages like Lisp are like this, where everything is just data, there is not distinction between code and data.\nThe idea of \u201ccode is data\u201d applied to DL is equivalent to saying that the DL architecture are representations that can be learned. We as humans require the concept of a meta meta-model to get a better handle of the complex recursive self-describing nature of DL systems. It would be interesting know what the language of the meta meta-model should look like. Unfortunately, if this language is one that is learned by a machine, then it may likely be as inscrutable as any other learned representation. See: \u201cThe Only Way to Make DL Interpretable\u201d.\nIt is my suspicion though that this meta meta-model approach if pursued in greater detail may the key in locking \u201cUnsupervised learning\u201d or alternatively \u201cPredictive learning\u201d. Perhaps our limited human brains cannot figure this out. However armed with meta-learning capabilities, it may be possible for machines to continually self improve upon themselves. See \u201c Meta-Unsupervised-Learning: A supervised approach to unsupervised learning\u201d for an early take on this approach.\nThe one reason that this may not work however is that the vocabulary or language that is the is limited (see: Canonical Patterns) and therefore \u201cpredictive learning\u201d is not derivable from this bootstrapping method. Meta-learners today discover can only the weights and the weights are just parameters of a fixed DL model. A discovery, even through evolutionary methods, can only happen if the genesis vocabulary is at the correct level. Evolution appears to be a Meta Metal-Model process.\nThere is plenty that is missing in our understanding of the language for the meta meta-model of DL. Perhaps we can discover this only if we work up the Capability levels of Deep Learning intelligence. DARPA has a program that is researching this topic \u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d. I hope to refine this idea over time.\n\u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d.\nSee Deep Learning Design Patterns for more details or visit \u201cIntuition Machine\u201d to keep abreast about the latest developments.\nFor more on this, read \u201cThe Deep Learning Playbook\u201d\n"
  },
  {
    "title": "The Meta Model and Meta Meta-Model of Deep Learning",
    "content": "The Meta Model and Meta Meta-Model of Deep Learning\nCredit: Inception (2010) http://www.imdb.com/title/tt1375666/\nThe model for deep learning consists of a computational graph that are most conveniently constructed by composing layers with other layers. Most introductory texts emphasize the individual neuron, but in practice it is the collective behavior of a layer of neurons that is important. So from an abstraction perspective, the layer is the right level to think about.\nUnderneath these layers are the computational graph, it\u2019s main purpose is to orchestrate the computation of the forward and backward phases of the network. From the perspective of optimizing the performance, this is an important abstraction to have. However, it is not at the ideal level to reason how it all should work.\nDeep Learning frameworks have evolved to develop models that ease construction of DL architectures. Theano has Blocks, Lasagne and Keras. Tensorflow has Keras and TF-Slim. Keras was originally inspired by the simplicity of Torch, so by default has a high-level modular API. Many other less popular frameworks like Nervana, CNTK, MXNet and Chainer do have high level model APIs. All these APIs however describe models. What then is a Deep Learning meta-model? Is there even a meta meta-model?\nFigure: This is what a Deep Learning model looks like.\nLet\u2019s explore first how a meta-model looks like. A good example is in the UML domain of Object Oriented Design. This is the UML metal model:\nCredit: Eclipse ATL project\nThis makes it clear that Layers, Objectives, Activations, Optimizers, Metrics in the Keras APIs are the meta-models for Deep Learning. That\u2019s not too difficult a concept to understand.\nFigure. Deep Learning Meta Model\nConventionally, an Objective is a function and an Optimizer is an algorithm. However, what if we think of them instead as also being models. In that case we have the following:\nFigure. Make everything into networks\nThis definitely is getting a whole lot more complicated. The objective function has become a neural network and the optimizer has also become a neural network. The first reaction to this is, has this kind of architecture been tested before? It\u2019s possible someone is already writing this paper. That\u2019s because an objective function that is a neural network is equivalent to the Discriminator in a Generative Adversarial Network (GAN) and an Optimizer being a neural network is precisely what a meta-learner is about. So this idea is not fantastically out of mainstream research.\nThe second reaction to this is, shouldn\u2019t we make everything neural networks and be done? There are still boxes in the diagram that are still functions and algorithms. The Objective\u2019s optimizer is one and there are 3 others. Once you do that, there\u2019s nothing else left that a designer needs to define! There are no functions, everything is learned from scratch!!\nSo a meta-model where everything is a neural network looks this:\nFigure. Deep Learning Meta-Model\nWhere the mode is broken apart into 3 parts just for clarity. Alternatively, it looks like this:\nFigure. Deep Learning Meta-Model\nWhat this makes abundantly clear however is that the kinds of layers that are available come from a fixed set (i.e. fully connected, convolution, LSTM etc.). There are in fact research papers that exploit this notion of selecting different kinds of layers to generate DL architectures( see: \u201cThe Unreasonable Effectiveness of Randomness\u201d ). A DL meta-model language serves as the lego blocks of an exploratory RL based system. This can generate multiple DL meta-model instances to optimize for the best architecture. That is a reflection of the importance of Deep Learning Patterns. Before you can generate architectures, you have to know what building blocks are available for exploitation.\nNow, if we make a quantum leap into meta meta-model of Deep Learning. What should that look like?\nLet\u2019s look at how OMG\u2019s UML specification describes the meta meta-model level (i.e. M3):\nhttps://en.wikipedia.org/wiki/Meta-Object_Facility\nThe M3 level has a simplified structure that only includes the class. Following an analogous prescription, we thus have the meta meta-model of Deep Learning defined by the following:\nDeep Learning Meta Meta-Model\nDespite the simpleness of the depiction, the interpretation of this is quite interesting. You see, this is a meta object that an instance of which is the conventional DL meta-model. These are the abstract concepts that define how to generate new DL architectures. More specifically, it is the language that defines the creation of new DL models such as a convolution network or a autoregressive network. When you work at this level, you essentially generate new kinds of DL architectures. This is what many DL researchers actually do for a living, designing new novel models.\nThere is one important concept to remember here though, the instance, model, meta-model and meta meta-model distinction are concepts that we\u2019ve invented to better understand the nature of language and specification. This concept that is not essentially and likely does not exists in separate form in reality. As an example, there are many programming languages that do not have a distinction between instance data and model data. Languages like Lisp are like this, where everything is just data, there is not distinction between code and data.\nThe idea of \u201ccode is data\u201d applied to DL is equivalent to saying that the DL architecture are representations that can be learned. We as humans require the concept of a meta meta-model to get a better handle of the complex recursive self-describing nature of DL systems. It would be interesting know what the language of the meta meta-model should look like. Unfortunately, if this language is one that is learned by a machine, then it may likely be as inscrutable as any other learned representation. See: \u201cThe Only Way to Make DL Interpretable\u201d.\nIt is my suspicion though that this meta meta-model approach if pursued in greater detail may the key in locking \u201cUnsupervised learning\u201d or alternatively \u201cPredictive learning\u201d. Perhaps our limited human brains cannot figure this out. However armed with meta-learning capabilities, it may be possible for machines to continually self improve upon themselves. See \u201c Meta-Unsupervised-Learning: A supervised approach to unsupervised learning\u201d for an early take on this approach.\nThe one reason that this may not work however is that the vocabulary or language that is the is limited (see: Canonical Patterns) and therefore \u201cpredictive learning\u201d is not derivable from this bootstrapping method. Meta-learners today discover can only the weights and the weights are just parameters of a fixed DL model. A discovery, even through evolutionary methods, can only happen if the genesis vocabulary is at the correct level. Evolution appears to be a Meta Metal-Model process.\nThere is plenty that is missing in our understanding of the language for the meta meta-model of DL. Perhaps we can discover this only if we work up the Capability levels of Deep Learning intelligence. DARPA has a program that is researching this topic \u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d. I hope to refine this idea over time.\n\u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d.\nSee Deep Learning Design Patterns for more details or visit \u201cIntuition Machine\u201d to keep abreast about the latest developments.\nFor more on this, read \u201cThe Deep Learning Playbook\u201d\n"
  },
  {
    "title": "The Meta Model and Meta Meta-Model of Deep Learning",
    "content": "The Meta Model and Meta Meta-Model of Deep Learning\nCredit: Inception (2010) http://www.imdb.com/title/tt1375666/\nThe model for deep learning consists of a computational graph that are most conveniently constructed by composing layers with other layers. Most introductory texts emphasize the individual neuron, but in practice it is the collective behavior of a layer of neurons that is important. So from an abstraction perspective, the layer is the right level to think about.\nUnderneath these layers are the computational graph, it\u2019s main purpose is to orchestrate the computation of the forward and backward phases of the network. From the perspective of optimizing the performance, this is an important abstraction to have. However, it is not at the ideal level to reason how it all should work.\nDeep Learning frameworks have evolved to develop models that ease construction of DL architectures. Theano has Blocks, Lasagne and Keras. Tensorflow has Keras and TF-Slim. Keras was originally inspired by the simplicity of Torch, so by default has a high-level modular API. Many other less popular frameworks like Nervana, CNTK, MXNet and Chainer do have high level model APIs. All these APIs however describe models. What then is a Deep Learning meta-model? Is there even a meta meta-model?\nFigure: This is what a Deep Learning model looks like.\nLet\u2019s explore first how a meta-model looks like. A good example is in the UML domain of Object Oriented Design. This is the UML metal model:\nCredit: Eclipse ATL project\nThis makes it clear that Layers, Objectives, Activations, Optimizers, Metrics in the Keras APIs are the meta-models for Deep Learning. That\u2019s not too difficult a concept to understand.\nFigure. Deep Learning Meta Model\nConventionally, an Objective is a function and an Optimizer is an algorithm. However, what if we think of them instead as also being models. In that case we have the following:\nFigure. Make everything into networks\nThis definitely is getting a whole lot more complicated. The objective function has become a neural network and the optimizer has also become a neural network. The first reaction to this is, has this kind of architecture been tested before? It\u2019s possible someone is already writing this paper. That\u2019s because an objective function that is a neural network is equivalent to the Discriminator in a Generative Adversarial Network (GAN) and an Optimizer being a neural network is precisely what a meta-learner is about. So this idea is not fantastically out of mainstream research.\nThe second reaction to this is, shouldn\u2019t we make everything neural networks and be done? There are still boxes in the diagram that are still functions and algorithms. The Objective\u2019s optimizer is one and there are 3 others. Once you do that, there\u2019s nothing else left that a designer needs to define! There are no functions, everything is learned from scratch!!\nSo a meta-model where everything is a neural network looks this:\nFigure. Deep Learning Meta-Model\nWhere the mode is broken apart into 3 parts just for clarity. Alternatively, it looks like this:\nFigure. Deep Learning Meta-Model\nWhat this makes abundantly clear however is that the kinds of layers that are available come from a fixed set (i.e. fully connected, convolution, LSTM etc.). There are in fact research papers that exploit this notion of selecting different kinds of layers to generate DL architectures( see: \u201cThe Unreasonable Effectiveness of Randomness\u201d ). A DL meta-model language serves as the lego blocks of an exploratory RL based system. This can generate multiple DL meta-model instances to optimize for the best architecture. That is a reflection of the importance of Deep Learning Patterns. Before you can generate architectures, you have to know what building blocks are available for exploitation.\nNow, if we make a quantum leap into meta meta-model of Deep Learning. What should that look like?\nLet\u2019s look at how OMG\u2019s UML specification describes the meta meta-model level (i.e. M3):\nhttps://en.wikipedia.org/wiki/Meta-Object_Facility\nThe M3 level has a simplified structure that only includes the class. Following an analogous prescription, we thus have the meta meta-model of Deep Learning defined by the following:\nDeep Learning Meta Meta-Model\nDespite the simpleness of the depiction, the interpretation of this is quite interesting. You see, this is a meta object that an instance of which is the conventional DL meta-model. These are the abstract concepts that define how to generate new DL architectures. More specifically, it is the language that defines the creation of new DL models such as a convolution network or a autoregressive network. When you work at this level, you essentially generate new kinds of DL architectures. This is what many DL researchers actually do for a living, designing new novel models.\nThere is one important concept to remember here though, the instance, model, meta-model and meta meta-model distinction are concepts that we\u2019ve invented to better understand the nature of language and specification. This concept that is not essentially and likely does not exists in separate form in reality. As an example, there are many programming languages that do not have a distinction between instance data and model data. Languages like Lisp are like this, where everything is just data, there is not distinction between code and data.\nThe idea of \u201ccode is data\u201d applied to DL is equivalent to saying that the DL architecture are representations that can be learned. We as humans require the concept of a meta meta-model to get a better handle of the complex recursive self-describing nature of DL systems. It would be interesting know what the language of the meta meta-model should look like. Unfortunately, if this language is one that is learned by a machine, then it may likely be as inscrutable as any other learned representation. See: \u201cThe Only Way to Make DL Interpretable\u201d.\nIt is my suspicion though that this meta meta-model approach if pursued in greater detail may the key in locking \u201cUnsupervised learning\u201d or alternatively \u201cPredictive learning\u201d. Perhaps our limited human brains cannot figure this out. However armed with meta-learning capabilities, it may be possible for machines to continually self improve upon themselves. See \u201c Meta-Unsupervised-Learning: A supervised approach to unsupervised learning\u201d for an early take on this approach.\nThe one reason that this may not work however is that the vocabulary or language that is the is limited (see: Canonical Patterns) and therefore \u201cpredictive learning\u201d is not derivable from this bootstrapping method. Meta-learners today discover can only the weights and the weights are just parameters of a fixed DL model. A discovery, even through evolutionary methods, can only happen if the genesis vocabulary is at the correct level. Evolution appears to be a Meta Metal-Model process.\nThere is plenty that is missing in our understanding of the language for the meta meta-model of DL. Perhaps we can discover this only if we work up the Capability levels of Deep Learning intelligence. DARPA has a program that is researching this topic \u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d. I hope to refine this idea over time.\n\u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d.\nSee Deep Learning Design Patterns for more details or visit \u201cIntuition Machine\u201d to keep abreast about the latest developments.\nFor more on this, read \u201cThe Deep Learning Playbook\u201d\n"
  },
  {
    "title": "The Meta Model and Meta Meta-Model of Deep Learning",
    "content": "The Meta Model and Meta Meta-Model of Deep Learning\nCredit: Inception (2010) http://www.imdb.com/title/tt1375666/\nThe model for deep learning consists of a computational graph that are most conveniently constructed by composing layers with other layers. Most introductory texts emphasize the individual neuron, but in practice it is the collective behavior of a layer of neurons that is important. So from an abstraction perspective, the layer is the right level to think about.\nUnderneath these layers are the computational graph, it\u2019s main purpose is to orchestrate the computation of the forward and backward phases of the network. From the perspective of optimizing the performance, this is an important abstraction to have. However, it is not at the ideal level to reason how it all should work.\nDeep Learning frameworks have evolved to develop models that ease construction of DL architectures. Theano has Blocks, Lasagne and Keras. Tensorflow has Keras and TF-Slim. Keras was originally inspired by the simplicity of Torch, so by default has a high-level modular API. Many other less popular frameworks like Nervana, CNTK, MXNet and Chainer do have high level model APIs. All these APIs however describe models. What then is a Deep Learning meta-model? Is there even a meta meta-model?\nFigure: This is what a Deep Learning model looks like.\nLet\u2019s explore first how a meta-model looks like. A good example is in the UML domain of Object Oriented Design. This is the UML metal model:\nCredit: Eclipse ATL project\nThis makes it clear that Layers, Objectives, Activations, Optimizers, Metrics in the Keras APIs are the meta-models for Deep Learning. That\u2019s not too difficult a concept to understand.\nFigure. Deep Learning Meta Model\nConventionally, an Objective is a function and an Optimizer is an algorithm. However, what if we think of them instead as also being models. In that case we have the following:\nFigure. Make everything into networks\nThis definitely is getting a whole lot more complicated. The objective function has become a neural network and the optimizer has also become a neural network. The first reaction to this is, has this kind of architecture been tested before? It\u2019s possible someone is already writing this paper. That\u2019s because an objective function that is a neural network is equivalent to the Discriminator in a Generative Adversarial Network (GAN) and an Optimizer being a neural network is precisely what a meta-learner is about. So this idea is not fantastically out of mainstream research.\nThe second reaction to this is, shouldn\u2019t we make everything neural networks and be done? There are still boxes in the diagram that are still functions and algorithms. The Objective\u2019s optimizer is one and there are 3 others. Once you do that, there\u2019s nothing else left that a designer needs to define! There are no functions, everything is learned from scratch!!\nSo a meta-model where everything is a neural network looks this:\nFigure. Deep Learning Meta-Model\nWhere the mode is broken apart into 3 parts just for clarity. Alternatively, it looks like this:\nFigure. Deep Learning Meta-Model\nWhat this makes abundantly clear however is that the kinds of layers that are available come from a fixed set (i.e. fully connected, convolution, LSTM etc.). There are in fact research papers that exploit this notion of selecting different kinds of layers to generate DL architectures( see: \u201cThe Unreasonable Effectiveness of Randomness\u201d ). A DL meta-model language serves as the lego blocks of an exploratory RL based system. This can generate multiple DL meta-model instances to optimize for the best architecture. That is a reflection of the importance of Deep Learning Patterns. Before you can generate architectures, you have to know what building blocks are available for exploitation.\nNow, if we make a quantum leap into meta meta-model of Deep Learning. What should that look like?\nLet\u2019s look at how OMG\u2019s UML specification describes the meta meta-model level (i.e. M3):\nhttps://en.wikipedia.org/wiki/Meta-Object_Facility\nThe M3 level has a simplified structure that only includes the class. Following an analogous prescription, we thus have the meta meta-model of Deep Learning defined by the following:\nDeep Learning Meta Meta-Model\nDespite the simpleness of the depiction, the interpretation of this is quite interesting. You see, this is a meta object that an instance of which is the conventional DL meta-model. These are the abstract concepts that define how to generate new DL architectures. More specifically, it is the language that defines the creation of new DL models such as a convolution network or a autoregressive network. When you work at this level, you essentially generate new kinds of DL architectures. This is what many DL researchers actually do for a living, designing new novel models.\nThere is one important concept to remember here though, the instance, model, meta-model and meta meta-model distinction are concepts that we\u2019ve invented to better understand the nature of language and specification. This concept that is not essentially and likely does not exists in separate form in reality. As an example, there are many programming languages that do not have a distinction between instance data and model data. Languages like Lisp are like this, where everything is just data, there is not distinction between code and data.\nThe idea of \u201ccode is data\u201d applied to DL is equivalent to saying that the DL architecture are representations that can be learned. We as humans require the concept of a meta meta-model to get a better handle of the complex recursive self-describing nature of DL systems. It would be interesting know what the language of the meta meta-model should look like. Unfortunately, if this language is one that is learned by a machine, then it may likely be as inscrutable as any other learned representation. See: \u201cThe Only Way to Make DL Interpretable\u201d.\nIt is my suspicion though that this meta meta-model approach if pursued in greater detail may the key in locking \u201cUnsupervised learning\u201d or alternatively \u201cPredictive learning\u201d. Perhaps our limited human brains cannot figure this out. However armed with meta-learning capabilities, it may be possible for machines to continually self improve upon themselves. See \u201c Meta-Unsupervised-Learning: A supervised approach to unsupervised learning\u201d for an early take on this approach.\nThe one reason that this may not work however is that the vocabulary or language that is the is limited (see: Canonical Patterns) and therefore \u201cpredictive learning\u201d is not derivable from this bootstrapping method. Meta-learners today discover can only the weights and the weights are just parameters of a fixed DL model. A discovery, even through evolutionary methods, can only happen if the genesis vocabulary is at the correct level. Evolution appears to be a Meta Metal-Model process.\nThere is plenty that is missing in our understanding of the language for the meta meta-model of DL. Perhaps we can discover this only if we work up the Capability levels of Deep Learning intelligence. DARPA has a program that is researching this topic \u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d. I hope to refine this idea over time.\n\u201cDARPA goes \u2018Meta\u2019 with Machine Learning for Machine Learning\u201d.\nSee Deep Learning Design Patterns for more details or visit \u201cIntuition Machine\u201d to keep abreast about the latest developments.\nFor more on this, read \u201cThe Deep Learning Playbook\u201d\n"
  },
  {
    "title": "Top 10 Tips for the Data Science Team To Succeed",
    "content": "Top 10 Tips for the Data Science Team To Succeed\n1. Get Executive Ownership\nOne of the important contributing factors to any project is getting executive buy-in. It is your job as a data science software manager or project manager to get your executives to believe for your mission. Without them, your project will not cross on.\n2. Gain the trust of your peers\nMany of the managers don\u2019t consider their information. They need new dashboards, data science teams, the complete nine yards. If you can\u2019t even consider your statistics. Prefer a quote from Sherlock Holmes who said about how statistics is the foundation for the constructing blocks of wondering. If that is real, and you don\u2019t consider the residence you have got built. It will fall on pinnacle of you. Get your managers to agree with you and your facts!\n3. First implement a simple project successfully\nEveryone desires to broaden the following Google or Facebook set of rules. If your team is simply beginning out and also you need them to be successful start small. Once you get that first win under your belt. Executives could be begging you to help them with everything. Then you\u2019ll need to paintings on making sure your projects are bombarded by means of requests all the time, or at least, simplest the proper projects are being worked on.\n4. Standardize your data science procedures\nData science has quite a few cool technology and tools that permit for extremely good perception. However, like software engineering, even with all of the cool matters you could do. Without techniques, you may fall in the back of projects, make terrible products and fail to maintain finish initiatives. This manner you need to report your approaches. It seems like a waste of time, till you begin having inner breakdowns of tasks.\n5. Play nicely with different departments\nEvery commercial enterprise is a team game. You have accounting, finance, operations, sales and all the other departments that your team desires to work with. They all commonly have their very own data warehouse and also you want that information! If you\u2019re fortunate, there is one primary crew that manages all the databases. Even if that is authentic. I still need to get the information from a couple of groups. In addition, all those teams will likely want to have a few necessities in your tasks. So make certain to play nice.\n6. Build a prototype first for early purchase-in\nBuild a prototype (positive, in python)! Show your team and your supervisor what it can do. People want motion, not just theories and phrases. Set up a prototype, if you may, get actual information. If you can\u2019t then pump it with some statistics but make sure the functionality is there. Make it tangible, interactive, and actionable!\n7. Design for robustness and maintainability\nWe can\u2019t pressure this sufficient. Make sure something dashboard you build, technique you place in the vicinity, or algorithm you broaden is maintainable. If you go away the enterprise the next day. Will the project still work? Seriously! People will in case you left at the back of no documentation, and never shared your code.\n8. Get a Data Science Guide\nThere is quite a few statistics technology consulting businesses with a view to increasing a facts technological know-how manual of right enterprise practices to your team. This would require they check your team\u2019s modern-day status and work with them to recognize where they might be greater powerful. Often instances that is skipped by maximum teams, so it is beneficial to usher in outside assistance.\n9. Collect a lot of smooth facts as possible\nData comes from all exceptional sources. You can get it from inner warehouses, outside APIs and pretty much anywhere. Gather as tons of it as you can, and ensure it\u2019s far managed and clean.\n10. Make a decision, give an actual opinion\nAs a data scientist, you have power. You have data that means you can make conclusions with confidence.\n"
  },
  {
    "title": "Top 10 Tips for the Data Science Team To Succeed",
    "content": "Top 10 Tips for the Data Science Team To Succeed\n1. Get Executive Ownership\nOne of the important contributing factors to any project is getting executive buy-in. It is your job as a data science software manager or project manager to get your executives to believe for your mission. Without them, your project will not cross on.\n2. Gain the trust of your peers\nMany of the managers don\u2019t consider their information. They need new dashboards, data science teams, the complete nine yards. If you can\u2019t even consider your statistics. Prefer a quote from Sherlock Holmes who said about how statistics is the foundation for the constructing blocks of wondering. If that is real, and you don\u2019t consider the residence you have got built. It will fall on pinnacle of you. Get your managers to agree with you and your facts!\n3. First implement a simple project successfully\nEveryone desires to broaden the following Google or Facebook set of rules. If your team is simply beginning out and also you need them to be successful start small. Once you get that first win under your belt. Executives could be begging you to help them with everything. Then you\u2019ll need to paintings on making sure your projects are bombarded by means of requests all the time, or at least, simplest the proper projects are being worked on.\n4. Standardize your data science procedures\nData science has quite a few cool technology and tools that permit for extremely good perception. However, like software engineering, even with all of the cool matters you could do. Without techniques, you may fall in the back of projects, make terrible products and fail to maintain finish initiatives. This manner you need to report your approaches. It seems like a waste of time, till you begin having inner breakdowns of tasks.\n5. Play nicely with different departments\nEvery commercial enterprise is a team game. You have accounting, finance, operations, sales and all the other departments that your team desires to work with. They all commonly have their very own data warehouse and also you want that information! If you\u2019re fortunate, there is one primary crew that manages all the databases. Even if that is authentic. I still need to get the information from a couple of groups. In addition, all those teams will likely want to have a few necessities in your tasks. So make certain to play nice.\n6. Build a prototype first for early purchase-in\nBuild a prototype (positive, in python)! Show your team and your supervisor what it can do. People want motion, not just theories and phrases. Set up a prototype, if you may, get actual information. If you can\u2019t then pump it with some statistics but make sure the functionality is there. Make it tangible, interactive, and actionable!\n7. Design for robustness and maintainability\nWe can\u2019t pressure this sufficient. Make sure something dashboard you build, technique you place in the vicinity, or algorithm you broaden is maintainable. If you go away the enterprise the next day. Will the project still work? Seriously! People will in case you left at the back of no documentation, and never shared your code.\n8. Get a Data Science Guide\nThere is quite a few statistics technology consulting businesses with a view to increasing a facts technological know-how manual of right enterprise practices to your team. This would require they check your team\u2019s modern-day status and work with them to recognize where they might be greater powerful. Often instances that is skipped by maximum teams, so it is beneficial to usher in outside assistance.\n9. Collect a lot of smooth facts as possible\nData comes from all exceptional sources. You can get it from inner warehouses, outside APIs and pretty much anywhere. Gather as tons of it as you can, and ensure it\u2019s far managed and clean.\n10. Make a decision, give an actual opinion\nAs a data scientist, you have power. You have data that means you can make conclusions with confidence.\n"
  },
  {
    "title": "Top 10 Tips for the Data Science Team To Succeed",
    "content": "Top 10 Tips for the Data Science Team To Succeed\n1. Get Executive Ownership\nOne of the important contributing factors to any project is getting executive buy-in. It is your job as a data science software manager or project manager to get your executives to believe for your mission. Without them, your project will not cross on.\n2. Gain the trust of your peers\nMany of the managers don\u2019t consider their information. They need new dashboards, data science teams, the complete nine yards. If you can\u2019t even consider your statistics. Prefer a quote from Sherlock Holmes who said about how statistics is the foundation for the constructing blocks of wondering. If that is real, and you don\u2019t consider the residence you have got built. It will fall on pinnacle of you. Get your managers to agree with you and your facts!\n3. First implement a simple project successfully\nEveryone desires to broaden the following Google or Facebook set of rules. If your team is simply beginning out and also you need them to be successful start small. Once you get that first win under your belt. Executives could be begging you to help them with everything. Then you\u2019ll need to paintings on making sure your projects are bombarded by means of requests all the time, or at least, simplest the proper projects are being worked on.\n4. Standardize your data science procedures\nData science has quite a few cool technology and tools that permit for extremely good perception. However, like software engineering, even with all of the cool matters you could do. Without techniques, you may fall in the back of projects, make terrible products and fail to maintain finish initiatives. This manner you need to report your approaches. It seems like a waste of time, till you begin having inner breakdowns of tasks.\n5. Play nicely with different departments\nEvery commercial enterprise is a team game. You have accounting, finance, operations, sales and all the other departments that your team desires to work with. They all commonly have their very own data warehouse and also you want that information! If you\u2019re fortunate, there is one primary crew that manages all the databases. Even if that is authentic. I still need to get the information from a couple of groups. In addition, all those teams will likely want to have a few necessities in your tasks. So make certain to play nice.\n6. Build a prototype first for early purchase-in\nBuild a prototype (positive, in python)! Show your team and your supervisor what it can do. People want motion, not just theories and phrases. Set up a prototype, if you may, get actual information. If you can\u2019t then pump it with some statistics but make sure the functionality is there. Make it tangible, interactive, and actionable!\n7. Design for robustness and maintainability\nWe can\u2019t pressure this sufficient. Make sure something dashboard you build, technique you place in the vicinity, or algorithm you broaden is maintainable. If you go away the enterprise the next day. Will the project still work? Seriously! People will in case you left at the back of no documentation, and never shared your code.\n8. Get a Data Science Guide\nThere is quite a few statistics technology consulting businesses with a view to increasing a facts technological know-how manual of right enterprise practices to your team. This would require they check your team\u2019s modern-day status and work with them to recognize where they might be greater powerful. Often instances that is skipped by maximum teams, so it is beneficial to usher in outside assistance.\n9. Collect a lot of smooth facts as possible\nData comes from all exceptional sources. You can get it from inner warehouses, outside APIs and pretty much anywhere. Gather as tons of it as you can, and ensure it\u2019s far managed and clean.\n10. Make a decision, give an actual opinion\nAs a data scientist, you have power. You have data that means you can make conclusions with confidence.\n"
  },
  {
    "title": "Don\u2019t trust \u201cDo you trust this computer\u201d",
    "content": "Don\u2019t trust \u201cDo you trust this computer\u201d\nfrom http://doyoutrustthiscomputer.org/watch\nLast Friday the movie \u201cDo you trust this computer\u201d by Chris Paine was launched (free to watch until the end of Sunday, April 10). It is a documentary that deals with the potential consequences of Artificial Intelligence (AI), and repeats once more Elon Musk\u2019s often quoted warnings about the dangers of AI. In fact, a representative for Elon Musk has confirmed that Musk is bankrolling the movie\u2019s free online release.\nUnfortunately, even though it displays an impressive list of experts, the overall message is too biased and one-sided to be trusted.\nIn short, it is a dangerous distraction from the urgent need to act on achieving Responsible AI now!\nAnd here are some other reasons:\nIt is unclear who the makers expect as audience. It is too alarmist and dystopic a general audience, scary even. If the aim is participatory AI, and ensure everyone\u2019s commitment, then such a scary message will just achieve the opposite. It is time to act, not to scare. To look for solutions and work together across disciplines to get \u201cAI for good\u201d. This is not helpful. Great, great missed opportunity. It is time for Responsible AI, and this includes using proper narrative and frame the problems correctly.\nThe lineup of experts is impressive, including several of my own \u2018heroes\u2019. However of the 26 experts listed in the movie\u2019s website only 3 are women. This is a great missed opportunity for the film. There are many highly qualified female AI researchers and professionals, with equally, or even more, impressive contributions to the field as the experts interviewed. But most importantly, this leads to a skewed, biased, view of the field (see point 3.). A better representation of different views, multidisciplinary, multidimensional, gender and culturally balanced, would have led to a better narrative more balanced about risks and benefits of AI. \nIn order to deal with the impact of AI, about which the documentary is so concerned, is exactly to ensure, enforce and demand participation, inclusion and diversity.\nThe absurd underlying message that superintelligence is about winning. \nTrue intelligence is about social skills, about collaboration and contribution to a greater good, about getting others to work with us in order to survive and prosper. There is no reason to expect superintelligence (if at all possible, see point 4) will be different. I suppose that this obsession with \u2018winning\u2019 is a male thing, specially the generation of the men appearing in the movie who grew up play war-like games\u2026 But as a message this is unethical. Just shows the need for all of us to stand up for participation, inclusion, diversity in AI now!\nGeneral Artificial Intelligence and narrow AI are very, very different. The movie makes a mess of this, inexplicable given the quality of the experts. We already have many real applications of narrow AI. But intelligence is not a one-dimensional thing nor a cumulative one. It is not by improving on one application of AI or by combining many different narrow AI systems that will get us to artificial general superintelligence. Moreover, intelligence is not just about knowing, is about feeling, enjoying, pushing limits\u2026 I often run marathons. I don\u2019t doubt that is possible to build a \u2018running robot\u2019 but will it ever experience, and enjoy, what means to run a marathon, to push through the pain and enjoy it ?\nThe \u201cTerminator\u201d. Really, guys??? Are you expecting anyone takes this serious? Such a \u201cTerminator\u201d view on AI is misleading and unhelpful. An ethical approach to AI also means to ensure a correct view on its capabilities and to increase public awareness. I start seriously wandering if this fixation by tech corporations on dystopic views of the future are now a way from them to move public attention away from their practices and avoid regulation and corporate responsibility? Less \u201cterminator\u201d and more participation and inclusion is need. This too is AI ethics.\nThe movie is far too long, repetitive, boring even. The message \u201cResponsible AI\u201d deserved much better.\n"
  },
  {
    "title": "Don\u2019t trust \u201cDo you trust this computer\u201d",
    "content": "Don\u2019t trust \u201cDo you trust this computer\u201d\nfrom http://doyoutrustthiscomputer.org/watch\nLast Friday the movie \u201cDo you trust this computer\u201d by Chris Paine was launched (free to watch until the end of Sunday, April 10). It is a documentary that deals with the potential consequences of Artificial Intelligence (AI), and repeats once more Elon Musk\u2019s often quoted warnings about the dangers of AI. In fact, a representative for Elon Musk has confirmed that Musk is bankrolling the movie\u2019s free online release.\nUnfortunately, even though it displays an impressive list of experts, the overall message is too biased and one-sided to be trusted.\nIn short, it is a dangerous distraction from the urgent need to act on achieving Responsible AI now!\nAnd here are some other reasons:\nIt is unclear who the makers expect as audience. It is too alarmist and dystopic a general audience, scary even. If the aim is participatory AI, and ensure everyone\u2019s commitment, then such a scary message will just achieve the opposite. It is time to act, not to scare. To look for solutions and work together across disciplines to get \u201cAI for good\u201d. This is not helpful. Great, great missed opportunity. It is time for Responsible AI, and this includes using proper narrative and frame the problems correctly.\nThe lineup of experts is impressive, including several of my own \u2018heroes\u2019. However of the 26 experts listed in the movie\u2019s website only 3 are women. This is a great missed opportunity for the film. There are many highly qualified female AI researchers and professionals, with equally, or even more, impressive contributions to the field as the experts interviewed. But most importantly, this leads to a skewed, biased, view of the field (see point 3.). A better representation of different views, multidisciplinary, multidimensional, gender and culturally balanced, would have led to a better narrative more balanced about risks and benefits of AI. \nIn order to deal with the impact of AI, about which the documentary is so concerned, is exactly to ensure, enforce and demand participation, inclusion and diversity.\nThe absurd underlying message that superintelligence is about winning. \nTrue intelligence is about social skills, about collaboration and contribution to a greater good, about getting others to work with us in order to survive and prosper. There is no reason to expect superintelligence (if at all possible, see point 4) will be different. I suppose that this obsession with \u2018winning\u2019 is a male thing, specially the generation of the men appearing in the movie who grew up play war-like games\u2026 But as a message this is unethical. Just shows the need for all of us to stand up for participation, inclusion, diversity in AI now!\nGeneral Artificial Intelligence and narrow AI are very, very different. The movie makes a mess of this, inexplicable given the quality of the experts. We already have many real applications of narrow AI. But intelligence is not a one-dimensional thing nor a cumulative one. It is not by improving on one application of AI or by combining many different narrow AI systems that will get us to artificial general superintelligence. Moreover, intelligence is not just about knowing, is about feeling, enjoying, pushing limits\u2026 I often run marathons. I don\u2019t doubt that is possible to build a \u2018running robot\u2019 but will it ever experience, and enjoy, what means to run a marathon, to push through the pain and enjoy it ?\nThe \u201cTerminator\u201d. Really, guys??? Are you expecting anyone takes this serious? Such a \u201cTerminator\u201d view on AI is misleading and unhelpful. An ethical approach to AI also means to ensure a correct view on its capabilities and to increase public awareness. I start seriously wandering if this fixation by tech corporations on dystopic views of the future are now a way from them to move public attention away from their practices and avoid regulation and corporate responsibility? Less \u201cterminator\u201d and more participation and inclusion is need. This too is AI ethics.\nThe movie is far too long, repetitive, boring even. The message \u201cResponsible AI\u201d deserved much better.\n"
  },
  {
    "title": "Don\u2019t trust \u201cDo you trust this computer\u201d",
    "content": "Don\u2019t trust \u201cDo you trust this computer\u201d\nfrom http://doyoutrustthiscomputer.org/watch\nLast Friday the movie \u201cDo you trust this computer\u201d by Chris Paine was launched (free to watch until the end of Sunday, April 10). It is a documentary that deals with the potential consequences of Artificial Intelligence (AI), and repeats once more Elon Musk\u2019s often quoted warnings about the dangers of AI. In fact, a representative for Elon Musk has confirmed that Musk is bankrolling the movie\u2019s free online release.\nUnfortunately, even though it displays an impressive list of experts, the overall message is too biased and one-sided to be trusted.\nIn short, it is a dangerous distraction from the urgent need to act on achieving Responsible AI now!\nAnd here are some other reasons:\nIt is unclear who the makers expect as audience. It is too alarmist and dystopic a general audience, scary even. If the aim is participatory AI, and ensure everyone\u2019s commitment, then such a scary message will just achieve the opposite. It is time to act, not to scare. To look for solutions and work together across disciplines to get \u201cAI for good\u201d. This is not helpful. Great, great missed opportunity. It is time for Responsible AI, and this includes using proper narrative and frame the problems correctly.\nThe lineup of experts is impressive, including several of my own \u2018heroes\u2019. However of the 26 experts listed in the movie\u2019s website only 3 are women. This is a great missed opportunity for the film. There are many highly qualified female AI researchers and professionals, with equally, or even more, impressive contributions to the field as the experts interviewed. But most importantly, this leads to a skewed, biased, view of the field (see point 3.). A better representation of different views, multidisciplinary, multidimensional, gender and culturally balanced, would have led to a better narrative more balanced about risks and benefits of AI. \nIn order to deal with the impact of AI, about which the documentary is so concerned, is exactly to ensure, enforce and demand participation, inclusion and diversity.\nThe absurd underlying message that superintelligence is about winning. \nTrue intelligence is about social skills, about collaboration and contribution to a greater good, about getting others to work with us in order to survive and prosper. There is no reason to expect superintelligence (if at all possible, see point 4) will be different. I suppose that this obsession with \u2018winning\u2019 is a male thing, specially the generation of the men appearing in the movie who grew up play war-like games\u2026 But as a message this is unethical. Just shows the need for all of us to stand up for participation, inclusion, diversity in AI now!\nGeneral Artificial Intelligence and narrow AI are very, very different. The movie makes a mess of this, inexplicable given the quality of the experts. We already have many real applications of narrow AI. But intelligence is not a one-dimensional thing nor a cumulative one. It is not by improving on one application of AI or by combining many different narrow AI systems that will get us to artificial general superintelligence. Moreover, intelligence is not just about knowing, is about feeling, enjoying, pushing limits\u2026 I often run marathons. I don\u2019t doubt that is possible to build a \u2018running robot\u2019 but will it ever experience, and enjoy, what means to run a marathon, to push through the pain and enjoy it ?\nThe \u201cTerminator\u201d. Really, guys??? Are you expecting anyone takes this serious? Such a \u201cTerminator\u201d view on AI is misleading and unhelpful. An ethical approach to AI also means to ensure a correct view on its capabilities and to increase public awareness. I start seriously wandering if this fixation by tech corporations on dystopic views of the future are now a way from them to move public attention away from their practices and avoid regulation and corporate responsibility? Less \u201cterminator\u201d and more participation and inclusion is need. This too is AI ethics.\nThe movie is far too long, repetitive, boring even. The message \u201cResponsible AI\u201d deserved much better.\n"
  },
  {
    "title": "Don\u2019t trust \u201cDo you trust this computer\u201d",
    "content": "Don\u2019t trust \u201cDo you trust this computer\u201d\nfrom http://doyoutrustthiscomputer.org/watch\nLast Friday the movie \u201cDo you trust this computer\u201d by Chris Paine was launched (free to watch until the end of Sunday, April 10). It is a documentary that deals with the potential consequences of Artificial Intelligence (AI), and repeats once more Elon Musk\u2019s often quoted warnings about the dangers of AI. In fact, a representative for Elon Musk has confirmed that Musk is bankrolling the movie\u2019s free online release.\nUnfortunately, even though it displays an impressive list of experts, the overall message is too biased and one-sided to be trusted.\nIn short, it is a dangerous distraction from the urgent need to act on achieving Responsible AI now!\nAnd here are some other reasons:\nIt is unclear who the makers expect as audience. It is too alarmist and dystopic a general audience, scary even. If the aim is participatory AI, and ensure everyone\u2019s commitment, then such a scary message will just achieve the opposite. It is time to act, not to scare. To look for solutions and work together across disciplines to get \u201cAI for good\u201d. This is not helpful. Great, great missed opportunity. It is time for Responsible AI, and this includes using proper narrative and frame the problems correctly.\nThe lineup of experts is impressive, including several of my own \u2018heroes\u2019. However of the 26 experts listed in the movie\u2019s website only 3 are women. This is a great missed opportunity for the film. There are many highly qualified female AI researchers and professionals, with equally, or even more, impressive contributions to the field as the experts interviewed. But most importantly, this leads to a skewed, biased, view of the field (see point 3.). A better representation of different views, multidisciplinary, multidimensional, gender and culturally balanced, would have led to a better narrative more balanced about risks and benefits of AI. \nIn order to deal with the impact of AI, about which the documentary is so concerned, is exactly to ensure, enforce and demand participation, inclusion and diversity.\nThe absurd underlying message that superintelligence is about winning. \nTrue intelligence is about social skills, about collaboration and contribution to a greater good, about getting others to work with us in order to survive and prosper. There is no reason to expect superintelligence (if at all possible, see point 4) will be different. I suppose that this obsession with \u2018winning\u2019 is a male thing, specially the generation of the men appearing in the movie who grew up play war-like games\u2026 But as a message this is unethical. Just shows the need for all of us to stand up for participation, inclusion, diversity in AI now!\nGeneral Artificial Intelligence and narrow AI are very, very different. The movie makes a mess of this, inexplicable given the quality of the experts. We already have many real applications of narrow AI. But intelligence is not a one-dimensional thing nor a cumulative one. It is not by improving on one application of AI or by combining many different narrow AI systems that will get us to artificial general superintelligence. Moreover, intelligence is not just about knowing, is about feeling, enjoying, pushing limits\u2026 I often run marathons. I don\u2019t doubt that is possible to build a \u2018running robot\u2019 but will it ever experience, and enjoy, what means to run a marathon, to push through the pain and enjoy it ?\nThe \u201cTerminator\u201d. Really, guys??? Are you expecting anyone takes this serious? Such a \u201cTerminator\u201d view on AI is misleading and unhelpful. An ethical approach to AI also means to ensure a correct view on its capabilities and to increase public awareness. I start seriously wandering if this fixation by tech corporations on dystopic views of the future are now a way from them to move public attention away from their practices and avoid regulation and corporate responsibility? Less \u201cterminator\u201d and more participation and inclusion is need. This too is AI ethics.\nThe movie is far too long, repetitive, boring even. The message \u201cResponsible AI\u201d deserved much better.\n"
  },
  {
    "title": "Don\u2019t trust \u201cDo you trust this computer\u201d",
    "content": "Don\u2019t trust \u201cDo you trust this computer\u201d\nfrom http://doyoutrustthiscomputer.org/watch\nLast Friday the movie \u201cDo you trust this computer\u201d by Chris Paine was launched (free to watch until the end of Sunday, April 10). It is a documentary that deals with the potential consequences of Artificial Intelligence (AI), and repeats once more Elon Musk\u2019s often quoted warnings about the dangers of AI. In fact, a representative for Elon Musk has confirmed that Musk is bankrolling the movie\u2019s free online release.\nUnfortunately, even though it displays an impressive list of experts, the overall message is too biased and one-sided to be trusted.\nIn short, it is a dangerous distraction from the urgent need to act on achieving Responsible AI now!\nAnd here are some other reasons:\nIt is unclear who the makers expect as audience. It is too alarmist and dystopic a general audience, scary even. If the aim is participatory AI, and ensure everyone\u2019s commitment, then such a scary message will just achieve the opposite. It is time to act, not to scare. To look for solutions and work together across disciplines to get \u201cAI for good\u201d. This is not helpful. Great, great missed opportunity. It is time for Responsible AI, and this includes using proper narrative and frame the problems correctly.\nThe lineup of experts is impressive, including several of my own \u2018heroes\u2019. However of the 26 experts listed in the movie\u2019s website only 3 are women. This is a great missed opportunity for the film. There are many highly qualified female AI researchers and professionals, with equally, or even more, impressive contributions to the field as the experts interviewed. But most importantly, this leads to a skewed, biased, view of the field (see point 3.). A better representation of different views, multidisciplinary, multidimensional, gender and culturally balanced, would have led to a better narrative more balanced about risks and benefits of AI. \nIn order to deal with the impact of AI, about which the documentary is so concerned, is exactly to ensure, enforce and demand participation, inclusion and diversity.\nThe absurd underlying message that superintelligence is about winning. \nTrue intelligence is about social skills, about collaboration and contribution to a greater good, about getting others to work with us in order to survive and prosper. There is no reason to expect superintelligence (if at all possible, see point 4) will be different. I suppose that this obsession with \u2018winning\u2019 is a male thing, specially the generation of the men appearing in the movie who grew up play war-like games\u2026 But as a message this is unethical. Just shows the need for all of us to stand up for participation, inclusion, diversity in AI now!\nGeneral Artificial Intelligence and narrow AI are very, very different. The movie makes a mess of this, inexplicable given the quality of the experts. We already have many real applications of narrow AI. But intelligence is not a one-dimensional thing nor a cumulative one. It is not by improving on one application of AI or by combining many different narrow AI systems that will get us to artificial general superintelligence. Moreover, intelligence is not just about knowing, is about feeling, enjoying, pushing limits\u2026 I often run marathons. I don\u2019t doubt that is possible to build a \u2018running robot\u2019 but will it ever experience, and enjoy, what means to run a marathon, to push through the pain and enjoy it ?\nThe \u201cTerminator\u201d. Really, guys??? Are you expecting anyone takes this serious? Such a \u201cTerminator\u201d view on AI is misleading and unhelpful. An ethical approach to AI also means to ensure a correct view on its capabilities and to increase public awareness. I start seriously wandering if this fixation by tech corporations on dystopic views of the future are now a way from them to move public attention away from their practices and avoid regulation and corporate responsibility? Less \u201cterminator\u201d and more participation and inclusion is need. This too is AI ethics.\nThe movie is far too long, repetitive, boring even. The message \u201cResponsible AI\u201d deserved much better.\n"
  },
  {
    "title": "The Cultural Revolution: Robots and Trust",
    "content": "The Cultural Revolution: Robots and Trust\n\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn\u2019t a solution to that.\nSo what happens when we add robots?\nRobots and the Black Market\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora\u2019s box will likely be open because of this and it will also cause a major societal shift.\nThe first major landmark ship shift will likely be pleasure robots.\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\nFlipping Culture on its Head:\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn\u2019t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\nThe opening of Pandora\u2019s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women\u2019s higher desire for connection than men, and men\u2019s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\nChildren and Robots:\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential \u201cgold diggers\u201d. Children will be a deliberate choice, by both parties.\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\nThe Outcome:\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore\u2019s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\nConclusion:\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\n"
  },
  {
    "title": "The Cultural Revolution: Robots and Trust",
    "content": "The Cultural Revolution: Robots and Trust\n\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn\u2019t a solution to that.\nSo what happens when we add robots?\nRobots and the Black Market\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora\u2019s box will likely be open because of this and it will also cause a major societal shift.\nThe first major landmark ship shift will likely be pleasure robots.\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\nFlipping Culture on its Head:\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn\u2019t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\nThe opening of Pandora\u2019s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women\u2019s higher desire for connection than men, and men\u2019s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\nChildren and Robots:\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential \u201cgold diggers\u201d. Children will be a deliberate choice, by both parties.\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\nThe Outcome:\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore\u2019s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\nConclusion:\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\n"
  },
  {
    "title": "The Cultural Revolution: Robots and Trust",
    "content": "The Cultural Revolution: Robots and Trust\n\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn\u2019t a solution to that.\nSo what happens when we add robots?\nRobots and the Black Market\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora\u2019s box will likely be open because of this and it will also cause a major societal shift.\nThe first major landmark ship shift will likely be pleasure robots.\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\nFlipping Culture on its Head:\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn\u2019t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\nThe opening of Pandora\u2019s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women\u2019s higher desire for connection than men, and men\u2019s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\nChildren and Robots:\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential \u201cgold diggers\u201d. Children will be a deliberate choice, by both parties.\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\nThe Outcome:\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore\u2019s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\nConclusion:\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\n"
  },
  {
    "title": "The Cultural Revolution: Robots and Trust",
    "content": "The Cultural Revolution: Robots and Trust\n\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn\u2019t a solution to that.\nSo what happens when we add robots?\nRobots and the Black Market\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora\u2019s box will likely be open because of this and it will also cause a major societal shift.\nThe first major landmark ship shift will likely be pleasure robots.\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\nFlipping Culture on its Head:\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn\u2019t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\nThe opening of Pandora\u2019s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women\u2019s higher desire for connection than men, and men\u2019s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\nChildren and Robots:\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential \u201cgold diggers\u201d. Children will be a deliberate choice, by both parties.\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\nThe Outcome:\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore\u2019s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\nConclusion:\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\n"
  },
  {
    "title": "The Cultural Revolution: Robots and Trust",
    "content": "The Cultural Revolution: Robots and Trust\n\nIt is important to understand where we are to see what the future holds. We live in a time of hedonism, what people call a hookup culture. Of disposable relationships. The most likely outcome is for the hookup culture to evolve. To a society is a similar situation Japan finds itself now. With the commodification of relationships. People will burn out, once this has run its course. Humans will have to connect based on connection and the want for children, as everything else has been parsed for profit or commodified.\nThere are two things that have and will continue to hinder the hookup culture to this point, pregnancy and rape. While contraceptives have mitigated unwanted pregnancies, they are not fully effective. As to the latter subject, well, there likely isn\u2019t a solution to that.\nSo what happens when we add robots?\nRobots and the Black Market\nIt is important to tackle this issue as this will be one of the main reasons for the introduction of pleasure robots. Pandora\u2019s box will likely be open because of this and it will also cause a major societal shift.\nThe first major landmark ship shift will likely be pleasure robots.\nThe sex trade a multi-billion dollar industry. It commodifies everything about human relationships. It is important to understand it exists because people want it and it is illegal. While the hookup culture has devalued the price for sex it has also made it easier for the black market to go undetected. The black market makes a profit off the sex trade by indentured servitude. Individuals are forced through debt, violence and addiction to continue hooking. Illegal operations have high costs both implicit and explicit.\nRobots will be introduced to combat this illegal market. Robots offer many advantages they do not need food, water, sleep, and do not become pregnant. More importantly, they are not human, which means they can be considered property. Which, can be legally owned and mass produced. Mass production will cause the further commodification of sex. Which in-turn will likely drop its price to virtually zero as availability increases.\nThis will force the illegal trade to do either compete on a comparable price point, try to compete on another level, or go out of business. Given the costs stated previously much of the market will dry up unless a caste system occurs. While there may be a higher end market it will be a small niche compared to the behemoth it is currently.\nThus legalized robots will irrefutably damage the sex trade. However, the bigger consequence will be the commodification of sex.\nFlipping Culture on its Head:\nWidespread pleasure robots may kill the pornography industry if it does not evolve fast enough. While the industry has tried to adapt to the internet, few will continue to pay as the legalized widespread access of robots becomes available. The pornography industry will survive however if it adapts to Augmented and virtual reality, especially if sense integration occurs.\nReligions, particular Christians will be torn on this issue. I mention Christians specifically because their religion is what Western society stands on, due to its values, laws, history etc. Is it adultery, if it isn\u2019t human, let alone alive? Is a man or woman still chaste if only a robot has been involved? These and many other moral questions will need to be answered.\nThe opening of Pandora\u2019s box of robots, however, will eventually kill the hookup culture. As the prevalence of robots makes human interaction irrelevant. Men in particular who are disenfranchised by the current culture often drop out will now have an outlet. These individuals will be the first and will likely proselytize their lifestyle. Those who may respond with snark, I will remind that this is common in Japan. What starts as a taboo often becomes a societal norm.\nThis will not be without its consequences. The more men who switch from traditional relationships to mechanical ones leaves more women without partners. While some may be filled by mechanical ones undoubtedly it will not be at the same pace. This due to women\u2019s higher desire for connection than men, and men\u2019s higher desire for sex. One of which is easily fulfilled, the other much harder. Thus a glut of women will likely compete for a smaller amount of men. With more options, men will become more selective. To compete for a mate a war of escalation will occur. This combined with technology needing for a culture of trust will increase the likelihood women will return to chastity until marriage.\nThe legalization of these robots could, potentially prevent societal collapse and violence. As men and women who are unable to form social connections would now have an outlet for their unfulfilled needs. Individuals who have dropped out of society can now integrate to some degree. As the idea of pleasure robots becomes less stigmatized more people will begin to replace real relationships with robots. Robots will evolve to fulfill these new roles. Which will cause the further decline of relationships, marriage and birthrates.\nChildren and Robots:\nMale birth control methods are primitive at best. New innovations that reduce the downsides will increase the deliberate action to have children. Unplanned children will drop dramatically. This will also reduce potential \u201cgold diggers\u201d. Children will be a deliberate choice, by both parties.\nThus birthrates will plummet. Far more then anyone can possibly imagine. People will call it the end of humanity, however, they lack vision. Artificial wombs may be the answer as humans can be created without the need for a female host. The other answer resembles a Margaret Atwood novel due to a crypto caste system.\nArtificial wombs may also cause the idea of children to be more thought out, given the likelihood of genetic engineering. Children will be altered for optimum health. Mate selection in the future is quite likely to be based on genetics. Artificial wombs will likely lessen the maternal instinct of women and her potential child. Which will make the child more of a commodity than a unique being, due to less of a psychological attachment. Infanticide may increase due to this lack of connection.\nMaternity, as we know of today, may be reserved for the rich. As the expense of rearing a child normally will be extremely high when compared to an artificial womb. It is entirely possible a system of sperm banks, genetic engineering and artificial wombs for adoptive parents emerges. One that selects for genetic diversity. This to reduce the likelihood of mass extinction while removing undesirable traits.\nThe Outcome:\nPersonal robots will be first reserved for the wealth due to the newness and complexity. So robots will operate in a manner similar to medieval brothels. Designated areas, cordoned off, especially if Artificial Intelligence continues to grow at the speed of Moore\u2019s Law. Also due to the cost of ownership and maintenance. This will eventually move towards mass ownership as costs come down and the cultural stigma subsides. Crimes regarding adult prostitution and sexual violence will likely drop. Poverty may increase as prostitution becomes a less viable way to earn money.\nThe culture will eventually accept albeit begrudgingly the robots as they move from pleasure to romantic companion. Women will likely choose chastity if the above situation occurs, even if they have the full cultural, legal and independent rights to do otherwise. But why? A war of escalation. While the majority may live their lives how they like, a small group will counter the rise of robots by doing the opposite of what the group does.\nThis group will be more valued due to its rarity like all things, especially given the abundance of pleasure. This group will be hated however they will be more successful in obtaining relationships, all else equal. As a result, a cultural movement will emerge.\nIn return, these women will want longer courtships as they only have one chance due to their choice. Men will agree, as pleasure is bountiful. Courtship will occur again, as the value of relationships takes on new meaning. A culture of trust. Similar to the Victorian era will develop. Courtship and chastity will be normal. Chaperones of robots or via the Internet of things is entirely possible. Trust and in turn honour will be valued. This due to the changing nature of relationships and the irreversibility of cryptographic transactions. Who you spend your time with, personally and in business, matter more.\nThe irreversibility of cryptocurrency transactions will impact business. Marriage unions, the joining families to secure alliances and business ties may also occur once again. It sounds ridiculous now, but what is the likelihood you would rip off your family? I bet less likely than some random stranger. \nLineage and Dynasty two words very uncommon today will likely make a resurgence into the public consciousness and lexicon.\nConclusion:\nIt is difficult to predict the full extent of how robots will change human society. This article offers a brief glimpse into what it may look like. Robots will likely speed up the current culture of hedonism, which will cause an eventual reversal. There will be three main robots that will change human society, pleasure robots, companion robots and artificial wombs.\nOne thing is for certain they will be in every part of our lives, ubiquitous. It will often change unexpected things in ways we did not expect. It is possible men and women play more of an active role in courtship. With the ideas of connection and children being at the heart of a relationship. If so this would create more stable and longer lasting relationships.\n"
  },
  {
    "title": "A Little Snippet to Automate Web Scraping using Python and Selenium",
    "content": "A Little Snippet to Automate Web Scraping using Python and Selenium\n\u201cgrayscale photo of dew on spider web\u201d by R\u00faben Marques on Unsplash\nHi everybody , this little snippet will show you how to use a selenium lib in order to make an automated web scraping you can use to analyse data, find patterns,etc.\nThis snippet is the first of many other, each one will show you the next step, this one shows the automated connection in a web page, in this case, the facebook, the next will show you how to scraping a web page using beautiful soap, after we\u2019ll to download the data and keep it in a database and so on.\nAccording with the documentation, the selenium package is used to automate web browser interaction from Python and used to make automated tests.\nYou can find more information in https://pypi.org/project/selenium/\nSeveral browsers/drivers are supported (Firefox, Chrome, Internet Explorer), as well as the Remote protocol.\nSupporte Python versions: Python 2.7, 3.4+\nFor the installation you can use on of this 3 options:\nusing pip:\npip install -U selenium\nYou can download the source distribution from PyPI (e.g. selenium-3.14.0.tar.gz), unarchive it, and run:\npython setup.py install\nFinally if you\u2019re using Anaconda:\nconda install -c conda-forge selenium\nThe first thing we need to do is to import the libraries we\u2019ll use in this snippet.\nIn this case, for this first step, the most important one is the selenium where we\u2019ll make the automated connection.\nIn [38]:\nAfter importing the libs, in order to run the code, we need to choose the correct driver to use in.\nSelenium requires a driver to interface with the chosen browser.\nHere, we\u2019ll use the Chromium, but many other can be used.\nyou can find the driver here:\nyou can find more information in the Selenium project\u2019s page.\nWith Chrome driver installed, we need to set some option in order to run it.\nIn [39]:\nNext step is to set the url we\u2019ll use and get it with the driver.\nIn [40]:\nIn [41]:\nIn our case we have a form to fill in order to access the web page, so we need to get the html ids from the respective fields. It\u2019s easy to find them using the driver methods like find-element_by_id or find_elements_by_xpath.\nIn [42]:\nIn [43]:\nIn [46]:\nIn [ ]:\nIn [47]:\nIn the next topics we\u2019ll learn how to get the data using beautiful soap, store it in a database and analyse it using some tools like pandas, matplotlib, sklearn, etc.\nEnjoy the code, improve it if you want!\nSee you!!!!\n"
  },
  {
    "title": "A Little Snippet to Automate Web Scraping using Python and Selenium",
    "content": "A Little Snippet to Automate Web Scraping using Python and Selenium\n\u201cgrayscale photo of dew on spider web\u201d by R\u00faben Marques on Unsplash\nHi everybody , this little snippet will show you how to use a selenium lib in order to make an automated web scraping you can use to analyse data, find patterns,etc.\nThis snippet is the first of many other, each one will show you the next step, this one shows the automated connection in a web page, in this case, the facebook, the next will show you how to scraping a web page using beautiful soap, after we\u2019ll to download the data and keep it in a database and so on.\nAccording with the documentation, the selenium package is used to automate web browser interaction from Python and used to make automated tests.\nYou can find more information in https://pypi.org/project/selenium/\nSeveral browsers/drivers are supported (Firefox, Chrome, Internet Explorer), as well as the Remote protocol.\nSupporte Python versions: Python 2.7, 3.4+\nFor the installation you can use on of this 3 options:\nusing pip:\npip install -U selenium\nYou can download the source distribution from PyPI (e.g. selenium-3.14.0.tar.gz), unarchive it, and run:\npython setup.py install\nFinally if you\u2019re using Anaconda:\nconda install -c conda-forge selenium\nThe first thing we need to do is to import the libraries we\u2019ll use in this snippet.\nIn this case, for this first step, the most important one is the selenium where we\u2019ll make the automated connection.\nIn [38]:\nAfter importing the libs, in order to run the code, we need to choose the correct driver to use in.\nSelenium requires a driver to interface with the chosen browser.\nHere, we\u2019ll use the Chromium, but many other can be used.\nyou can find the driver here:\nyou can find more information in the Selenium project\u2019s page.\nWith Chrome driver installed, we need to set some option in order to run it.\nIn [39]:\nNext step is to set the url we\u2019ll use and get it with the driver.\nIn [40]:\nIn [41]:\nIn our case we have a form to fill in order to access the web page, so we need to get the html ids from the respective fields. It\u2019s easy to find them using the driver methods like find-element_by_id or find_elements_by_xpath.\nIn [42]:\nIn [43]:\nIn [46]:\nIn [ ]:\nIn [47]:\nIn the next topics we\u2019ll learn how to get the data using beautiful soap, store it in a database and analyse it using some tools like pandas, matplotlib, sklearn, etc.\nEnjoy the code, improve it if you want!\nSee you!!!!\n"
  },
  {
    "title": "A Little Snippet to Automate Web Scraping using Python and Selenium",
    "content": "A Little Snippet to Automate Web Scraping using Python and Selenium\n\u201cgrayscale photo of dew on spider web\u201d by R\u00faben Marques on Unsplash\nHi everybody , this little snippet will show you how to use a selenium lib in order to make an automated web scraping you can use to analyse data, find patterns,etc.\nThis snippet is the first of many other, each one will show you the next step, this one shows the automated connection in a web page, in this case, the facebook, the next will show you how to scraping a web page using beautiful soap, after we\u2019ll to download the data and keep it in a database and so on.\nAccording with the documentation, the selenium package is used to automate web browser interaction from Python and used to make automated tests.\nYou can find more information in https://pypi.org/project/selenium/\nSeveral browsers/drivers are supported (Firefox, Chrome, Internet Explorer), as well as the Remote protocol.\nSupporte Python versions: Python 2.7, 3.4+\nFor the installation you can use on of this 3 options:\nusing pip:\npip install -U selenium\nYou can download the source distribution from PyPI (e.g. selenium-3.14.0.tar.gz), unarchive it, and run:\npython setup.py install\nFinally if you\u2019re using Anaconda:\nconda install -c conda-forge selenium\nThe first thing we need to do is to import the libraries we\u2019ll use in this snippet.\nIn this case, for this first step, the most important one is the selenium where we\u2019ll make the automated connection.\nIn [38]:\nAfter importing the libs, in order to run the code, we need to choose the correct driver to use in.\nSelenium requires a driver to interface with the chosen browser.\nHere, we\u2019ll use the Chromium, but many other can be used.\nyou can find the driver here:\nyou can find more information in the Selenium project\u2019s page.\nWith Chrome driver installed, we need to set some option in order to run it.\nIn [39]:\nNext step is to set the url we\u2019ll use and get it with the driver.\nIn [40]:\nIn [41]:\nIn our case we have a form to fill in order to access the web page, so we need to get the html ids from the respective fields. It\u2019s easy to find them using the driver methods like find-element_by_id or find_elements_by_xpath.\nIn [42]:\nIn [43]:\nIn [46]:\nIn [ ]:\nIn [47]:\nIn the next topics we\u2019ll learn how to get the data using beautiful soap, store it in a database and analyse it using some tools like pandas, matplotlib, sklearn, etc.\nEnjoy the code, improve it if you want!\nSee you!!!!\n"
  },
  {
    "title": "A Little Snippet to Automate Web Scraping using Python and Selenium",
    "content": "A Little Snippet to Automate Web Scraping using Python and Selenium\n\u201cgrayscale photo of dew on spider web\u201d by R\u00faben Marques on Unsplash\nHi everybody , this little snippet will show you how to use a selenium lib in order to make an automated web scraping you can use to analyse data, find patterns,etc.\nThis snippet is the first of many other, each one will show you the next step, this one shows the automated connection in a web page, in this case, the facebook, the next will show you how to scraping a web page using beautiful soap, after we\u2019ll to download the data and keep it in a database and so on.\nAccording with the documentation, the selenium package is used to automate web browser interaction from Python and used to make automated tests.\nYou can find more information in https://pypi.org/project/selenium/\nSeveral browsers/drivers are supported (Firefox, Chrome, Internet Explorer), as well as the Remote protocol.\nSupporte Python versions: Python 2.7, 3.4+\nFor the installation you can use on of this 3 options:\nusing pip:\npip install -U selenium\nYou can download the source distribution from PyPI (e.g. selenium-3.14.0.tar.gz), unarchive it, and run:\npython setup.py install\nFinally if you\u2019re using Anaconda:\nconda install -c conda-forge selenium\nThe first thing we need to do is to import the libraries we\u2019ll use in this snippet.\nIn this case, for this first step, the most important one is the selenium where we\u2019ll make the automated connection.\nIn [38]:\nAfter importing the libs, in order to run the code, we need to choose the correct driver to use in.\nSelenium requires a driver to interface with the chosen browser.\nHere, we\u2019ll use the Chromium, but many other can be used.\nyou can find the driver here:\nyou can find more information in the Selenium project\u2019s page.\nWith Chrome driver installed, we need to set some option in order to run it.\nIn [39]:\nNext step is to set the url we\u2019ll use and get it with the driver.\nIn [40]:\nIn [41]:\nIn our case we have a form to fill in order to access the web page, so we need to get the html ids from the respective fields. It\u2019s easy to find them using the driver methods like find-element_by_id or find_elements_by_xpath.\nIn [42]:\nIn [43]:\nIn [46]:\nIn [ ]:\nIn [47]:\nIn the next topics we\u2019ll learn how to get the data using beautiful soap, store it in a database and analyse it using some tools like pandas, matplotlib, sklearn, etc.\nEnjoy the code, improve it if you want!\nSee you!!!!\n"
  },
  {
    "title": "A Little Snippet to Automate Web Scraping using Python and Selenium",
    "content": "A Little Snippet to Automate Web Scraping using Python and Selenium\n\u201cgrayscale photo of dew on spider web\u201d by R\u00faben Marques on Unsplash\nHi everybody , this little snippet will show you how to use a selenium lib in order to make an automated web scraping you can use to analyse data, find patterns,etc.\nThis snippet is the first of many other, each one will show you the next step, this one shows the automated connection in a web page, in this case, the facebook, the next will show you how to scraping a web page using beautiful soap, after we\u2019ll to download the data and keep it in a database and so on.\nAccording with the documentation, the selenium package is used to automate web browser interaction from Python and used to make automated tests.\nYou can find more information in https://pypi.org/project/selenium/\nSeveral browsers/drivers are supported (Firefox, Chrome, Internet Explorer), as well as the Remote protocol.\nSupporte Python versions: Python 2.7, 3.4+\nFor the installation you can use on of this 3 options:\nusing pip:\npip install -U selenium\nYou can download the source distribution from PyPI (e.g. selenium-3.14.0.tar.gz), unarchive it, and run:\npython setup.py install\nFinally if you\u2019re using Anaconda:\nconda install -c conda-forge selenium\nThe first thing we need to do is to import the libraries we\u2019ll use in this snippet.\nIn this case, for this first step, the most important one is the selenium where we\u2019ll make the automated connection.\nIn [38]:\nAfter importing the libs, in order to run the code, we need to choose the correct driver to use in.\nSelenium requires a driver to interface with the chosen browser.\nHere, we\u2019ll use the Chromium, but many other can be used.\nyou can find the driver here:\nyou can find more information in the Selenium project\u2019s page.\nWith Chrome driver installed, we need to set some option in order to run it.\nIn [39]:\nNext step is to set the url we\u2019ll use and get it with the driver.\nIn [40]:\nIn [41]:\nIn our case we have a form to fill in order to access the web page, so we need to get the html ids from the respective fields. It\u2019s easy to find them using the driver methods like find-element_by_id or find_elements_by_xpath.\nIn [42]:\nIn [43]:\nIn [46]:\nIn [ ]:\nIn [47]:\nIn the next topics we\u2019ll learn how to get the data using beautiful soap, store it in a database and analyse it using some tools like pandas, matplotlib, sklearn, etc.\nEnjoy the code, improve it if you want!\nSee you!!!!\n"
  },
  {
    "title": "Product Release Wrap-up July",
    "content": "\nProduct Release Wrap-up July\nOur new Unleash live Release Cozumel (v1.15) has just arrived with many new features and some bug fixes.\nTake off for a flight at https://cloud.unleashlive.com\nHere is the detailed run down:\nEnhanced Features:\nHD live video streaming latency decreased by another 20%. Benchmarking shows we are now about 50\u201380% faster than typical Youtube or facebook live stream. Read here for more details\nRefreshed A.I. live in-stream UI overlays.\nAdded in-stream video A.I. object count analytics.\n3D Modelling jobs allowance increased from 250 to up to 500 images on all Business subscriptions. Contact us for even higher allowances.\nFull screen Point cloud and 3D Model view for more immersive showcases.\nPoint cloud tools menu updated with enhanced measurements and rendering options.\nAdditional browser theme options for rich charcoal titanium background or bright white for 3D models.\nMore fluid touch and mouse interaction for 3D models to inspect any model location. Pan/tilt, pinch/zoom, rotate.\nFor even faster browser navigation, we added advanced model controls, enabling different lighting for models and low, med, high resolution of models.\nQuick view of latest media library items.\nExpanded inventory of user guides with detailed workflow steps and Youtube videos.\nEnhanced sharing functionality of VR models.\nSeveral new A.I. inference models from various 3rd party developers available for testing in connected HD live streams. This is still an experimental feature. For example: Improving track inspections with automation.\nA.I. developer sandbox features updated.\nBug Zapper:\nSeveral users reported issues with Google sign-in on older Chrome browser versions.\nSome users reported issues with lack of thumbnails on older Safari browser.\nLinked Unleash live Youtube user guides sometimes did not start playing with certain privacy settings in Chrome.\nSeveral Android 6 and iPhone 11 stability fixes.\n"
  },
  {
    "title": "Product Release Wrap-up July",
    "content": "\nProduct Release Wrap-up July\nOur new Unleash live Release Cozumel (v1.15) has just arrived with many new features and some bug fixes.\nTake off for a flight at https://cloud.unleashlive.com\nHere is the detailed run down:\nEnhanced Features:\nHD live video streaming latency decreased by another 20%. Benchmarking shows we are now about 50\u201380% faster than typical Youtube or facebook live stream. Read here for more details\nRefreshed A.I. live in-stream UI overlays.\nAdded in-stream video A.I. object count analytics.\n3D Modelling jobs allowance increased from 250 to up to 500 images on all Business subscriptions. Contact us for even higher allowances.\nFull screen Point cloud and 3D Model view for more immersive showcases.\nPoint cloud tools menu updated with enhanced measurements and rendering options.\nAdditional browser theme options for rich charcoal titanium background or bright white for 3D models.\nMore fluid touch and mouse interaction for 3D models to inspect any model location. Pan/tilt, pinch/zoom, rotate.\nFor even faster browser navigation, we added advanced model controls, enabling different lighting for models and low, med, high resolution of models.\nQuick view of latest media library items.\nExpanded inventory of user guides with detailed workflow steps and Youtube videos.\nEnhanced sharing functionality of VR models.\nSeveral new A.I. inference models from various 3rd party developers available for testing in connected HD live streams. This is still an experimental feature. For example: Improving track inspections with automation.\nA.I. developer sandbox features updated.\nBug Zapper:\nSeveral users reported issues with Google sign-in on older Chrome browser versions.\nSome users reported issues with lack of thumbnails on older Safari browser.\nLinked Unleash live Youtube user guides sometimes did not start playing with certain privacy settings in Chrome.\nSeveral Android 6 and iPhone 11 stability fixes.\n"
  },
  {
    "title": "Product Release Wrap-up July",
    "content": "\nProduct Release Wrap-up July\nOur new Unleash live Release Cozumel (v1.15) has just arrived with many new features and some bug fixes.\nTake off for a flight at https://cloud.unleashlive.com\nHere is the detailed run down:\nEnhanced Features:\nHD live video streaming latency decreased by another 20%. Benchmarking shows we are now about 50\u201380% faster than typical Youtube or facebook live stream. Read here for more details\nRefreshed A.I. live in-stream UI overlays.\nAdded in-stream video A.I. object count analytics.\n3D Modelling jobs allowance increased from 250 to up to 500 images on all Business subscriptions. Contact us for even higher allowances.\nFull screen Point cloud and 3D Model view for more immersive showcases.\nPoint cloud tools menu updated with enhanced measurements and rendering options.\nAdditional browser theme options for rich charcoal titanium background or bright white for 3D models.\nMore fluid touch and mouse interaction for 3D models to inspect any model location. Pan/tilt, pinch/zoom, rotate.\nFor even faster browser navigation, we added advanced model controls, enabling different lighting for models and low, med, high resolution of models.\nQuick view of latest media library items.\nExpanded inventory of user guides with detailed workflow steps and Youtube videos.\nEnhanced sharing functionality of VR models.\nSeveral new A.I. inference models from various 3rd party developers available for testing in connected HD live streams. This is still an experimental feature. For example: Improving track inspections with automation.\nA.I. developer sandbox features updated.\nBug Zapper:\nSeveral users reported issues with Google sign-in on older Chrome browser versions.\nSome users reported issues with lack of thumbnails on older Safari browser.\nLinked Unleash live Youtube user guides sometimes did not start playing with certain privacy settings in Chrome.\nSeveral Android 6 and iPhone 11 stability fixes.\n"
  },
  {
    "title": "AI Saturdays by AiDevNepal : A Review from participant by Raisha Shrestha",
    "content": "AI Saturdays by AiDevNepal : A Review from participant by Raisha Shrestha\nAI Saturdays , a global event conducted by AiDevNepal has been very successful till date. It has been heading forward with the motto \u201cLearn , Share and Grow together\u201d. It is a great opportunity for the learners to be a part of AI Saturdays and learn informative things related to Artificial Intelligence (AI) from the well experienced mentors who are professional AI developers of Nepal. AiDevNepal has taken a great step by taking initiation to conduct this global event \u201cAI Saturdays \u201c in Nepal. AIDevNepal has enlightened a number of AI enthusiasts by giving them opportunity to get involved in these workshops of AI Saturdays.\nI myself being a member of the workshop would love to share the experience I gathered. The first workshop involved interaction and knowledge sharing from well known experienced professionals in the field. In the later workshops we learnt about basics of AI , tools used for AI implementation, Basic Libraries and functions. Then in next workshops we learnt implementation of AI . We are in the process of learning. We learnt implementation of number of things like decision tree, deep learning and so on. We dealt with examples which fall under these categories. We got sound knowledge regarding topics which we had only surface level information. I am glad I got to be a part of these workshops and learnt this much of stuff.\nFrom very surface level, we are rising a step ahead in each workshop. This is making us very enthusiastic to learn more in the field of AI. As a result of this enthusiasm we are working on our project in AI as a assignment given to us by our mentors even on 1st March, when Holi is celebrated in Nepal. Instead of playing Holi people are working out in their codes to get more accuracy in their AI projects. This is great interest development. And AiDevNepal deserves a round of applause for being able to enlighten people with knowledge of AI and making them more enthusiast in the field.\nTill date 6 workshops have been conducted along with 2 interactive AI meetups. A number of workshops are yet to come and all of us are very excited to learn further. The organising team always encourage us to learn, share and grow together. So the entire team of the AiDevNepal including the organisers, and participants share a lot of knowledge with each other. We discuss regarding our confusions , share the discoveries or helpful tutorials found in our facebook group \u201cDN: AI Developers Nepal\u201d or \u201cAiDevNepal\u201d. In this way we actually learn , share and grow together.\nThe day when 14 workshops of AI Saturdays will be completed will be a day of pride for all of us. We participants will always try to share the knowledge gained from AiDevNepal by being associated with AiDevNepal itself. We shall try to make the motto of \u201cLearn, Share and Grow together\u201d by very much implementing it and making AI successfully established in Nepal some day. As a very good initiation has already begun and a number of enthusiasts are getting enlightened, that day is not too far. Cheers to AiDevNepal for this great initiation.\nAiDevNepal has prepared a number of materials for the workshop which is also in their github link mentioned below. Everyone are free to use the material but are requested to give reference to AiDevNepal whenever the material is used for the purpose of knowledge sharing. You can also subscribe to AiDevNepal in youtube and watch informative videos related to AI.\nWebsite of AiDevNepal : https://aidevnepal.github.io/\nGithub Link : https://github.com/AiDevNepal\nYoutube Channel Link: https://www.youtube.com/channel/UChk69vbMbxBPRutHpcDfe0Q\nOriginally published at medium.com on March 1, 2018.\n"
  },
  {
    "title": "Is the age of theory over as Machine Learning emerges?",
    "content": "Is the age of theory over as Machine Learning emerges?\nhttps://www.linkedin.com/pulse/age-theory-over-machine-learning-emerges-sam-ghosh/\n"
  },
  {
    "title": "Is the age of theory over as Machine Learning emerges?",
    "content": "Is the age of theory over as Machine Learning emerges?\nhttps://www.linkedin.com/pulse/age-theory-over-machine-learning-emerges-sam-ghosh/\n"
  },
  {
    "title": "Is the age of theory over as Machine Learning emerges?",
    "content": "Is the age of theory over as Machine Learning emerges?\nhttps://www.linkedin.com/pulse/age-theory-over-machine-learning-emerges-sam-ghosh/\n"
  },
  {
    "title": "AI based UI Development (AI-UI)",
    "content": "AI based UI Development (AI-UI)\nArtificial Intelligence (AI) is currently one of the most popular topics in the industry with seemingly endless applications in everything from matchmaking to self-driving cars. The most disturbing aspect of AI that we hear is it will result in massive job losses across industries. Can AI also affect the IT jobs? If so which skills will be impacted? When? How? These are some questions every software engineer must be seeking.\nCreative designers or business users comes up with UI (User Interface) ideas for application/ website on a sheet of paper or on a whiteboard or on their fancy graphics tablet. It is a job of an UI developer to convert the design idea/ wireframes into a working UI keeping the creative design intent in mind. This is one of the complex, time-consuming step in software development process. In this article, we will see an interesting example of applying AI for UI development. We will try to understand this by comparing it with human learning process and (over)simplifying the technology behind it.\nTypical hand drawn design for a UI\nMimicking our eyes and brain\nAs a child, we learn to observe and label the things around us. The learning happens through feedback provided by our parents and others. Our brain gets trained to look for some pattern, texture, color, size in a object to identify it. In AI, Convolutional Neural Network (CNN) is a class of deep neural network very effective at recognizing the objects in a given image.\n\nBasic idea behind CNN is to look for some shapes or patterns with the help of various filters in small parts of the image one at a time. Below figure shows applying 2 filters to look for slanted lines. Based on the filter results features are extracted. Finally by voting for the extracted features, the algorithm can conclude on the objects in the image.\n\nDescribing the image\nThe child starts uttering a single word label for each identified object, such as \u2018ball\u2019. Soon she will also learn to identify the relationship between the identified objects and describe it in a short sentences such as \u2018a red ball and a brown bat is on the lawn\u2019. The learning happens through a cycle of trial and errors.\nIn AI, for a given image constructing sentences from the word labels is a job of LSTM (Long Short Term Memory) networks. This process is called as image captioning.\n\nBelow are some examples of AI based image captioning. More such examples are at http://cs.stanford.edu/people/karpathy/deepimagesent/\n\nThe image captioning is achieved by appending LSTM network to the CNN discussed earlier. LSTM is very effective in language related tasks, because of their unique property of referring to their previous outputs. LSTM generates a word at a time. The next word is decided based on it\u2019s inputs, but also on previous words generated. e.g. in a sentence \u2018My name is John.\u2019, you can say \u2018John\u2019 only if earlier three words were \u2018My name is\u2019. The sequence of words forms into a sentence. Like any other neural network, LSTM goes through a learning at building the sentences.\nUI Development Process\nTypically UI development happens through following steps,\nCreative designers or business users of the application likes to hand draw their UI design ideas on a whiteboard or a graphic tablet or even a piece of tissue paper.\nDesigner uses wireframing tool on a computer to create the same design again. This is a redundant step.\nUI developers will translate the wireframes into a working UI code. The developers and designers goes through a iterative process till the expected UI is built. This step is a time consuming and repetitive process.\n\nAI based UI development\nWhat if the hand-drawn design idea is directly translated to a working UI? AI can do this. Below is an example of the same.\nUI generated with pix2code\nIn image captioning, AI describes objects (such as dog, horse) in a scene and builds a English sentence describing the objects and their relationship with each other.\nIn case of UI code, the UI design is like a scene, but instead of dog and horse will have UI objects like button, slider. Instead of English language, the objects will be described in UI code. The UI code is having a limited vocabulary (such as button, slider), and relationship between objects are described with few more words (such as position, hierarchy). Thus UI code generation can be considered specific use case of image captioning.\nUI code generation goes through two stages.\nTraining Stage:\nImagine a child (child_1) learning to look at many UI images and creating a list of the UI objects for each UI image. Other child (child_2) learns to read the descriptive code for the same UI. Third child (child_3) learns to find the relationship between the child_1 and child_2\u2019s learning. They together learn to observe a image and create a corresponding UI code.\n\nCNN takes role of Child_1, LSTM as Child_2 and another LSTM as Child_3. (For a complete technical explanation, refer the link for pix2code paper at end of the article.)\nSampling Stage:\n\nThe trained model is now ready to process hand drawn GUI drawing. The code context is updated for each prediction to contain the last predicted token. The resulting sequence of DSL tokens is compiled to the desired target language (e.g. for android, iOS, HTML etc.) using traditional compiler techniques.\nBenefits of AI-UI\nFor designers and developers, AI based solution would save critical time early on a project by rapid prototyping, boost iteration cycles, and eventually enable the development of better apps.\nThey will save on all the trivial, repetitive and redundant tasks.\nIt also will allow designers and developers to focus on what matters the most that is to bring value to the end-users.\nThe entry barrier to build apps will become really low. Learning to use a UI design tool takes time, learning to code takes even more time. However everyone can draw UI on paper. This will allow your grandma to go from an idea to a working UI running on her phone in a matter of seconds.\nCurrent and future state\nAs of now only few AI based UI development products (e.g. Uizard) are getting developed and not yet reached maturity to replace the human UI developers. But still they are good as an assistant for any UI developers. In coming years, we may see new approaches and improved AI products, where this assistant will take over the role of the experienced UI developer. It\u2019s time for UI developers to look at the changing trends and get ready for Reskilling.\nStill many of us may think generating UI code from the creative designers drawings is OK, but AI itself cannot come up with it\u2019s own creative UI designs. We still need artists, creative designers, Right? Maybe wrong! AI has Generative Adversarial Network (GAN) and Creative Adversarial Networks (CAN) have proven to generate art and sometimes better than humans. We will discuss this in some other article.\nReferences\npix2code: Generating Code from a Graphical User Interface Screenshot by Tony Beltramelli https://arxiv.org/pdf/1705.07962.pdf\nDeep Visual-Semantic Alignments for Generating Image Descriptions by Andrej Karpathy, Li Fei-Fei http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\n"
  },
  {
    "title": "AI based UI Development (AI-UI)",
    "content": "AI based UI Development (AI-UI)\nArtificial Intelligence (AI) is currently one of the most popular topics in the industry with seemingly endless applications in everything from matchmaking to self-driving cars. The most disturbing aspect of AI that we hear is it will result in massive job losses across industries. Can AI also affect the IT jobs? If so which skills will be impacted? When? How? These are some questions every software engineer must be seeking.\nCreative designers or business users comes up with UI (User Interface) ideas for application/ website on a sheet of paper or on a whiteboard or on their fancy graphics tablet. It is a job of an UI developer to convert the design idea/ wireframes into a working UI keeping the creative design intent in mind. This is one of the complex, time-consuming step in software development process. In this article, we will see an interesting example of applying AI for UI development. We will try to understand this by comparing it with human learning process and (over)simplifying the technology behind it.\nTypical hand drawn design for a UI\nMimicking our eyes and brain\nAs a child, we learn to observe and label the things around us. The learning happens through feedback provided by our parents and others. Our brain gets trained to look for some pattern, texture, color, size in a object to identify it. In AI, Convolutional Neural Network (CNN) is a class of deep neural network very effective at recognizing the objects in a given image.\n\nBasic idea behind CNN is to look for some shapes or patterns with the help of various filters in small parts of the image one at a time. Below figure shows applying 2 filters to look for slanted lines. Based on the filter results features are extracted. Finally by voting for the extracted features, the algorithm can conclude on the objects in the image.\n\nDescribing the image\nThe child starts uttering a single word label for each identified object, such as \u2018ball\u2019. Soon she will also learn to identify the relationship between the identified objects and describe it in a short sentences such as \u2018a red ball and a brown bat is on the lawn\u2019. The learning happens through a cycle of trial and errors.\nIn AI, for a given image constructing sentences from the word labels is a job of LSTM (Long Short Term Memory) networks. This process is called as image captioning.\n\nBelow are some examples of AI based image captioning. More such examples are at http://cs.stanford.edu/people/karpathy/deepimagesent/\n\nThe image captioning is achieved by appending LSTM network to the CNN discussed earlier. LSTM is very effective in language related tasks, because of their unique property of referring to their previous outputs. LSTM generates a word at a time. The next word is decided based on it\u2019s inputs, but also on previous words generated. e.g. in a sentence \u2018My name is John.\u2019, you can say \u2018John\u2019 only if earlier three words were \u2018My name is\u2019. The sequence of words forms into a sentence. Like any other neural network, LSTM goes through a learning at building the sentences.\nUI Development Process\nTypically UI development happens through following steps,\nCreative designers or business users of the application likes to hand draw their UI design ideas on a whiteboard or a graphic tablet or even a piece of tissue paper.\nDesigner uses wireframing tool on a computer to create the same design again. This is a redundant step.\nUI developers will translate the wireframes into a working UI code. The developers and designers goes through a iterative process till the expected UI is built. This step is a time consuming and repetitive process.\n\nAI based UI development\nWhat if the hand-drawn design idea is directly translated to a working UI? AI can do this. Below is an example of the same.\nUI generated with pix2code\nIn image captioning, AI describes objects (such as dog, horse) in a scene and builds a English sentence describing the objects and their relationship with each other.\nIn case of UI code, the UI design is like a scene, but instead of dog and horse will have UI objects like button, slider. Instead of English language, the objects will be described in UI code. The UI code is having a limited vocabulary (such as button, slider), and relationship between objects are described with few more words (such as position, hierarchy). Thus UI code generation can be considered specific use case of image captioning.\nUI code generation goes through two stages.\nTraining Stage:\nImagine a child (child_1) learning to look at many UI images and creating a list of the UI objects for each UI image. Other child (child_2) learns to read the descriptive code for the same UI. Third child (child_3) learns to find the relationship between the child_1 and child_2\u2019s learning. They together learn to observe a image and create a corresponding UI code.\n\nCNN takes role of Child_1, LSTM as Child_2 and another LSTM as Child_3. (For a complete technical explanation, refer the link for pix2code paper at end of the article.)\nSampling Stage:\n\nThe trained model is now ready to process hand drawn GUI drawing. The code context is updated for each prediction to contain the last predicted token. The resulting sequence of DSL tokens is compiled to the desired target language (e.g. for android, iOS, HTML etc.) using traditional compiler techniques.\nBenefits of AI-UI\nFor designers and developers, AI based solution would save critical time early on a project by rapid prototyping, boost iteration cycles, and eventually enable the development of better apps.\nThey will save on all the trivial, repetitive and redundant tasks.\nIt also will allow designers and developers to focus on what matters the most that is to bring value to the end-users.\nThe entry barrier to build apps will become really low. Learning to use a UI design tool takes time, learning to code takes even more time. However everyone can draw UI on paper. This will allow your grandma to go from an idea to a working UI running on her phone in a matter of seconds.\nCurrent and future state\nAs of now only few AI based UI development products (e.g. Uizard) are getting developed and not yet reached maturity to replace the human UI developers. But still they are good as an assistant for any UI developers. In coming years, we may see new approaches and improved AI products, where this assistant will take over the role of the experienced UI developer. It\u2019s time for UI developers to look at the changing trends and get ready for Reskilling.\nStill many of us may think generating UI code from the creative designers drawings is OK, but AI itself cannot come up with it\u2019s own creative UI designs. We still need artists, creative designers, Right? Maybe wrong! AI has Generative Adversarial Network (GAN) and Creative Adversarial Networks (CAN) have proven to generate art and sometimes better than humans. We will discuss this in some other article.\nReferences\npix2code: Generating Code from a Graphical User Interface Screenshot by Tony Beltramelli https://arxiv.org/pdf/1705.07962.pdf\nDeep Visual-Semantic Alignments for Generating Image Descriptions by Andrej Karpathy, Li Fei-Fei http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\n"
  },
  {
    "title": "AI based UI Development (AI-UI)",
    "content": "AI based UI Development (AI-UI)\nArtificial Intelligence (AI) is currently one of the most popular topics in the industry with seemingly endless applications in everything from matchmaking to self-driving cars. The most disturbing aspect of AI that we hear is it will result in massive job losses across industries. Can AI also affect the IT jobs? If so which skills will be impacted? When? How? These are some questions every software engineer must be seeking.\nCreative designers or business users comes up with UI (User Interface) ideas for application/ website on a sheet of paper or on a whiteboard or on their fancy graphics tablet. It is a job of an UI developer to convert the design idea/ wireframes into a working UI keeping the creative design intent in mind. This is one of the complex, time-consuming step in software development process. In this article, we will see an interesting example of applying AI for UI development. We will try to understand this by comparing it with human learning process and (over)simplifying the technology behind it.\nTypical hand drawn design for a UI\nMimicking our eyes and brain\nAs a child, we learn to observe and label the things around us. The learning happens through feedback provided by our parents and others. Our brain gets trained to look for some pattern, texture, color, size in a object to identify it. In AI, Convolutional Neural Network (CNN) is a class of deep neural network very effective at recognizing the objects in a given image.\n\nBasic idea behind CNN is to look for some shapes or patterns with the help of various filters in small parts of the image one at a time. Below figure shows applying 2 filters to look for slanted lines. Based on the filter results features are extracted. Finally by voting for the extracted features, the algorithm can conclude on the objects in the image.\n\nDescribing the image\nThe child starts uttering a single word label for each identified object, such as \u2018ball\u2019. Soon she will also learn to identify the relationship between the identified objects and describe it in a short sentences such as \u2018a red ball and a brown bat is on the lawn\u2019. The learning happens through a cycle of trial and errors.\nIn AI, for a given image constructing sentences from the word labels is a job of LSTM (Long Short Term Memory) networks. This process is called as image captioning.\n\nBelow are some examples of AI based image captioning. More such examples are at http://cs.stanford.edu/people/karpathy/deepimagesent/\n\nThe image captioning is achieved by appending LSTM network to the CNN discussed earlier. LSTM is very effective in language related tasks, because of their unique property of referring to their previous outputs. LSTM generates a word at a time. The next word is decided based on it\u2019s inputs, but also on previous words generated. e.g. in a sentence \u2018My name is John.\u2019, you can say \u2018John\u2019 only if earlier three words were \u2018My name is\u2019. The sequence of words forms into a sentence. Like any other neural network, LSTM goes through a learning at building the sentences.\nUI Development Process\nTypically UI development happens through following steps,\nCreative designers or business users of the application likes to hand draw their UI design ideas on a whiteboard or a graphic tablet or even a piece of tissue paper.\nDesigner uses wireframing tool on a computer to create the same design again. This is a redundant step.\nUI developers will translate the wireframes into a working UI code. The developers and designers goes through a iterative process till the expected UI is built. This step is a time consuming and repetitive process.\n\nAI based UI development\nWhat if the hand-drawn design idea is directly translated to a working UI? AI can do this. Below is an example of the same.\nUI generated with pix2code\nIn image captioning, AI describes objects (such as dog, horse) in a scene and builds a English sentence describing the objects and their relationship with each other.\nIn case of UI code, the UI design is like a scene, but instead of dog and horse will have UI objects like button, slider. Instead of English language, the objects will be described in UI code. The UI code is having a limited vocabulary (such as button, slider), and relationship between objects are described with few more words (such as position, hierarchy). Thus UI code generation can be considered specific use case of image captioning.\nUI code generation goes through two stages.\nTraining Stage:\nImagine a child (child_1) learning to look at many UI images and creating a list of the UI objects for each UI image. Other child (child_2) learns to read the descriptive code for the same UI. Third child (child_3) learns to find the relationship between the child_1 and child_2\u2019s learning. They together learn to observe a image and create a corresponding UI code.\n\nCNN takes role of Child_1, LSTM as Child_2 and another LSTM as Child_3. (For a complete technical explanation, refer the link for pix2code paper at end of the article.)\nSampling Stage:\n\nThe trained model is now ready to process hand drawn GUI drawing. The code context is updated for each prediction to contain the last predicted token. The resulting sequence of DSL tokens is compiled to the desired target language (e.g. for android, iOS, HTML etc.) using traditional compiler techniques.\nBenefits of AI-UI\nFor designers and developers, AI based solution would save critical time early on a project by rapid prototyping, boost iteration cycles, and eventually enable the development of better apps.\nThey will save on all the trivial, repetitive and redundant tasks.\nIt also will allow designers and developers to focus on what matters the most that is to bring value to the end-users.\nThe entry barrier to build apps will become really low. Learning to use a UI design tool takes time, learning to code takes even more time. However everyone can draw UI on paper. This will allow your grandma to go from an idea to a working UI running on her phone in a matter of seconds.\nCurrent and future state\nAs of now only few AI based UI development products (e.g. Uizard) are getting developed and not yet reached maturity to replace the human UI developers. But still they are good as an assistant for any UI developers. In coming years, we may see new approaches and improved AI products, where this assistant will take over the role of the experienced UI developer. It\u2019s time for UI developers to look at the changing trends and get ready for Reskilling.\nStill many of us may think generating UI code from the creative designers drawings is OK, but AI itself cannot come up with it\u2019s own creative UI designs. We still need artists, creative designers, Right? Maybe wrong! AI has Generative Adversarial Network (GAN) and Creative Adversarial Networks (CAN) have proven to generate art and sometimes better than humans. We will discuss this in some other article.\nReferences\npix2code: Generating Code from a Graphical User Interface Screenshot by Tony Beltramelli https://arxiv.org/pdf/1705.07962.pdf\nDeep Visual-Semantic Alignments for Generating Image Descriptions by Andrej Karpathy, Li Fei-Fei http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\n"
  },
  {
    "title": "AI based UI Development (AI-UI)",
    "content": "AI based UI Development (AI-UI)\nArtificial Intelligence (AI) is currently one of the most popular topics in the industry with seemingly endless applications in everything from matchmaking to self-driving cars. The most disturbing aspect of AI that we hear is it will result in massive job losses across industries. Can AI also affect the IT jobs? If so which skills will be impacted? When? How? These are some questions every software engineer must be seeking.\nCreative designers or business users comes up with UI (User Interface) ideas for application/ website on a sheet of paper or on a whiteboard or on their fancy graphics tablet. It is a job of an UI developer to convert the design idea/ wireframes into a working UI keeping the creative design intent in mind. This is one of the complex, time-consuming step in software development process. In this article, we will see an interesting example of applying AI for UI development. We will try to understand this by comparing it with human learning process and (over)simplifying the technology behind it.\nTypical hand drawn design for a UI\nMimicking our eyes and brain\nAs a child, we learn to observe and label the things around us. The learning happens through feedback provided by our parents and others. Our brain gets trained to look for some pattern, texture, color, size in a object to identify it. In AI, Convolutional Neural Network (CNN) is a class of deep neural network very effective at recognizing the objects in a given image.\n\nBasic idea behind CNN is to look for some shapes or patterns with the help of various filters in small parts of the image one at a time. Below figure shows applying 2 filters to look for slanted lines. Based on the filter results features are extracted. Finally by voting for the extracted features, the algorithm can conclude on the objects in the image.\n\nDescribing the image\nThe child starts uttering a single word label for each identified object, such as \u2018ball\u2019. Soon she will also learn to identify the relationship between the identified objects and describe it in a short sentences such as \u2018a red ball and a brown bat is on the lawn\u2019. The learning happens through a cycle of trial and errors.\nIn AI, for a given image constructing sentences from the word labels is a job of LSTM (Long Short Term Memory) networks. This process is called as image captioning.\n\nBelow are some examples of AI based image captioning. More such examples are at http://cs.stanford.edu/people/karpathy/deepimagesent/\n\nThe image captioning is achieved by appending LSTM network to the CNN discussed earlier. LSTM is very effective in language related tasks, because of their unique property of referring to their previous outputs. LSTM generates a word at a time. The next word is decided based on it\u2019s inputs, but also on previous words generated. e.g. in a sentence \u2018My name is John.\u2019, you can say \u2018John\u2019 only if earlier three words were \u2018My name is\u2019. The sequence of words forms into a sentence. Like any other neural network, LSTM goes through a learning at building the sentences.\nUI Development Process\nTypically UI development happens through following steps,\nCreative designers or business users of the application likes to hand draw their UI design ideas on a whiteboard or a graphic tablet or even a piece of tissue paper.\nDesigner uses wireframing tool on a computer to create the same design again. This is a redundant step.\nUI developers will translate the wireframes into a working UI code. The developers and designers goes through a iterative process till the expected UI is built. This step is a time consuming and repetitive process.\n\nAI based UI development\nWhat if the hand-drawn design idea is directly translated to a working UI? AI can do this. Below is an example of the same.\nUI generated with pix2code\nIn image captioning, AI describes objects (such as dog, horse) in a scene and builds a English sentence describing the objects and their relationship with each other.\nIn case of UI code, the UI design is like a scene, but instead of dog and horse will have UI objects like button, slider. Instead of English language, the objects will be described in UI code. The UI code is having a limited vocabulary (such as button, slider), and relationship between objects are described with few more words (such as position, hierarchy). Thus UI code generation can be considered specific use case of image captioning.\nUI code generation goes through two stages.\nTraining Stage:\nImagine a child (child_1) learning to look at many UI images and creating a list of the UI objects for each UI image. Other child (child_2) learns to read the descriptive code for the same UI. Third child (child_3) learns to find the relationship between the child_1 and child_2\u2019s learning. They together learn to observe a image and create a corresponding UI code.\n\nCNN takes role of Child_1, LSTM as Child_2 and another LSTM as Child_3. (For a complete technical explanation, refer the link for pix2code paper at end of the article.)\nSampling Stage:\n\nThe trained model is now ready to process hand drawn GUI drawing. The code context is updated for each prediction to contain the last predicted token. The resulting sequence of DSL tokens is compiled to the desired target language (e.g. for android, iOS, HTML etc.) using traditional compiler techniques.\nBenefits of AI-UI\nFor designers and developers, AI based solution would save critical time early on a project by rapid prototyping, boost iteration cycles, and eventually enable the development of better apps.\nThey will save on all the trivial, repetitive and redundant tasks.\nIt also will allow designers and developers to focus on what matters the most that is to bring value to the end-users.\nThe entry barrier to build apps will become really low. Learning to use a UI design tool takes time, learning to code takes even more time. However everyone can draw UI on paper. This will allow your grandma to go from an idea to a working UI running on her phone in a matter of seconds.\nCurrent and future state\nAs of now only few AI based UI development products (e.g. Uizard) are getting developed and not yet reached maturity to replace the human UI developers. But still they are good as an assistant for any UI developers. In coming years, we may see new approaches and improved AI products, where this assistant will take over the role of the experienced UI developer. It\u2019s time for UI developers to look at the changing trends and get ready for Reskilling.\nStill many of us may think generating UI code from the creative designers drawings is OK, but AI itself cannot come up with it\u2019s own creative UI designs. We still need artists, creative designers, Right? Maybe wrong! AI has Generative Adversarial Network (GAN) and Creative Adversarial Networks (CAN) have proven to generate art and sometimes better than humans. We will discuss this in some other article.\nReferences\npix2code: Generating Code from a Graphical User Interface Screenshot by Tony Beltramelli https://arxiv.org/pdf/1705.07962.pdf\nDeep Visual-Semantic Alignments for Generating Image Descriptions by Andrej Karpathy, Li Fei-Fei http://cs.stanford.edu/people/karpathy/cvpr2015.pdf\n"
  },
  {
    "title": "Can Technology Replace Record Companies?",
    "content": "Grow your learning @ incentivetheory.com\nCan Technology Replace Record Companies?\nThe music industry is a business theorist\u2019s dream. It is a great case study, because unlike many industries, it faces almost all the possible issues a market could face (regulatory hurdles, high visibility, innovative, fast paced, low barriers to entry, high barriers to sustainability). It reminds me of an internet accelerated version of the 1980s version of the disk drive industry.\n\nIn the wake of my recent article, I have had a few people share articles about the emergence of the company United Masters from stealth mode. For those of you that don\u2019t know, before I started at Sonos, I briefly worked on an application that competed in a similar space. From this experience, I learned that music analytics is a very competitive space with a laundry list of modularized niche suppliers (Swift & Next big sound for streaming analytics, MAX for paring artist for social analytics, WAVO for tour ads). Things to consider\u2026\nThe Customer Experience\nAs noted in my last article, the record labels\u2019 customer is the artist, not the music listener. A company\u2019s customer experience really matters. Taking out all the inefficiencies in the supply chain might actually affect a record company\u2019s ability to win business. If an independent artists gets big enough, they don\u2019t want to be treated like a commodity user of a technical platform; Artists and their teams are willing to pay for a luxury experience, especially if the experience comes at the expense of uncertain future gains.\nPeople are Loss Averse\nIn economics, it is known as the Prospect Theory. Prospect Theory states that people are loss averse, meaning people perceive losses more strongly than gains. If a small artist or team doesn\u2019t go with a big label now, they may not have the opportunity to go with them in the future. A potentially big loss if the artist fails. If United Masters can quantify and mitigate the monetary value lost if an act succeeds, they could persuade some managers to adopt the risk and cost associated with staying independent. Clearly articulating a value proposition for theoretical future gains is difficult.\nConflict of Interest\nIn management theory, it is known as the Realtor Effect. If a realtor is selling a house, they only get a small percent of the sale. Instead of fighting for incremental gains for the seller, the Realtor\u2019s time is better spent finding other houses to sell, despite whether the extra work is in the seller\u2019s best interest. People on the business side of an artists career are incentivized to have artist\u2019s work with a larger record company, because their dollar per hour inputed is more attractive. The business person is required they spend less time working with an act, but still sees attractive financial returns. The business person\u2019s time is better spent finding and signing new acts.\nPlatform\nIt\u2019s extremely difficult to build a platform based on assets you don\u2019t own. Surviving in a company\u2019s supply chain is difficult, because you are ultimately beholden to the owner of the content. United Masters doesn\u2019t own the Streaming Services\u2019 data or distribution network.\n\nTo The Point\nIf someone is going to disrupt the market with a low-end disruption, it would be an industry insider like United Masters\u2019 founder. There are two reasons here\u2026\nLongtime industry insider is the only person familiar enough with the inefficiencies that are actually crucial to win business.\nLow-end market disruption work in a B2B environment. Industry insiders know how to speak to the decision makers on the business side of an artist\u2019s career, which makes them more qualified to explain the value proposition to them.\nConclusion\nIf you read my article closely, you\u2019ll notice I don\u2019t take a stand on the viability of United Masters. I don\u2019t think asking the question \u201cDo you think the company will succeed?\u201d is the right question \u2014 I can\u2019t tell you if the company will succeed. I can tell you how the incentives work. However, just because the incentives line up for the company does not mean they will succeed. But if a company can understand the incentives, they can make the right decisions, but that is half the battle. The ability to design and implement creative solutions to leverage these incentives is what separates success from failure.\nIf you enjoyed, Don\u2019t forget to click and hold the \ud83d\udc4f so other people can find the article. Incentive Theory is a publication that focuses in data science and direct to consumer strategy.\n\n"
  },
  {
    "title": "Can Technology Replace Record Companies?",
    "content": "Grow your learning @ incentivetheory.com\nCan Technology Replace Record Companies?\nThe music industry is a business theorist\u2019s dream. It is a great case study, because unlike many industries, it faces almost all the possible issues a market could face (regulatory hurdles, high visibility, innovative, fast paced, low barriers to entry, high barriers to sustainability). It reminds me of an internet accelerated version of the 1980s version of the disk drive industry.\n\nIn the wake of my recent article, I have had a few people share articles about the emergence of the company United Masters from stealth mode. For those of you that don\u2019t know, before I started at Sonos, I briefly worked on an application that competed in a similar space. From this experience, I learned that music analytics is a very competitive space with a laundry list of modularized niche suppliers (Swift & Next big sound for streaming analytics, MAX for paring artist for social analytics, WAVO for tour ads). Things to consider\u2026\nThe Customer Experience\nAs noted in my last article, the record labels\u2019 customer is the artist, not the music listener. A company\u2019s customer experience really matters. Taking out all the inefficiencies in the supply chain might actually affect a record company\u2019s ability to win business. If an independent artists gets big enough, they don\u2019t want to be treated like a commodity user of a technical platform; Artists and their teams are willing to pay for a luxury experience, especially if the experience comes at the expense of uncertain future gains.\nPeople are Loss Averse\nIn economics, it is known as the Prospect Theory. Prospect Theory states that people are loss averse, meaning people perceive losses more strongly than gains. If a small artist or team doesn\u2019t go with a big label now, they may not have the opportunity to go with them in the future. A potentially big loss if the artist fails. If United Masters can quantify and mitigate the monetary value lost if an act succeeds, they could persuade some managers to adopt the risk and cost associated with staying independent. Clearly articulating a value proposition for theoretical future gains is difficult.\nConflict of Interest\nIn management theory, it is known as the Realtor Effect. If a realtor is selling a house, they only get a small percent of the sale. Instead of fighting for incremental gains for the seller, the Realtor\u2019s time is better spent finding other houses to sell, despite whether the extra work is in the seller\u2019s best interest. People on the business side of an artists career are incentivized to have artist\u2019s work with a larger record company, because their dollar per hour inputed is more attractive. The business person is required they spend less time working with an act, but still sees attractive financial returns. The business person\u2019s time is better spent finding and signing new acts.\nPlatform\nIt\u2019s extremely difficult to build a platform based on assets you don\u2019t own. Surviving in a company\u2019s supply chain is difficult, because you are ultimately beholden to the owner of the content. United Masters doesn\u2019t own the Streaming Services\u2019 data or distribution network.\n\nTo The Point\nIf someone is going to disrupt the market with a low-end disruption, it would be an industry insider like United Masters\u2019 founder. There are two reasons here\u2026\nLongtime industry insider is the only person familiar enough with the inefficiencies that are actually crucial to win business.\nLow-end market disruption work in a B2B environment. Industry insiders know how to speak to the decision makers on the business side of an artist\u2019s career, which makes them more qualified to explain the value proposition to them.\nConclusion\nIf you read my article closely, you\u2019ll notice I don\u2019t take a stand on the viability of United Masters. I don\u2019t think asking the question \u201cDo you think the company will succeed?\u201d is the right question \u2014 I can\u2019t tell you if the company will succeed. I can tell you how the incentives work. However, just because the incentives line up for the company does not mean they will succeed. But if a company can understand the incentives, they can make the right decisions, but that is half the battle. The ability to design and implement creative solutions to leverage these incentives is what separates success from failure.\nIf you enjoyed, Don\u2019t forget to click and hold the \ud83d\udc4f so other people can find the article. Incentive Theory is a publication that focuses in data science and direct to consumer strategy.\n\n"
  },
  {
    "title": "Can Technology Replace Record Companies?",
    "content": "Grow your learning @ incentivetheory.com\nCan Technology Replace Record Companies?\nThe music industry is a business theorist\u2019s dream. It is a great case study, because unlike many industries, it faces almost all the possible issues a market could face (regulatory hurdles, high visibility, innovative, fast paced, low barriers to entry, high barriers to sustainability). It reminds me of an internet accelerated version of the 1980s version of the disk drive industry.\n\nIn the wake of my recent article, I have had a few people share articles about the emergence of the company United Masters from stealth mode. For those of you that don\u2019t know, before I started at Sonos, I briefly worked on an application that competed in a similar space. From this experience, I learned that music analytics is a very competitive space with a laundry list of modularized niche suppliers (Swift & Next big sound for streaming analytics, MAX for paring artist for social analytics, WAVO for tour ads). Things to consider\u2026\nThe Customer Experience\nAs noted in my last article, the record labels\u2019 customer is the artist, not the music listener. A company\u2019s customer experience really matters. Taking out all the inefficiencies in the supply chain might actually affect a record company\u2019s ability to win business. If an independent artists gets big enough, they don\u2019t want to be treated like a commodity user of a technical platform; Artists and their teams are willing to pay for a luxury experience, especially if the experience comes at the expense of uncertain future gains.\nPeople are Loss Averse\nIn economics, it is known as the Prospect Theory. Prospect Theory states that people are loss averse, meaning people perceive losses more strongly than gains. If a small artist or team doesn\u2019t go with a big label now, they may not have the opportunity to go with them in the future. A potentially big loss if the artist fails. If United Masters can quantify and mitigate the monetary value lost if an act succeeds, they could persuade some managers to adopt the risk and cost associated with staying independent. Clearly articulating a value proposition for theoretical future gains is difficult.\nConflict of Interest\nIn management theory, it is known as the Realtor Effect. If a realtor is selling a house, they only get a small percent of the sale. Instead of fighting for incremental gains for the seller, the Realtor\u2019s time is better spent finding other houses to sell, despite whether the extra work is in the seller\u2019s best interest. People on the business side of an artists career are incentivized to have artist\u2019s work with a larger record company, because their dollar per hour inputed is more attractive. The business person is required they spend less time working with an act, but still sees attractive financial returns. The business person\u2019s time is better spent finding and signing new acts.\nPlatform\nIt\u2019s extremely difficult to build a platform based on assets you don\u2019t own. Surviving in a company\u2019s supply chain is difficult, because you are ultimately beholden to the owner of the content. United Masters doesn\u2019t own the Streaming Services\u2019 data or distribution network.\n\nTo The Point\nIf someone is going to disrupt the market with a low-end disruption, it would be an industry insider like United Masters\u2019 founder. There are two reasons here\u2026\nLongtime industry insider is the only person familiar enough with the inefficiencies that are actually crucial to win business.\nLow-end market disruption work in a B2B environment. Industry insiders know how to speak to the decision makers on the business side of an artist\u2019s career, which makes them more qualified to explain the value proposition to them.\nConclusion\nIf you read my article closely, you\u2019ll notice I don\u2019t take a stand on the viability of United Masters. I don\u2019t think asking the question \u201cDo you think the company will succeed?\u201d is the right question \u2014 I can\u2019t tell you if the company will succeed. I can tell you how the incentives work. However, just because the incentives line up for the company does not mean they will succeed. But if a company can understand the incentives, they can make the right decisions, but that is half the battle. The ability to design and implement creative solutions to leverage these incentives is what separates success from failure.\nIf you enjoyed, Don\u2019t forget to click and hold the \ud83d\udc4f so other people can find the article. Incentive Theory is a publication that focuses in data science and direct to consumer strategy.\n\n"
  },
  {
    "title": "Can Technology Replace Record Companies?",
    "content": "Grow your learning @ incentivetheory.com\nCan Technology Replace Record Companies?\nThe music industry is a business theorist\u2019s dream. It is a great case study, because unlike many industries, it faces almost all the possible issues a market could face (regulatory hurdles, high visibility, innovative, fast paced, low barriers to entry, high barriers to sustainability). It reminds me of an internet accelerated version of the 1980s version of the disk drive industry.\n\nIn the wake of my recent article, I have had a few people share articles about the emergence of the company United Masters from stealth mode. For those of you that don\u2019t know, before I started at Sonos, I briefly worked on an application that competed in a similar space. From this experience, I learned that music analytics is a very competitive space with a laundry list of modularized niche suppliers (Swift & Next big sound for streaming analytics, MAX for paring artist for social analytics, WAVO for tour ads). Things to consider\u2026\nThe Customer Experience\nAs noted in my last article, the record labels\u2019 customer is the artist, not the music listener. A company\u2019s customer experience really matters. Taking out all the inefficiencies in the supply chain might actually affect a record company\u2019s ability to win business. If an independent artists gets big enough, they don\u2019t want to be treated like a commodity user of a technical platform; Artists and their teams are willing to pay for a luxury experience, especially if the experience comes at the expense of uncertain future gains.\nPeople are Loss Averse\nIn economics, it is known as the Prospect Theory. Prospect Theory states that people are loss averse, meaning people perceive losses more strongly than gains. If a small artist or team doesn\u2019t go with a big label now, they may not have the opportunity to go with them in the future. A potentially big loss if the artist fails. If United Masters can quantify and mitigate the monetary value lost if an act succeeds, they could persuade some managers to adopt the risk and cost associated with staying independent. Clearly articulating a value proposition for theoretical future gains is difficult.\nConflict of Interest\nIn management theory, it is known as the Realtor Effect. If a realtor is selling a house, they only get a small percent of the sale. Instead of fighting for incremental gains for the seller, the Realtor\u2019s time is better spent finding other houses to sell, despite whether the extra work is in the seller\u2019s best interest. People on the business side of an artists career are incentivized to have artist\u2019s work with a larger record company, because their dollar per hour inputed is more attractive. The business person is required they spend less time working with an act, but still sees attractive financial returns. The business person\u2019s time is better spent finding and signing new acts.\nPlatform\nIt\u2019s extremely difficult to build a platform based on assets you don\u2019t own. Surviving in a company\u2019s supply chain is difficult, because you are ultimately beholden to the owner of the content. United Masters doesn\u2019t own the Streaming Services\u2019 data or distribution network.\n\nTo The Point\nIf someone is going to disrupt the market with a low-end disruption, it would be an industry insider like United Masters\u2019 founder. There are two reasons here\u2026\nLongtime industry insider is the only person familiar enough with the inefficiencies that are actually crucial to win business.\nLow-end market disruption work in a B2B environment. Industry insiders know how to speak to the decision makers on the business side of an artist\u2019s career, which makes them more qualified to explain the value proposition to them.\nConclusion\nIf you read my article closely, you\u2019ll notice I don\u2019t take a stand on the viability of United Masters. I don\u2019t think asking the question \u201cDo you think the company will succeed?\u201d is the right question \u2014 I can\u2019t tell you if the company will succeed. I can tell you how the incentives work. However, just because the incentives line up for the company does not mean they will succeed. But if a company can understand the incentives, they can make the right decisions, but that is half the battle. The ability to design and implement creative solutions to leverage these incentives is what separates success from failure.\nIf you enjoyed, Don\u2019t forget to click and hold the \ud83d\udc4f so other people can find the article. Incentive Theory is a publication that focuses in data science and direct to consumer strategy.\n\n"
  },
  {
    "title": "Can Technology Replace Record Companies?",
    "content": "Grow your learning @ incentivetheory.com\nCan Technology Replace Record Companies?\nThe music industry is a business theorist\u2019s dream. It is a great case study, because unlike many industries, it faces almost all the possible issues a market could face (regulatory hurdles, high visibility, innovative, fast paced, low barriers to entry, high barriers to sustainability). It reminds me of an internet accelerated version of the 1980s version of the disk drive industry.\n\nIn the wake of my recent article, I have had a few people share articles about the emergence of the company United Masters from stealth mode. For those of you that don\u2019t know, before I started at Sonos, I briefly worked on an application that competed in a similar space. From this experience, I learned that music analytics is a very competitive space with a laundry list of modularized niche suppliers (Swift & Next big sound for streaming analytics, MAX for paring artist for social analytics, WAVO for tour ads). Things to consider\u2026\nThe Customer Experience\nAs noted in my last article, the record labels\u2019 customer is the artist, not the music listener. A company\u2019s customer experience really matters. Taking out all the inefficiencies in the supply chain might actually affect a record company\u2019s ability to win business. If an independent artists gets big enough, they don\u2019t want to be treated like a commodity user of a technical platform; Artists and their teams are willing to pay for a luxury experience, especially if the experience comes at the expense of uncertain future gains.\nPeople are Loss Averse\nIn economics, it is known as the Prospect Theory. Prospect Theory states that people are loss averse, meaning people perceive losses more strongly than gains. If a small artist or team doesn\u2019t go with a big label now, they may not have the opportunity to go with them in the future. A potentially big loss if the artist fails. If United Masters can quantify and mitigate the monetary value lost if an act succeeds, they could persuade some managers to adopt the risk and cost associated with staying independent. Clearly articulating a value proposition for theoretical future gains is difficult.\nConflict of Interest\nIn management theory, it is known as the Realtor Effect. If a realtor is selling a house, they only get a small percent of the sale. Instead of fighting for incremental gains for the seller, the Realtor\u2019s time is better spent finding other houses to sell, despite whether the extra work is in the seller\u2019s best interest. People on the business side of an artists career are incentivized to have artist\u2019s work with a larger record company, because their dollar per hour inputed is more attractive. The business person is required they spend less time working with an act, but still sees attractive financial returns. The business person\u2019s time is better spent finding and signing new acts.\nPlatform\nIt\u2019s extremely difficult to build a platform based on assets you don\u2019t own. Surviving in a company\u2019s supply chain is difficult, because you are ultimately beholden to the owner of the content. United Masters doesn\u2019t own the Streaming Services\u2019 data or distribution network.\n\nTo The Point\nIf someone is going to disrupt the market with a low-end disruption, it would be an industry insider like United Masters\u2019 founder. There are two reasons here\u2026\nLongtime industry insider is the only person familiar enough with the inefficiencies that are actually crucial to win business.\nLow-end market disruption work in a B2B environment. Industry insiders know how to speak to the decision makers on the business side of an artist\u2019s career, which makes them more qualified to explain the value proposition to them.\nConclusion\nIf you read my article closely, you\u2019ll notice I don\u2019t take a stand on the viability of United Masters. I don\u2019t think asking the question \u201cDo you think the company will succeed?\u201d is the right question \u2014 I can\u2019t tell you if the company will succeed. I can tell you how the incentives work. However, just because the incentives line up for the company does not mean they will succeed. But if a company can understand the incentives, they can make the right decisions, but that is half the battle. The ability to design and implement creative solutions to leverage these incentives is what separates success from failure.\nIf you enjoyed, Don\u2019t forget to click and hold the \ud83d\udc4f so other people can find the article. Incentive Theory is a publication that focuses in data science and direct to consumer strategy.\n\n"
  },
  {
    "title": "AI & Blockchain Predictions in Davos: Myth or Reality?",
    "content": "Session \u201cAsk About: AI and Diagnosis\u201d at the Annual Meeting 2018 of the World Economic Forum in Davos, January 23, 2018 Copyright by World Economic Forum\nAI & Blockchain Predictions in Davos: Myth or Reality?\nDuring this year\u2019s World Economic Forum Annual Meeting in Davos, I had the privilege of spending one week with the world leaders in business, government and civil society, discussing predictions about technology and politics. Three months after that intense week spent in the Magic Mountains, now that the snow is melting, have those predictions become reality?\nThe coverage of the Annual Meeting of the World Economic Forum 2018 was dominated by tech and innovation, in addition to Mr. Trump\u2019s attendance, of course. Tech issues dominated the scene and the discussion both on social media (source: Brunswick Insight) and at the event. The conference\u2019s agenda is a roadmap to key digital transformation technologies empowering the \u201cFourth Industrial Revolution\u201d, a disruptive economic and societal concept introduced at the event in 2013, predicated on the confluence of physical, digital and virtual technologies. Five years later, the embracing of digital transformation, Artificial Intelligence and blockchain were among the most discussed topics in Davos.\n\n1. Artificial Intelligence (AI)\nAI is the new technological frontier over which companies and countries are vying for control, especially the US and China. According to the latest report from McKinsey, Google\u2019s parent company Alphabet invested roughly $30 billion in developing AI technologies. Baidu, the Chinese search giant, invested $20 billion in AI.\nAI has been on the scene for many years, and it\u2019s now evolving so fast that it is going to change our lives. Google\u2019s CEO Sundar Pichai compared artificial intelligence to the discovery of electricity or the mastery of fire, describing it as \u201cprobably the most important thing humanity has ever worked on.\u201d \u201cEven more than fire, as steam AI will act as a multiplier of human work,\u201d reinforced Christian Lanng, CEO at Tradeshift. The role of AI to leverage the power of data is key. For me it was an honor to be part of the panel for the SOLVER Series in Davos to discuss data for healthcare. With Kees Aarts, Beth Weesner and Olivier Ouiller we discussed how data from different businesses can be used to better serve people\u2019s lives and revolutionize preventive tech. AI combined with IoT will change the rules of the game completely.\nDavos 2018 Prediction: Artificial Intelligence & Tech Geopolitics\nThe most mentioned business leader was George Soros, the investor and chairman of Soros Fund Management, who made headlines with his speech about tech geopolitics. \u201cIt is only a matter of time before the global dominance of the US IT monopolies is broken. Davos is a good place to announce that their days are numbered,\u201d predicted Mr. Soros, as tech giants \u201care poised to dominate the new growth areas that artificial intelligence is opening up.\u201d\nChina\u2019s proportion of global AI startup funding as a percentage of dollar value. Image: CB Insights.\nThree Months Later: Reality\nChina has taken the crown in AI funding, overtaking the US: a Chinese facial recognition surveillance company is now the world\u2019s most valuable AI startup. In April 2018, SenseTime Group has raised funding from Alibaba and other investors at a valuation of more than $3 billion, becoming the world\u2019s most valuable artificial intelligence startup. \u201cIn China there is an advantage in areas like facial recognition because of the privacy that exists in the U.S. and elsewhere in the EU, and some of the very best facial recognition technology in the world that I\u2019ve seen is in China,\u201d said Breyer Capital founder Jim Breyer, an indirect investor in SenseTime through IDG.\n2. Blockchain & Crypto\nEverything this year in Davos was about cryptocurrencies and Bitcoin. While in 2017 the event organized by WISeKey on \u201cBlockchain and the Internet of Value\u201d was an exclusive meeting with 300 delegates where the leading Blockchain expert Don Tapscott presented his book Blockchain Revolution, this year Carlos Creus Moreira, founder and CEO of WISeKey, was assaulted by a huge crowd in Davos. And blockchain came up in one panel discussion after the next. Everyone was excited about blockchain technology, naturally. And even more so about Bitcoin. Bitcoin value is ten times the value of the previous year, so this is not a surprise. What is behind Bitcoin and other crypto? Blockchain is a shared ledger technology that powers cryptocurrencies but also allows encrypted data on anything from money to medical records to be shared between companies, people and institutions. This protects data from fraud while instantly updating all parties concerned. There is an incredible number of businesses outside of cryptocurrencies that are leveraging blockchain and that will change the way we work dramatically.\nDavos 2018 Prediction: Blockchain & Crypto\nWhile the potential of blockchain, the underlying technology behind cryptocurrencies, was praised, bitcoin got slammed. \u201cBitcoin is a fraud,\u201d a statement made by Jamie Dimon, CEO of JPMorgan Chase, raised many discussions, and in Davos he stated, \u201cCryptocurrency: it\u2019s not my interest.\u201d \u201cThere is no intrinsic value for something like bitcoin so it\u2019s not really an asset one can analyze. It\u2019s just essentially speculative or gambling,\u201d reinforced Stephen Poloz, the governor of the Bank of Canada.\nCopyrights World Economic Forum\nThree Months Later: Reality\nWe all know that after Bitcoin almost hit 20,000 USD in December 2017, it had a big drop, and the decline continued after Davos: the BTC-USD rollercoaster is now between 7,000 and 9,000 USD.\nOrbis Research has just released its new report, \u201cBlockchain Technology Market Forecasts, 2017\u20132025\u201d: the blockchain technology market, valued at approximately USD 350 million in 2016, is anticipated to reach up to USD 10.5 billion, growing at a lucrative rate of more than 50% over the forecast period 2017\u20132025. The market\u2019s growth is attributed to the increasing penetration of cryptocurrency and ICO, and to the growing adoption rate of blockchain-as-a-service, blockchain to enable faster transactions. Moreover, the rising rate at which the blockchain technology is being adopted for payments, smart contracts and digital identities is creating significant opportunities for the global blockchain technology market.\nThe bottom line? Blockchain and crypto can no longer be ignored. Banks are calling on regulators to tackle the new crypto-markets such as ICOs quickly. \u201cWe can\u2019t deny that things are changing,\u201d says Benoit Legrand, chief innovation officer at Dutch bank ING. \u201cThe world will include cryptocurrencies in the way we work in the next ten years.\u201d\nConclusions\nThree months after the event, the big Davos predictions about AI and blockchain have not only been realized but have also become exponential We still don\u2019t know how the future will look, what will work or how it will work. But there is no doubt that everyone is rushing to get ready for this evolution. Companies, sectors and countries are running a critical race to invest and discover the best technologies to leverage AI and blockchain. The time is now.\nWhat were your Prediction? Have they become reality? Comment below with your perspective or connect with me here\nAbout the Author: Giulia Zanzi is passionate about combining IoT and mobile technologies with science to improve people\u2019s lives. As Head of Marketing Fertility in Swiss Precision Diagnostics, a Procter & Gamble JV, she led the launch of the first Connected Ovulation Test System that helps women to get pregnant faster by detecting two hormones and syncing with their phone. A former member of the European Youth Parliament, Giulia is currently serving on the Advisory Council of the World Economic Forum Global Shapers and she is a Lean In Partner Champion. Giulia graduated with honors at Bocconi University in Milan and holds a Masters at Fudan University in Shanghai.\n"
  },
  {
    "title": "AI & Blockchain Predictions in Davos: Myth or Reality?",
    "content": "Session \u201cAsk About: AI and Diagnosis\u201d at the Annual Meeting 2018 of the World Economic Forum in Davos, January 23, 2018 Copyright by World Economic Forum\nAI & Blockchain Predictions in Davos: Myth or Reality?\nDuring this year\u2019s World Economic Forum Annual Meeting in Davos, I had the privilege of spending one week with the world leaders in business, government and civil society, discussing predictions about technology and politics. Three months after that intense week spent in the Magic Mountains, now that the snow is melting, have those predictions become reality?\nThe coverage of the Annual Meeting of the World Economic Forum 2018 was dominated by tech and innovation, in addition to Mr. Trump\u2019s attendance, of course. Tech issues dominated the scene and the discussion both on social media (source: Brunswick Insight) and at the event. The conference\u2019s agenda is a roadmap to key digital transformation technologies empowering the \u201cFourth Industrial Revolution\u201d, a disruptive economic and societal concept introduced at the event in 2013, predicated on the confluence of physical, digital and virtual technologies. Five years later, the embracing of digital transformation, Artificial Intelligence and blockchain were among the most discussed topics in Davos.\n\n1. Artificial Intelligence (AI)\nAI is the new technological frontier over which companies and countries are vying for control, especially the US and China. According to the latest report from McKinsey, Google\u2019s parent company Alphabet invested roughly $30 billion in developing AI technologies. Baidu, the Chinese search giant, invested $20 billion in AI.\nAI has been on the scene for many years, and it\u2019s now evolving so fast that it is going to change our lives. Google\u2019s CEO Sundar Pichai compared artificial intelligence to the discovery of electricity or the mastery of fire, describing it as \u201cprobably the most important thing humanity has ever worked on.\u201d \u201cEven more than fire, as steam AI will act as a multiplier of human work,\u201d reinforced Christian Lanng, CEO at Tradeshift. The role of AI to leverage the power of data is key. For me it was an honor to be part of the panel for the SOLVER Series in Davos to discuss data for healthcare. With Kees Aarts, Beth Weesner and Olivier Ouiller we discussed how data from different businesses can be used to better serve people\u2019s lives and revolutionize preventive tech. AI combined with IoT will change the rules of the game completely.\nDavos 2018 Prediction: Artificial Intelligence & Tech Geopolitics\nThe most mentioned business leader was George Soros, the investor and chairman of Soros Fund Management, who made headlines with his speech about tech geopolitics. \u201cIt is only a matter of time before the global dominance of the US IT monopolies is broken. Davos is a good place to announce that their days are numbered,\u201d predicted Mr. Soros, as tech giants \u201care poised to dominate the new growth areas that artificial intelligence is opening up.\u201d\nChina\u2019s proportion of global AI startup funding as a percentage of dollar value. Image: CB Insights.\nThree Months Later: Reality\nChina has taken the crown in AI funding, overtaking the US: a Chinese facial recognition surveillance company is now the world\u2019s most valuable AI startup. In April 2018, SenseTime Group has raised funding from Alibaba and other investors at a valuation of more than $3 billion, becoming the world\u2019s most valuable artificial intelligence startup. \u201cIn China there is an advantage in areas like facial recognition because of the privacy that exists in the U.S. and elsewhere in the EU, and some of the very best facial recognition technology in the world that I\u2019ve seen is in China,\u201d said Breyer Capital founder Jim Breyer, an indirect investor in SenseTime through IDG.\n2. Blockchain & Crypto\nEverything this year in Davos was about cryptocurrencies and Bitcoin. While in 2017 the event organized by WISeKey on \u201cBlockchain and the Internet of Value\u201d was an exclusive meeting with 300 delegates where the leading Blockchain expert Don Tapscott presented his book Blockchain Revolution, this year Carlos Creus Moreira, founder and CEO of WISeKey, was assaulted by a huge crowd in Davos. And blockchain came up in one panel discussion after the next. Everyone was excited about blockchain technology, naturally. And even more so about Bitcoin. Bitcoin value is ten times the value of the previous year, so this is not a surprise. What is behind Bitcoin and other crypto? Blockchain is a shared ledger technology that powers cryptocurrencies but also allows encrypted data on anything from money to medical records to be shared between companies, people and institutions. This protects data from fraud while instantly updating all parties concerned. There is an incredible number of businesses outside of cryptocurrencies that are leveraging blockchain and that will change the way we work dramatically.\nDavos 2018 Prediction: Blockchain & Crypto\nWhile the potential of blockchain, the underlying technology behind cryptocurrencies, was praised, bitcoin got slammed. \u201cBitcoin is a fraud,\u201d a statement made by Jamie Dimon, CEO of JPMorgan Chase, raised many discussions, and in Davos he stated, \u201cCryptocurrency: it\u2019s not my interest.\u201d \u201cThere is no intrinsic value for something like bitcoin so it\u2019s not really an asset one can analyze. It\u2019s just essentially speculative or gambling,\u201d reinforced Stephen Poloz, the governor of the Bank of Canada.\nCopyrights World Economic Forum\nThree Months Later: Reality\nWe all know that after Bitcoin almost hit 20,000 USD in December 2017, it had a big drop, and the decline continued after Davos: the BTC-USD rollercoaster is now between 7,000 and 9,000 USD.\nOrbis Research has just released its new report, \u201cBlockchain Technology Market Forecasts, 2017\u20132025\u201d: the blockchain technology market, valued at approximately USD 350 million in 2016, is anticipated to reach up to USD 10.5 billion, growing at a lucrative rate of more than 50% over the forecast period 2017\u20132025. The market\u2019s growth is attributed to the increasing penetration of cryptocurrency and ICO, and to the growing adoption rate of blockchain-as-a-service, blockchain to enable faster transactions. Moreover, the rising rate at which the blockchain technology is being adopted for payments, smart contracts and digital identities is creating significant opportunities for the global blockchain technology market.\nThe bottom line? Blockchain and crypto can no longer be ignored. Banks are calling on regulators to tackle the new crypto-markets such as ICOs quickly. \u201cWe can\u2019t deny that things are changing,\u201d says Benoit Legrand, chief innovation officer at Dutch bank ING. \u201cThe world will include cryptocurrencies in the way we work in the next ten years.\u201d\nConclusions\nThree months after the event, the big Davos predictions about AI and blockchain have not only been realized but have also become exponential We still don\u2019t know how the future will look, what will work or how it will work. But there is no doubt that everyone is rushing to get ready for this evolution. Companies, sectors and countries are running a critical race to invest and discover the best technologies to leverage AI and blockchain. The time is now.\nWhat were your Prediction? Have they become reality? Comment below with your perspective or connect with me here\nAbout the Author: Giulia Zanzi is passionate about combining IoT and mobile technologies with science to improve people\u2019s lives. As Head of Marketing Fertility in Swiss Precision Diagnostics, a Procter & Gamble JV, she led the launch of the first Connected Ovulation Test System that helps women to get pregnant faster by detecting two hormones and syncing with their phone. A former member of the European Youth Parliament, Giulia is currently serving on the Advisory Council of the World Economic Forum Global Shapers and she is a Lean In Partner Champion. Giulia graduated with honors at Bocconi University in Milan and holds a Masters at Fudan University in Shanghai.\n"
  },
  {
    "title": "AI & Blockchain Predictions in Davos: Myth or Reality?",
    "content": "Session \u201cAsk About: AI and Diagnosis\u201d at the Annual Meeting 2018 of the World Economic Forum in Davos, January 23, 2018 Copyright by World Economic Forum\nAI & Blockchain Predictions in Davos: Myth or Reality?\nDuring this year\u2019s World Economic Forum Annual Meeting in Davos, I had the privilege of spending one week with the world leaders in business, government and civil society, discussing predictions about technology and politics. Three months after that intense week spent in the Magic Mountains, now that the snow is melting, have those predictions become reality?\nThe coverage of the Annual Meeting of the World Economic Forum 2018 was dominated by tech and innovation, in addition to Mr. Trump\u2019s attendance, of course. Tech issues dominated the scene and the discussion both on social media (source: Brunswick Insight) and at the event. The conference\u2019s agenda is a roadmap to key digital transformation technologies empowering the \u201cFourth Industrial Revolution\u201d, a disruptive economic and societal concept introduced at the event in 2013, predicated on the confluence of physical, digital and virtual technologies. Five years later, the embracing of digital transformation, Artificial Intelligence and blockchain were among the most discussed topics in Davos.\n\n1. Artificial Intelligence (AI)\nAI is the new technological frontier over which companies and countries are vying for control, especially the US and China. According to the latest report from McKinsey, Google\u2019s parent company Alphabet invested roughly $30 billion in developing AI technologies. Baidu, the Chinese search giant, invested $20 billion in AI.\nAI has been on the scene for many years, and it\u2019s now evolving so fast that it is going to change our lives. Google\u2019s CEO Sundar Pichai compared artificial intelligence to the discovery of electricity or the mastery of fire, describing it as \u201cprobably the most important thing humanity has ever worked on.\u201d \u201cEven more than fire, as steam AI will act as a multiplier of human work,\u201d reinforced Christian Lanng, CEO at Tradeshift. The role of AI to leverage the power of data is key. For me it was an honor to be part of the panel for the SOLVER Series in Davos to discuss data for healthcare. With Kees Aarts, Beth Weesner and Olivier Ouiller we discussed how data from different businesses can be used to better serve people\u2019s lives and revolutionize preventive tech. AI combined with IoT will change the rules of the game completely.\nDavos 2018 Prediction: Artificial Intelligence & Tech Geopolitics\nThe most mentioned business leader was George Soros, the investor and chairman of Soros Fund Management, who made headlines with his speech about tech geopolitics. \u201cIt is only a matter of time before the global dominance of the US IT monopolies is broken. Davos is a good place to announce that their days are numbered,\u201d predicted Mr. Soros, as tech giants \u201care poised to dominate the new growth areas that artificial intelligence is opening up.\u201d\nChina\u2019s proportion of global AI startup funding as a percentage of dollar value. Image: CB Insights.\nThree Months Later: Reality\nChina has taken the crown in AI funding, overtaking the US: a Chinese facial recognition surveillance company is now the world\u2019s most valuable AI startup. In April 2018, SenseTime Group has raised funding from Alibaba and other investors at a valuation of more than $3 billion, becoming the world\u2019s most valuable artificial intelligence startup. \u201cIn China there is an advantage in areas like facial recognition because of the privacy that exists in the U.S. and elsewhere in the EU, and some of the very best facial recognition technology in the world that I\u2019ve seen is in China,\u201d said Breyer Capital founder Jim Breyer, an indirect investor in SenseTime through IDG.\n2. Blockchain & Crypto\nEverything this year in Davos was about cryptocurrencies and Bitcoin. While in 2017 the event organized by WISeKey on \u201cBlockchain and the Internet of Value\u201d was an exclusive meeting with 300 delegates where the leading Blockchain expert Don Tapscott presented his book Blockchain Revolution, this year Carlos Creus Moreira, founder and CEO of WISeKey, was assaulted by a huge crowd in Davos. And blockchain came up in one panel discussion after the next. Everyone was excited about blockchain technology, naturally. And even more so about Bitcoin. Bitcoin value is ten times the value of the previous year, so this is not a surprise. What is behind Bitcoin and other crypto? Blockchain is a shared ledger technology that powers cryptocurrencies but also allows encrypted data on anything from money to medical records to be shared between companies, people and institutions. This protects data from fraud while instantly updating all parties concerned. There is an incredible number of businesses outside of cryptocurrencies that are leveraging blockchain and that will change the way we work dramatically.\nDavos 2018 Prediction: Blockchain & Crypto\nWhile the potential of blockchain, the underlying technology behind cryptocurrencies, was praised, bitcoin got slammed. \u201cBitcoin is a fraud,\u201d a statement made by Jamie Dimon, CEO of JPMorgan Chase, raised many discussions, and in Davos he stated, \u201cCryptocurrency: it\u2019s not my interest.\u201d \u201cThere is no intrinsic value for something like bitcoin so it\u2019s not really an asset one can analyze. It\u2019s just essentially speculative or gambling,\u201d reinforced Stephen Poloz, the governor of the Bank of Canada.\nCopyrights World Economic Forum\nThree Months Later: Reality\nWe all know that after Bitcoin almost hit 20,000 USD in December 2017, it had a big drop, and the decline continued after Davos: the BTC-USD rollercoaster is now between 7,000 and 9,000 USD.\nOrbis Research has just released its new report, \u201cBlockchain Technology Market Forecasts, 2017\u20132025\u201d: the blockchain technology market, valued at approximately USD 350 million in 2016, is anticipated to reach up to USD 10.5 billion, growing at a lucrative rate of more than 50% over the forecast period 2017\u20132025. The market\u2019s growth is attributed to the increasing penetration of cryptocurrency and ICO, and to the growing adoption rate of blockchain-as-a-service, blockchain to enable faster transactions. Moreover, the rising rate at which the blockchain technology is being adopted for payments, smart contracts and digital identities is creating significant opportunities for the global blockchain technology market.\nThe bottom line? Blockchain and crypto can no longer be ignored. Banks are calling on regulators to tackle the new crypto-markets such as ICOs quickly. \u201cWe can\u2019t deny that things are changing,\u201d says Benoit Legrand, chief innovation officer at Dutch bank ING. \u201cThe world will include cryptocurrencies in the way we work in the next ten years.\u201d\nConclusions\nThree months after the event, the big Davos predictions about AI and blockchain have not only been realized but have also become exponential We still don\u2019t know how the future will look, what will work or how it will work. But there is no doubt that everyone is rushing to get ready for this evolution. Companies, sectors and countries are running a critical race to invest and discover the best technologies to leverage AI and blockchain. The time is now.\nWhat were your Prediction? Have they become reality? Comment below with your perspective or connect with me here\nAbout the Author: Giulia Zanzi is passionate about combining IoT and mobile technologies with science to improve people\u2019s lives. As Head of Marketing Fertility in Swiss Precision Diagnostics, a Procter & Gamble JV, she led the launch of the first Connected Ovulation Test System that helps women to get pregnant faster by detecting two hormones and syncing with their phone. A former member of the European Youth Parliament, Giulia is currently serving on the Advisory Council of the World Economic Forum Global Shapers and she is a Lean In Partner Champion. Giulia graduated with honors at Bocconi University in Milan and holds a Masters at Fudan University in Shanghai.\n"
  },
  {
    "title": "AI & Blockchain Predictions in Davos: Myth or Reality?",
    "content": "Session \u201cAsk About: AI and Diagnosis\u201d at the Annual Meeting 2018 of the World Economic Forum in Davos, January 23, 2018 Copyright by World Economic Forum\nAI & Blockchain Predictions in Davos: Myth or Reality?\nDuring this year\u2019s World Economic Forum Annual Meeting in Davos, I had the privilege of spending one week with the world leaders in business, government and civil society, discussing predictions about technology and politics. Three months after that intense week spent in the Magic Mountains, now that the snow is melting, have those predictions become reality?\nThe coverage of the Annual Meeting of the World Economic Forum 2018 was dominated by tech and innovation, in addition to Mr. Trump\u2019s attendance, of course. Tech issues dominated the scene and the discussion both on social media (source: Brunswick Insight) and at the event. The conference\u2019s agenda is a roadmap to key digital transformation technologies empowering the \u201cFourth Industrial Revolution\u201d, a disruptive economic and societal concept introduced at the event in 2013, predicated on the confluence of physical, digital and virtual technologies. Five years later, the embracing of digital transformation, Artificial Intelligence and blockchain were among the most discussed topics in Davos.\n\n1. Artificial Intelligence (AI)\nAI is the new technological frontier over which companies and countries are vying for control, especially the US and China. According to the latest report from McKinsey, Google\u2019s parent company Alphabet invested roughly $30 billion in developing AI technologies. Baidu, the Chinese search giant, invested $20 billion in AI.\nAI has been on the scene for many years, and it\u2019s now evolving so fast that it is going to change our lives. Google\u2019s CEO Sundar Pichai compared artificial intelligence to the discovery of electricity or the mastery of fire, describing it as \u201cprobably the most important thing humanity has ever worked on.\u201d \u201cEven more than fire, as steam AI will act as a multiplier of human work,\u201d reinforced Christian Lanng, CEO at Tradeshift. The role of AI to leverage the power of data is key. For me it was an honor to be part of the panel for the SOLVER Series in Davos to discuss data for healthcare. With Kees Aarts, Beth Weesner and Olivier Ouiller we discussed how data from different businesses can be used to better serve people\u2019s lives and revolutionize preventive tech. AI combined with IoT will change the rules of the game completely.\nDavos 2018 Prediction: Artificial Intelligence & Tech Geopolitics\nThe most mentioned business leader was George Soros, the investor and chairman of Soros Fund Management, who made headlines with his speech about tech geopolitics. \u201cIt is only a matter of time before the global dominance of the US IT monopolies is broken. Davos is a good place to announce that their days are numbered,\u201d predicted Mr. Soros, as tech giants \u201care poised to dominate the new growth areas that artificial intelligence is opening up.\u201d\nChina\u2019s proportion of global AI startup funding as a percentage of dollar value. Image: CB Insights.\nThree Months Later: Reality\nChina has taken the crown in AI funding, overtaking the US: a Chinese facial recognition surveillance company is now the world\u2019s most valuable AI startup. In April 2018, SenseTime Group has raised funding from Alibaba and other investors at a valuation of more than $3 billion, becoming the world\u2019s most valuable artificial intelligence startup. \u201cIn China there is an advantage in areas like facial recognition because of the privacy that exists in the U.S. and elsewhere in the EU, and some of the very best facial recognition technology in the world that I\u2019ve seen is in China,\u201d said Breyer Capital founder Jim Breyer, an indirect investor in SenseTime through IDG.\n2. Blockchain & Crypto\nEverything this year in Davos was about cryptocurrencies and Bitcoin. While in 2017 the event organized by WISeKey on \u201cBlockchain and the Internet of Value\u201d was an exclusive meeting with 300 delegates where the leading Blockchain expert Don Tapscott presented his book Blockchain Revolution, this year Carlos Creus Moreira, founder and CEO of WISeKey, was assaulted by a huge crowd in Davos. And blockchain came up in one panel discussion after the next. Everyone was excited about blockchain technology, naturally. And even more so about Bitcoin. Bitcoin value is ten times the value of the previous year, so this is not a surprise. What is behind Bitcoin and other crypto? Blockchain is a shared ledger technology that powers cryptocurrencies but also allows encrypted data on anything from money to medical records to be shared between companies, people and institutions. This protects data from fraud while instantly updating all parties concerned. There is an incredible number of businesses outside of cryptocurrencies that are leveraging blockchain and that will change the way we work dramatically.\nDavos 2018 Prediction: Blockchain & Crypto\nWhile the potential of blockchain, the underlying technology behind cryptocurrencies, was praised, bitcoin got slammed. \u201cBitcoin is a fraud,\u201d a statement made by Jamie Dimon, CEO of JPMorgan Chase, raised many discussions, and in Davos he stated, \u201cCryptocurrency: it\u2019s not my interest.\u201d \u201cThere is no intrinsic value for something like bitcoin so it\u2019s not really an asset one can analyze. It\u2019s just essentially speculative or gambling,\u201d reinforced Stephen Poloz, the governor of the Bank of Canada.\nCopyrights World Economic Forum\nThree Months Later: Reality\nWe all know that after Bitcoin almost hit 20,000 USD in December 2017, it had a big drop, and the decline continued after Davos: the BTC-USD rollercoaster is now between 7,000 and 9,000 USD.\nOrbis Research has just released its new report, \u201cBlockchain Technology Market Forecasts, 2017\u20132025\u201d: the blockchain technology market, valued at approximately USD 350 million in 2016, is anticipated to reach up to USD 10.5 billion, growing at a lucrative rate of more than 50% over the forecast period 2017\u20132025. The market\u2019s growth is attributed to the increasing penetration of cryptocurrency and ICO, and to the growing adoption rate of blockchain-as-a-service, blockchain to enable faster transactions. Moreover, the rising rate at which the blockchain technology is being adopted for payments, smart contracts and digital identities is creating significant opportunities for the global blockchain technology market.\nThe bottom line? Blockchain and crypto can no longer be ignored. Banks are calling on regulators to tackle the new crypto-markets such as ICOs quickly. \u201cWe can\u2019t deny that things are changing,\u201d says Benoit Legrand, chief innovation officer at Dutch bank ING. \u201cThe world will include cryptocurrencies in the way we work in the next ten years.\u201d\nConclusions\nThree months after the event, the big Davos predictions about AI and blockchain have not only been realized but have also become exponential We still don\u2019t know how the future will look, what will work or how it will work. But there is no doubt that everyone is rushing to get ready for this evolution. Companies, sectors and countries are running a critical race to invest and discover the best technologies to leverage AI and blockchain. The time is now.\nWhat were your Prediction? Have they become reality? Comment below with your perspective or connect with me here\nAbout the Author: Giulia Zanzi is passionate about combining IoT and mobile technologies with science to improve people\u2019s lives. As Head of Marketing Fertility in Swiss Precision Diagnostics, a Procter & Gamble JV, she led the launch of the first Connected Ovulation Test System that helps women to get pregnant faster by detecting two hormones and syncing with their phone. A former member of the European Youth Parliament, Giulia is currently serving on the Advisory Council of the World Economic Forum Global Shapers and she is a Lean In Partner Champion. Giulia graduated with honors at Bocconi University in Milan and holds a Masters at Fudan University in Shanghai.\n"
  },
  {
    "title": "AI & Blockchain Predictions in Davos: Myth or Reality?",
    "content": "Session \u201cAsk About: AI and Diagnosis\u201d at the Annual Meeting 2018 of the World Economic Forum in Davos, January 23, 2018 Copyright by World Economic Forum\nAI & Blockchain Predictions in Davos: Myth or Reality?\nDuring this year\u2019s World Economic Forum Annual Meeting in Davos, I had the privilege of spending one week with the world leaders in business, government and civil society, discussing predictions about technology and politics. Three months after that intense week spent in the Magic Mountains, now that the snow is melting, have those predictions become reality?\nThe coverage of the Annual Meeting of the World Economic Forum 2018 was dominated by tech and innovation, in addition to Mr. Trump\u2019s attendance, of course. Tech issues dominated the scene and the discussion both on social media (source: Brunswick Insight) and at the event. The conference\u2019s agenda is a roadmap to key digital transformation technologies empowering the \u201cFourth Industrial Revolution\u201d, a disruptive economic and societal concept introduced at the event in 2013, predicated on the confluence of physical, digital and virtual technologies. Five years later, the embracing of digital transformation, Artificial Intelligence and blockchain were among the most discussed topics in Davos.\n\n1. Artificial Intelligence (AI)\nAI is the new technological frontier over which companies and countries are vying for control, especially the US and China. According to the latest report from McKinsey, Google\u2019s parent company Alphabet invested roughly $30 billion in developing AI technologies. Baidu, the Chinese search giant, invested $20 billion in AI.\nAI has been on the scene for many years, and it\u2019s now evolving so fast that it is going to change our lives. Google\u2019s CEO Sundar Pichai compared artificial intelligence to the discovery of electricity or the mastery of fire, describing it as \u201cprobably the most important thing humanity has ever worked on.\u201d \u201cEven more than fire, as steam AI will act as a multiplier of human work,\u201d reinforced Christian Lanng, CEO at Tradeshift. The role of AI to leverage the power of data is key. For me it was an honor to be part of the panel for the SOLVER Series in Davos to discuss data for healthcare. With Kees Aarts, Beth Weesner and Olivier Ouiller we discussed how data from different businesses can be used to better serve people\u2019s lives and revolutionize preventive tech. AI combined with IoT will change the rules of the game completely.\nDavos 2018 Prediction: Artificial Intelligence & Tech Geopolitics\nThe most mentioned business leader was George Soros, the investor and chairman of Soros Fund Management, who made headlines with his speech about tech geopolitics. \u201cIt is only a matter of time before the global dominance of the US IT monopolies is broken. Davos is a good place to announce that their days are numbered,\u201d predicted Mr. Soros, as tech giants \u201care poised to dominate the new growth areas that artificial intelligence is opening up.\u201d\nChina\u2019s proportion of global AI startup funding as a percentage of dollar value. Image: CB Insights.\nThree Months Later: Reality\nChina has taken the crown in AI funding, overtaking the US: a Chinese facial recognition surveillance company is now the world\u2019s most valuable AI startup. In April 2018, SenseTime Group has raised funding from Alibaba and other investors at a valuation of more than $3 billion, becoming the world\u2019s most valuable artificial intelligence startup. \u201cIn China there is an advantage in areas like facial recognition because of the privacy that exists in the U.S. and elsewhere in the EU, and some of the very best facial recognition technology in the world that I\u2019ve seen is in China,\u201d said Breyer Capital founder Jim Breyer, an indirect investor in SenseTime through IDG.\n2. Blockchain & Crypto\nEverything this year in Davos was about cryptocurrencies and Bitcoin. While in 2017 the event organized by WISeKey on \u201cBlockchain and the Internet of Value\u201d was an exclusive meeting with 300 delegates where the leading Blockchain expert Don Tapscott presented his book Blockchain Revolution, this year Carlos Creus Moreira, founder and CEO of WISeKey, was assaulted by a huge crowd in Davos. And blockchain came up in one panel discussion after the next. Everyone was excited about blockchain technology, naturally. And even more so about Bitcoin. Bitcoin value is ten times the value of the previous year, so this is not a surprise. What is behind Bitcoin and other crypto? Blockchain is a shared ledger technology that powers cryptocurrencies but also allows encrypted data on anything from money to medical records to be shared between companies, people and institutions. This protects data from fraud while instantly updating all parties concerned. There is an incredible number of businesses outside of cryptocurrencies that are leveraging blockchain and that will change the way we work dramatically.\nDavos 2018 Prediction: Blockchain & Crypto\nWhile the potential of blockchain, the underlying technology behind cryptocurrencies, was praised, bitcoin got slammed. \u201cBitcoin is a fraud,\u201d a statement made by Jamie Dimon, CEO of JPMorgan Chase, raised many discussions, and in Davos he stated, \u201cCryptocurrency: it\u2019s not my interest.\u201d \u201cThere is no intrinsic value for something like bitcoin so it\u2019s not really an asset one can analyze. It\u2019s just essentially speculative or gambling,\u201d reinforced Stephen Poloz, the governor of the Bank of Canada.\nCopyrights World Economic Forum\nThree Months Later: Reality\nWe all know that after Bitcoin almost hit 20,000 USD in December 2017, it had a big drop, and the decline continued after Davos: the BTC-USD rollercoaster is now between 7,000 and 9,000 USD.\nOrbis Research has just released its new report, \u201cBlockchain Technology Market Forecasts, 2017\u20132025\u201d: the blockchain technology market, valued at approximately USD 350 million in 2016, is anticipated to reach up to USD 10.5 billion, growing at a lucrative rate of more than 50% over the forecast period 2017\u20132025. The market\u2019s growth is attributed to the increasing penetration of cryptocurrency and ICO, and to the growing adoption rate of blockchain-as-a-service, blockchain to enable faster transactions. Moreover, the rising rate at which the blockchain technology is being adopted for payments, smart contracts and digital identities is creating significant opportunities for the global blockchain technology market.\nThe bottom line? Blockchain and crypto can no longer be ignored. Banks are calling on regulators to tackle the new crypto-markets such as ICOs quickly. \u201cWe can\u2019t deny that things are changing,\u201d says Benoit Legrand, chief innovation officer at Dutch bank ING. \u201cThe world will include cryptocurrencies in the way we work in the next ten years.\u201d\nConclusions\nThree months after the event, the big Davos predictions about AI and blockchain have not only been realized but have also become exponential We still don\u2019t know how the future will look, what will work or how it will work. But there is no doubt that everyone is rushing to get ready for this evolution. Companies, sectors and countries are running a critical race to invest and discover the best technologies to leverage AI and blockchain. The time is now.\nWhat were your Prediction? Have they become reality? Comment below with your perspective or connect with me here\nAbout the Author: Giulia Zanzi is passionate about combining IoT and mobile technologies with science to improve people\u2019s lives. As Head of Marketing Fertility in Swiss Precision Diagnostics, a Procter & Gamble JV, she led the launch of the first Connected Ovulation Test System that helps women to get pregnant faster by detecting two hormones and syncing with their phone. A former member of the European Youth Parliament, Giulia is currently serving on the Advisory Council of the World Economic Forum Global Shapers and she is a Lean In Partner Champion. Giulia graduated with honors at Bocconi University in Milan and holds a Masters at Fudan University in Shanghai.\n"
  },
  {
    "title": "A Historic Phase Change in the Way We Build Things",
    "content": "A Historic Phase Change in the Way We Build Things\nPavillion of a Chinese construction company at the 2015 World Expo in Milan / Photo by author\nTo understand the sea change currently happening in the world of manufacturing, it is important to look at the historical perspective. We can split history into the pre-industrial epoch, the time after the Industrial Revolution, and a new era, that we are currently entering.\nUntil the 19th century, the production of goods was a manual process. Even though craftsmen sometimes had simple machines at their disposal, each item was built by hand and became one individual, often unique, object.\nThis changed during the Industrial Revolution, which caused a dramatic shift to the manufacturing of large quantities of identical items. Many objects became standardized and the focus moved to the assembly of objects from as many off-the-shelf parts as possible, while trying to minimize the number of custom components and manual work. Engineers constantly strived to reduce complexity to bring down cost.\nWith the advent of Additive Manufacturing on an industrial level, we are adopting a new paradigm, where complex, highly customized objects are becoming the norm. A printer aggregates small pieces of matter according to a blueprint, indifferent to the simplicity or complexity of the instructions. The resulting object can almost be arbitrarily sophisticated with little impact on cost and manufacturing time.\n3D printers were first used for applications like rapid prototyping, where fast turnaround times allowed designers to work iteratively. With the introduction of better materials and the increased sophistication of the output, printers started to be used in highly individualized end-product manufacturing, such as prosthetics.\nThis shift to Additive Manufacturing of end-use-parts is starting to give designers and engineers newfound freedom, to design objects that cannot be produced through traditional manufacturing. In these applications, the additive aspect of the printers is the key element to the production of completely enclosed parts or objects that use complex internal substructures to reduce weight or that contain functional elements. This transition is going to speed up in the coming years as printers will start to include multiple diverse materials and are able to incorporate the placing of electronics, sensors and actuators into the printed product. The results will be highly sophisticated objects with little or no assembly required.\nWith this phase change happening, the focus now shifts to the software side, which is the key element to enabling objects of significantly higher complexity.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nLin Kayser is the CEO of Munich-based Hyperganic, where he and his team are reinventing how we design and engineer objects in an age of digital manufacturing and synthetic biology.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nThis article was originally published on LinkedIn on April 22, 2018\n"
  },
  {
    "title": "A Historic Phase Change in the Way We Build Things",
    "content": "A Historic Phase Change in the Way We Build Things\nPavillion of a Chinese construction company at the 2015 World Expo in Milan / Photo by author\nTo understand the sea change currently happening in the world of manufacturing, it is important to look at the historical perspective. We can split history into the pre-industrial epoch, the time after the Industrial Revolution, and a new era, that we are currently entering.\nUntil the 19th century, the production of goods was a manual process. Even though craftsmen sometimes had simple machines at their disposal, each item was built by hand and became one individual, often unique, object.\nThis changed during the Industrial Revolution, which caused a dramatic shift to the manufacturing of large quantities of identical items. Many objects became standardized and the focus moved to the assembly of objects from as many off-the-shelf parts as possible, while trying to minimize the number of custom components and manual work. Engineers constantly strived to reduce complexity to bring down cost.\nWith the advent of Additive Manufacturing on an industrial level, we are adopting a new paradigm, where complex, highly customized objects are becoming the norm. A printer aggregates small pieces of matter according to a blueprint, indifferent to the simplicity or complexity of the instructions. The resulting object can almost be arbitrarily sophisticated with little impact on cost and manufacturing time.\n3D printers were first used for applications like rapid prototyping, where fast turnaround times allowed designers to work iteratively. With the introduction of better materials and the increased sophistication of the output, printers started to be used in highly individualized end-product manufacturing, such as prosthetics.\nThis shift to Additive Manufacturing of end-use-parts is starting to give designers and engineers newfound freedom, to design objects that cannot be produced through traditional manufacturing. In these applications, the additive aspect of the printers is the key element to the production of completely enclosed parts or objects that use complex internal substructures to reduce weight or that contain functional elements. This transition is going to speed up in the coming years as printers will start to include multiple diverse materials and are able to incorporate the placing of electronics, sensors and actuators into the printed product. The results will be highly sophisticated objects with little or no assembly required.\nWith this phase change happening, the focus now shifts to the software side, which is the key element to enabling objects of significantly higher complexity.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nLin Kayser is the CEO of Munich-based Hyperganic, where he and his team are reinventing how we design and engineer objects in an age of digital manufacturing and synthetic biology.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nThis article was originally published on LinkedIn on April 22, 2018\n"
  },
  {
    "title": "A Historic Phase Change in the Way We Build Things",
    "content": "A Historic Phase Change in the Way We Build Things\nPavillion of a Chinese construction company at the 2015 World Expo in Milan / Photo by author\nTo understand the sea change currently happening in the world of manufacturing, it is important to look at the historical perspective. We can split history into the pre-industrial epoch, the time after the Industrial Revolution, and a new era, that we are currently entering.\nUntil the 19th century, the production of goods was a manual process. Even though craftsmen sometimes had simple machines at their disposal, each item was built by hand and became one individual, often unique, object.\nThis changed during the Industrial Revolution, which caused a dramatic shift to the manufacturing of large quantities of identical items. Many objects became standardized and the focus moved to the assembly of objects from as many off-the-shelf parts as possible, while trying to minimize the number of custom components and manual work. Engineers constantly strived to reduce complexity to bring down cost.\nWith the advent of Additive Manufacturing on an industrial level, we are adopting a new paradigm, where complex, highly customized objects are becoming the norm. A printer aggregates small pieces of matter according to a blueprint, indifferent to the simplicity or complexity of the instructions. The resulting object can almost be arbitrarily sophisticated with little impact on cost and manufacturing time.\n3D printers were first used for applications like rapid prototyping, where fast turnaround times allowed designers to work iteratively. With the introduction of better materials and the increased sophistication of the output, printers started to be used in highly individualized end-product manufacturing, such as prosthetics.\nThis shift to Additive Manufacturing of end-use-parts is starting to give designers and engineers newfound freedom, to design objects that cannot be produced through traditional manufacturing. In these applications, the additive aspect of the printers is the key element to the production of completely enclosed parts or objects that use complex internal substructures to reduce weight or that contain functional elements. This transition is going to speed up in the coming years as printers will start to include multiple diverse materials and are able to incorporate the placing of electronics, sensors and actuators into the printed product. The results will be highly sophisticated objects with little or no assembly required.\nWith this phase change happening, the focus now shifts to the software side, which is the key element to enabling objects of significantly higher complexity.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nLin Kayser is the CEO of Munich-based Hyperganic, where he and his team are reinventing how we design and engineer objects in an age of digital manufacturing and synthetic biology.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nThis article was originally published on LinkedIn on April 22, 2018\n"
  },
  {
    "title": "A Historic Phase Change in the Way We Build Things",
    "content": "A Historic Phase Change in the Way We Build Things\nPavillion of a Chinese construction company at the 2015 World Expo in Milan / Photo by author\nTo understand the sea change currently happening in the world of manufacturing, it is important to look at the historical perspective. We can split history into the pre-industrial epoch, the time after the Industrial Revolution, and a new era, that we are currently entering.\nUntil the 19th century, the production of goods was a manual process. Even though craftsmen sometimes had simple machines at their disposal, each item was built by hand and became one individual, often unique, object.\nThis changed during the Industrial Revolution, which caused a dramatic shift to the manufacturing of large quantities of identical items. Many objects became standardized and the focus moved to the assembly of objects from as many off-the-shelf parts as possible, while trying to minimize the number of custom components and manual work. Engineers constantly strived to reduce complexity to bring down cost.\nWith the advent of Additive Manufacturing on an industrial level, we are adopting a new paradigm, where complex, highly customized objects are becoming the norm. A printer aggregates small pieces of matter according to a blueprint, indifferent to the simplicity or complexity of the instructions. The resulting object can almost be arbitrarily sophisticated with little impact on cost and manufacturing time.\n3D printers were first used for applications like rapid prototyping, where fast turnaround times allowed designers to work iteratively. With the introduction of better materials and the increased sophistication of the output, printers started to be used in highly individualized end-product manufacturing, such as prosthetics.\nThis shift to Additive Manufacturing of end-use-parts is starting to give designers and engineers newfound freedom, to design objects that cannot be produced through traditional manufacturing. In these applications, the additive aspect of the printers is the key element to the production of completely enclosed parts or objects that use complex internal substructures to reduce weight or that contain functional elements. This transition is going to speed up in the coming years as printers will start to include multiple diverse materials and are able to incorporate the placing of electronics, sensors and actuators into the printed product. The results will be highly sophisticated objects with little or no assembly required.\nWith this phase change happening, the focus now shifts to the software side, which is the key element to enabling objects of significantly higher complexity.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nLin Kayser is the CEO of Munich-based Hyperganic, where he and his team are reinventing how we design and engineer objects in an age of digital manufacturing and synthetic biology.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nThis article was originally published on LinkedIn on April 22, 2018\n"
  },
  {
    "title": "A Historic Phase Change in the Way We Build Things",
    "content": "A Historic Phase Change in the Way We Build Things\nPavillion of a Chinese construction company at the 2015 World Expo in Milan / Photo by author\nTo understand the sea change currently happening in the world of manufacturing, it is important to look at the historical perspective. We can split history into the pre-industrial epoch, the time after the Industrial Revolution, and a new era, that we are currently entering.\nUntil the 19th century, the production of goods was a manual process. Even though craftsmen sometimes had simple machines at their disposal, each item was built by hand and became one individual, often unique, object.\nThis changed during the Industrial Revolution, which caused a dramatic shift to the manufacturing of large quantities of identical items. Many objects became standardized and the focus moved to the assembly of objects from as many off-the-shelf parts as possible, while trying to minimize the number of custom components and manual work. Engineers constantly strived to reduce complexity to bring down cost.\nWith the advent of Additive Manufacturing on an industrial level, we are adopting a new paradigm, where complex, highly customized objects are becoming the norm. A printer aggregates small pieces of matter according to a blueprint, indifferent to the simplicity or complexity of the instructions. The resulting object can almost be arbitrarily sophisticated with little impact on cost and manufacturing time.\n3D printers were first used for applications like rapid prototyping, where fast turnaround times allowed designers to work iteratively. With the introduction of better materials and the increased sophistication of the output, printers started to be used in highly individualized end-product manufacturing, such as prosthetics.\nThis shift to Additive Manufacturing of end-use-parts is starting to give designers and engineers newfound freedom, to design objects that cannot be produced through traditional manufacturing. In these applications, the additive aspect of the printers is the key element to the production of completely enclosed parts or objects that use complex internal substructures to reduce weight or that contain functional elements. This transition is going to speed up in the coming years as printers will start to include multiple diverse materials and are able to incorporate the placing of electronics, sensors and actuators into the printed product. The results will be highly sophisticated objects with little or no assembly required.\nWith this phase change happening, the focus now shifts to the software side, which is the key element to enabling objects of significantly higher complexity.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nLin Kayser is the CEO of Munich-based Hyperganic, where he and his team are reinventing how we design and engineer objects in an age of digital manufacturing and synthetic biology.\n\u2014 \u2014 \u2014 \u2014 \u2014 \u2014\nThis article was originally published on LinkedIn on April 22, 2018\n"
  },
  {
    "title": "Five tech trends that shaped 2017",
    "content": "Five tech trends that shaped 2017\n\u201cThe historian is a prophet looking backwards.\u201d \u2015 Friedrich Schlegel\n\nThis post was originally published on VC Cafe. As we approach the last stretch of 2017, I wanted to take stock of the tech trends that shaped our year. In the next post, I\u2019ll cover my predictions for 2018.\n1. Decentralisation\nPerhaps the most impactful trend this year is the proliferation of Blockchain technologies and cryptocurrencies into the mainstream.\nOn the Blockchain front we\u2019ve seen a wide array of potential applications from real estate to art dealing and diamond trade.\nOn Crypto, we moved from Voice Over IP to Money Over IP, and saw Bitcoin cross the $10,000 line. ICOs (initial coin offerings) became a \u2018thing\u2019 \u2014 tokenise everything, with people spending over $1M to buy virtual cats with Ethereum on CryptoKitties (it\u2019s been acquired since).\nFor a second it looked like White Papers were replacing the fundraising deck, with startups that struggled raising traditional funding completing multi millions ICOs seemingly overnight. Unfortunately, a large percent of ICOs feel like a potential scam, money gets taken off the table quickly and almost with no supervision, and with the only collateral at risk being reputation (in some cases, not even that).\n\nThis is just the beginning in my opinion, but regulation is likely to step in here very soon.\n\n2. AI is the new UI\nThe hype around AI reached new heights in 2017. Using a decision tree to apply a set of rules, or operating a chatbot don\u2019t necessarily qualify as using AI, but it is almost inevitable to avoid having some form of machine learning, deep leaning, NLP etc today\u2019s tech startups.\nAs a field, AI made major breakthroughs this year, namely DeepMind\u2019s AlphaGo decisive victory over the Go world champion, and then the improved version AlphaGo Zero, which was self taught and even better.\n\nThere\u2019s no doubt that AI will continue to penetrate entire industries, in particular Automotive (self driving vehicles), robotics, drones, healthcare and marketing tech \u2014 from advertising to customer service.\nAnother aspect of the rise of AI is the infrastructure side: new chips from Nvidia, Google and Graphcore to fuel our growing need for fast data processing.\nThe Artificial Intelligence Index 2017, a \u202aStanford report by AI Index (pdf) has some fantastic nuggets on the number of AI academic papers published, the number of enrolled students into AI courses, the growth rate of AI startups etc.\n\n3. Data is the new oil\nThere\u2019s one big problem with the perception of data being the new oil, the CEO of a successful AI startup told me. Large corporates are sure they are sitting on an oil field, and so spend millions to pour their data over to expensive data lakes, only to find that\u2019s it\u2019s hard to refine that crude oil (took the analogy all the way, I guess). Organisations are simply \u2018sitting\u2019 on their data, or paying for unproven expensive solutions. We are producing more data than ever in human history, and are getting better at understanding the patterns and the meaning of that data, but there\u2019s still a lot of friction in getting that data and using it wisely.\nFor example, researchers can now predict the face of person based on a tiny sample of DNA. We are able to predict what customers will churn or upgrade simply by watching a small sample of their behaviour, and soon, we should be able to predict where/when a crime is about to happen, by applying models to surveillance data and past crime statistics.\nWhere does the line cross? Ethical considerations are becoming a major part of big data and machine learning startups, with several companies and industry bodies formed to tackle these questions.\n4. Cyber is here to stay\nAlmost no weeks go by without the headline of a major hack. It seems like the Cyber security industry will only get bigger with more and more devices getting online, from our cars to our appliances.\nWe saw the rise of \u2018Dark Marketing\u2019, where advertisers are able to target individuals based on increasingly granular attributes (including race, religion, beliefs) and as Prof Scott Galloway said, \u201cweaponise Facebook\u201d as a platform to change public opinion.\nIsraeli startups attracted about 20% of the global funding for the security sector and saw the IPO of ForScout, reaching an $897M market cap.\n5. GAFAM\n5 companies now dominate tech (Google, Apple, Facebook, Amazon and Microsoft), or 7 if you add Alibaba and Tencent. Their power in the market is almost absolute for example, 99% of digital advertising growth is going to Facebook and Google. Just look at the size of Amazon compared to ALL OF RETAIL.\n\nTheir power is creating a public backlash \u2014 calling for tighter regulation on these companies dealings with privacy, data transparency and competition scrutiny.\nIt\u2019s also getting increasingly hard to find a niche to compete with these giants, as they expand into to every major area from Cloud, messaging, hardware, enterprise, etc, adopting an AI first strategy. As an example, take a look at everything that Amazon announced at AWS re: Invent 2017.\n\nIn my next posts I will cover additional trends that dominated 2017, including Fake News, the Seed Slump, digital health, etc as well as some predictions for 2018. In the meanwhile, take a moment to sign up to my newsletter.\n"
  },
  {
    "title": "Five tech trends that shaped 2017",
    "content": "Five tech trends that shaped 2017\n\u201cThe historian is a prophet looking backwards.\u201d \u2015 Friedrich Schlegel\n\nThis post was originally published on VC Cafe. As we approach the last stretch of 2017, I wanted to take stock of the tech trends that shaped our year. In the next post, I\u2019ll cover my predictions for 2018.\n1. Decentralisation\nPerhaps the most impactful trend this year is the proliferation of Blockchain technologies and cryptocurrencies into the mainstream.\nOn the Blockchain front we\u2019ve seen a wide array of potential applications from real estate to art dealing and diamond trade.\nOn Crypto, we moved from Voice Over IP to Money Over IP, and saw Bitcoin cross the $10,000 line. ICOs (initial coin offerings) became a \u2018thing\u2019 \u2014 tokenise everything, with people spending over $1M to buy virtual cats with Ethereum on CryptoKitties (it\u2019s been acquired since).\nFor a second it looked like White Papers were replacing the fundraising deck, with startups that struggled raising traditional funding completing multi millions ICOs seemingly overnight. Unfortunately, a large percent of ICOs feel like a potential scam, money gets taken off the table quickly and almost with no supervision, and with the only collateral at risk being reputation (in some cases, not even that).\n\nThis is just the beginning in my opinion, but regulation is likely to step in here very soon.\n\n2. AI is the new UI\nThe hype around AI reached new heights in 2017. Using a decision tree to apply a set of rules, or operating a chatbot don\u2019t necessarily qualify as using AI, but it is almost inevitable to avoid having some form of machine learning, deep leaning, NLP etc today\u2019s tech startups.\nAs a field, AI made major breakthroughs this year, namely DeepMind\u2019s AlphaGo decisive victory over the Go world champion, and then the improved version AlphaGo Zero, which was self taught and even better.\n\nThere\u2019s no doubt that AI will continue to penetrate entire industries, in particular Automotive (self driving vehicles), robotics, drones, healthcare and marketing tech \u2014 from advertising to customer service.\nAnother aspect of the rise of AI is the infrastructure side: new chips from Nvidia, Google and Graphcore to fuel our growing need for fast data processing.\nThe Artificial Intelligence Index 2017, a \u202aStanford report by AI Index (pdf) has some fantastic nuggets on the number of AI academic papers published, the number of enrolled students into AI courses, the growth rate of AI startups etc.\n\n3. Data is the new oil\nThere\u2019s one big problem with the perception of data being the new oil, the CEO of a successful AI startup told me. Large corporates are sure they are sitting on an oil field, and so spend millions to pour their data over to expensive data lakes, only to find that\u2019s it\u2019s hard to refine that crude oil (took the analogy all the way, I guess). Organisations are simply \u2018sitting\u2019 on their data, or paying for unproven expensive solutions. We are producing more data than ever in human history, and are getting better at understanding the patterns and the meaning of that data, but there\u2019s still a lot of friction in getting that data and using it wisely.\nFor example, researchers can now predict the face of person based on a tiny sample of DNA. We are able to predict what customers will churn or upgrade simply by watching a small sample of their behaviour, and soon, we should be able to predict where/when a crime is about to happen, by applying models to surveillance data and past crime statistics.\nWhere does the line cross? Ethical considerations are becoming a major part of big data and machine learning startups, with several companies and industry bodies formed to tackle these questions.\n4. Cyber is here to stay\nAlmost no weeks go by without the headline of a major hack. It seems like the Cyber security industry will only get bigger with more and more devices getting online, from our cars to our appliances.\nWe saw the rise of \u2018Dark Marketing\u2019, where advertisers are able to target individuals based on increasingly granular attributes (including race, religion, beliefs) and as Prof Scott Galloway said, \u201cweaponise Facebook\u201d as a platform to change public opinion.\nIsraeli startups attracted about 20% of the global funding for the security sector and saw the IPO of ForScout, reaching an $897M market cap.\n5. GAFAM\n5 companies now dominate tech (Google, Apple, Facebook, Amazon and Microsoft), or 7 if you add Alibaba and Tencent. Their power in the market is almost absolute for example, 99% of digital advertising growth is going to Facebook and Google. Just look at the size of Amazon compared to ALL OF RETAIL.\n\nTheir power is creating a public backlash \u2014 calling for tighter regulation on these companies dealings with privacy, data transparency and competition scrutiny.\nIt\u2019s also getting increasingly hard to find a niche to compete with these giants, as they expand into to every major area from Cloud, messaging, hardware, enterprise, etc, adopting an AI first strategy. As an example, take a look at everything that Amazon announced at AWS re: Invent 2017.\n\nIn my next posts I will cover additional trends that dominated 2017, including Fake News, the Seed Slump, digital health, etc as well as some predictions for 2018. In the meanwhile, take a moment to sign up to my newsletter.\n"
  },
  {
    "title": "Five tech trends that shaped 2017",
    "content": "Five tech trends that shaped 2017\n\u201cThe historian is a prophet looking backwards.\u201d \u2015 Friedrich Schlegel\n\nThis post was originally published on VC Cafe. As we approach the last stretch of 2017, I wanted to take stock of the tech trends that shaped our year. In the next post, I\u2019ll cover my predictions for 2018.\n1. Decentralisation\nPerhaps the most impactful trend this year is the proliferation of Blockchain technologies and cryptocurrencies into the mainstream.\nOn the Blockchain front we\u2019ve seen a wide array of potential applications from real estate to art dealing and diamond trade.\nOn Crypto, we moved from Voice Over IP to Money Over IP, and saw Bitcoin cross the $10,000 line. ICOs (initial coin offerings) became a \u2018thing\u2019 \u2014 tokenise everything, with people spending over $1M to buy virtual cats with Ethereum on CryptoKitties (it\u2019s been acquired since).\nFor a second it looked like White Papers were replacing the fundraising deck, with startups that struggled raising traditional funding completing multi millions ICOs seemingly overnight. Unfortunately, a large percent of ICOs feel like a potential scam, money gets taken off the table quickly and almost with no supervision, and with the only collateral at risk being reputation (in some cases, not even that).\n\nThis is just the beginning in my opinion, but regulation is likely to step in here very soon.\n\n2. AI is the new UI\nThe hype around AI reached new heights in 2017. Using a decision tree to apply a set of rules, or operating a chatbot don\u2019t necessarily qualify as using AI, but it is almost inevitable to avoid having some form of machine learning, deep leaning, NLP etc today\u2019s tech startups.\nAs a field, AI made major breakthroughs this year, namely DeepMind\u2019s AlphaGo decisive victory over the Go world champion, and then the improved version AlphaGo Zero, which was self taught and even better.\n\nThere\u2019s no doubt that AI will continue to penetrate entire industries, in particular Automotive (self driving vehicles), robotics, drones, healthcare and marketing tech \u2014 from advertising to customer service.\nAnother aspect of the rise of AI is the infrastructure side: new chips from Nvidia, Google and Graphcore to fuel our growing need for fast data processing.\nThe Artificial Intelligence Index 2017, a \u202aStanford report by AI Index (pdf) has some fantastic nuggets on the number of AI academic papers published, the number of enrolled students into AI courses, the growth rate of AI startups etc.\n\n3. Data is the new oil\nThere\u2019s one big problem with the perception of data being the new oil, the CEO of a successful AI startup told me. Large corporates are sure they are sitting on an oil field, and so spend millions to pour their data over to expensive data lakes, only to find that\u2019s it\u2019s hard to refine that crude oil (took the analogy all the way, I guess). Organisations are simply \u2018sitting\u2019 on their data, or paying for unproven expensive solutions. We are producing more data than ever in human history, and are getting better at understanding the patterns and the meaning of that data, but there\u2019s still a lot of friction in getting that data and using it wisely.\nFor example, researchers can now predict the face of person based on a tiny sample of DNA. We are able to predict what customers will churn or upgrade simply by watching a small sample of their behaviour, and soon, we should be able to predict where/when a crime is about to happen, by applying models to surveillance data and past crime statistics.\nWhere does the line cross? Ethical considerations are becoming a major part of big data and machine learning startups, with several companies and industry bodies formed to tackle these questions.\n4. Cyber is here to stay\nAlmost no weeks go by without the headline of a major hack. It seems like the Cyber security industry will only get bigger with more and more devices getting online, from our cars to our appliances.\nWe saw the rise of \u2018Dark Marketing\u2019, where advertisers are able to target individuals based on increasingly granular attributes (including race, religion, beliefs) and as Prof Scott Galloway said, \u201cweaponise Facebook\u201d as a platform to change public opinion.\nIsraeli startups attracted about 20% of the global funding for the security sector and saw the IPO of ForScout, reaching an $897M market cap.\n5. GAFAM\n5 companies now dominate tech (Google, Apple, Facebook, Amazon and Microsoft), or 7 if you add Alibaba and Tencent. Their power in the market is almost absolute for example, 99% of digital advertising growth is going to Facebook and Google. Just look at the size of Amazon compared to ALL OF RETAIL.\n\nTheir power is creating a public backlash \u2014 calling for tighter regulation on these companies dealings with privacy, data transparency and competition scrutiny.\nIt\u2019s also getting increasingly hard to find a niche to compete with these giants, as they expand into to every major area from Cloud, messaging, hardware, enterprise, etc, adopting an AI first strategy. As an example, take a look at everything that Amazon announced at AWS re: Invent 2017.\n\nIn my next posts I will cover additional trends that dominated 2017, including Fake News, the Seed Slump, digital health, etc as well as some predictions for 2018. In the meanwhile, take a moment to sign up to my newsletter.\n"
  },
  {
    "title": "Five tech trends that shaped 2017",
    "content": "Five tech trends that shaped 2017\n\u201cThe historian is a prophet looking backwards.\u201d \u2015 Friedrich Schlegel\n\nThis post was originally published on VC Cafe. As we approach the last stretch of 2017, I wanted to take stock of the tech trends that shaped our year. In the next post, I\u2019ll cover my predictions for 2018.\n1. Decentralisation\nPerhaps the most impactful trend this year is the proliferation of Blockchain technologies and cryptocurrencies into the mainstream.\nOn the Blockchain front we\u2019ve seen a wide array of potential applications from real estate to art dealing and diamond trade.\nOn Crypto, we moved from Voice Over IP to Money Over IP, and saw Bitcoin cross the $10,000 line. ICOs (initial coin offerings) became a \u2018thing\u2019 \u2014 tokenise everything, with people spending over $1M to buy virtual cats with Ethereum on CryptoKitties (it\u2019s been acquired since).\nFor a second it looked like White Papers were replacing the fundraising deck, with startups that struggled raising traditional funding completing multi millions ICOs seemingly overnight. Unfortunately, a large percent of ICOs feel like a potential scam, money gets taken off the table quickly and almost with no supervision, and with the only collateral at risk being reputation (in some cases, not even that).\n\nThis is just the beginning in my opinion, but regulation is likely to step in here very soon.\n\n2. AI is the new UI\nThe hype around AI reached new heights in 2017. Using a decision tree to apply a set of rules, or operating a chatbot don\u2019t necessarily qualify as using AI, but it is almost inevitable to avoid having some form of machine learning, deep leaning, NLP etc today\u2019s tech startups.\nAs a field, AI made major breakthroughs this year, namely DeepMind\u2019s AlphaGo decisive victory over the Go world champion, and then the improved version AlphaGo Zero, which was self taught and even better.\n\nThere\u2019s no doubt that AI will continue to penetrate entire industries, in particular Automotive (self driving vehicles), robotics, drones, healthcare and marketing tech \u2014 from advertising to customer service.\nAnother aspect of the rise of AI is the infrastructure side: new chips from Nvidia, Google and Graphcore to fuel our growing need for fast data processing.\nThe Artificial Intelligence Index 2017, a \u202aStanford report by AI Index (pdf) has some fantastic nuggets on the number of AI academic papers published, the number of enrolled students into AI courses, the growth rate of AI startups etc.\n\n3. Data is the new oil\nThere\u2019s one big problem with the perception of data being the new oil, the CEO of a successful AI startup told me. Large corporates are sure they are sitting on an oil field, and so spend millions to pour their data over to expensive data lakes, only to find that\u2019s it\u2019s hard to refine that crude oil (took the analogy all the way, I guess). Organisations are simply \u2018sitting\u2019 on their data, or paying for unproven expensive solutions. We are producing more data than ever in human history, and are getting better at understanding the patterns and the meaning of that data, but there\u2019s still a lot of friction in getting that data and using it wisely.\nFor example, researchers can now predict the face of person based on a tiny sample of DNA. We are able to predict what customers will churn or upgrade simply by watching a small sample of their behaviour, and soon, we should be able to predict where/when a crime is about to happen, by applying models to surveillance data and past crime statistics.\nWhere does the line cross? Ethical considerations are becoming a major part of big data and machine learning startups, with several companies and industry bodies formed to tackle these questions.\n4. Cyber is here to stay\nAlmost no weeks go by without the headline of a major hack. It seems like the Cyber security industry will only get bigger with more and more devices getting online, from our cars to our appliances.\nWe saw the rise of \u2018Dark Marketing\u2019, where advertisers are able to target individuals based on increasingly granular attributes (including race, religion, beliefs) and as Prof Scott Galloway said, \u201cweaponise Facebook\u201d as a platform to change public opinion.\nIsraeli startups attracted about 20% of the global funding for the security sector and saw the IPO of ForScout, reaching an $897M market cap.\n5. GAFAM\n5 companies now dominate tech (Google, Apple, Facebook, Amazon and Microsoft), or 7 if you add Alibaba and Tencent. Their power in the market is almost absolute for example, 99% of digital advertising growth is going to Facebook and Google. Just look at the size of Amazon compared to ALL OF RETAIL.\n\nTheir power is creating a public backlash \u2014 calling for tighter regulation on these companies dealings with privacy, data transparency and competition scrutiny.\nIt\u2019s also getting increasingly hard to find a niche to compete with these giants, as they expand into to every major area from Cloud, messaging, hardware, enterprise, etc, adopting an AI first strategy. As an example, take a look at everything that Amazon announced at AWS re: Invent 2017.\n\nIn my next posts I will cover additional trends that dominated 2017, including Fake News, the Seed Slump, digital health, etc as well as some predictions for 2018. In the meanwhile, take a moment to sign up to my newsletter.\n"
  },
  {
    "title": "Five tech trends that shaped 2017",
    "content": "Five tech trends that shaped 2017\n\u201cThe historian is a prophet looking backwards.\u201d \u2015 Friedrich Schlegel\n\nThis post was originally published on VC Cafe. As we approach the last stretch of 2017, I wanted to take stock of the tech trends that shaped our year. In the next post, I\u2019ll cover my predictions for 2018.\n1. Decentralisation\nPerhaps the most impactful trend this year is the proliferation of Blockchain technologies and cryptocurrencies into the mainstream.\nOn the Blockchain front we\u2019ve seen a wide array of potential applications from real estate to art dealing and diamond trade.\nOn Crypto, we moved from Voice Over IP to Money Over IP, and saw Bitcoin cross the $10,000 line. ICOs (initial coin offerings) became a \u2018thing\u2019 \u2014 tokenise everything, with people spending over $1M to buy virtual cats with Ethereum on CryptoKitties (it\u2019s been acquired since).\nFor a second it looked like White Papers were replacing the fundraising deck, with startups that struggled raising traditional funding completing multi millions ICOs seemingly overnight. Unfortunately, a large percent of ICOs feel like a potential scam, money gets taken off the table quickly and almost with no supervision, and with the only collateral at risk being reputation (in some cases, not even that).\n\nThis is just the beginning in my opinion, but regulation is likely to step in here very soon.\n\n2. AI is the new UI\nThe hype around AI reached new heights in 2017. Using a decision tree to apply a set of rules, or operating a chatbot don\u2019t necessarily qualify as using AI, but it is almost inevitable to avoid having some form of machine learning, deep leaning, NLP etc today\u2019s tech startups.\nAs a field, AI made major breakthroughs this year, namely DeepMind\u2019s AlphaGo decisive victory over the Go world champion, and then the improved version AlphaGo Zero, which was self taught and even better.\n\nThere\u2019s no doubt that AI will continue to penetrate entire industries, in particular Automotive (self driving vehicles), robotics, drones, healthcare and marketing tech \u2014 from advertising to customer service.\nAnother aspect of the rise of AI is the infrastructure side: new chips from Nvidia, Google and Graphcore to fuel our growing need for fast data processing.\nThe Artificial Intelligence Index 2017, a \u202aStanford report by AI Index (pdf) has some fantastic nuggets on the number of AI academic papers published, the number of enrolled students into AI courses, the growth rate of AI startups etc.\n\n3. Data is the new oil\nThere\u2019s one big problem with the perception of data being the new oil, the CEO of a successful AI startup told me. Large corporates are sure they are sitting on an oil field, and so spend millions to pour their data over to expensive data lakes, only to find that\u2019s it\u2019s hard to refine that crude oil (took the analogy all the way, I guess). Organisations are simply \u2018sitting\u2019 on their data, or paying for unproven expensive solutions. We are producing more data than ever in human history, and are getting better at understanding the patterns and the meaning of that data, but there\u2019s still a lot of friction in getting that data and using it wisely.\nFor example, researchers can now predict the face of person based on a tiny sample of DNA. We are able to predict what customers will churn or upgrade simply by watching a small sample of their behaviour, and soon, we should be able to predict where/when a crime is about to happen, by applying models to surveillance data and past crime statistics.\nWhere does the line cross? Ethical considerations are becoming a major part of big data and machine learning startups, with several companies and industry bodies formed to tackle these questions.\n4. Cyber is here to stay\nAlmost no weeks go by without the headline of a major hack. It seems like the Cyber security industry will only get bigger with more and more devices getting online, from our cars to our appliances.\nWe saw the rise of \u2018Dark Marketing\u2019, where advertisers are able to target individuals based on increasingly granular attributes (including race, religion, beliefs) and as Prof Scott Galloway said, \u201cweaponise Facebook\u201d as a platform to change public opinion.\nIsraeli startups attracted about 20% of the global funding for the security sector and saw the IPO of ForScout, reaching an $897M market cap.\n5. GAFAM\n5 companies now dominate tech (Google, Apple, Facebook, Amazon and Microsoft), or 7 if you add Alibaba and Tencent. Their power in the market is almost absolute for example, 99% of digital advertising growth is going to Facebook and Google. Just look at the size of Amazon compared to ALL OF RETAIL.\n\nTheir power is creating a public backlash \u2014 calling for tighter regulation on these companies dealings with privacy, data transparency and competition scrutiny.\nIt\u2019s also getting increasingly hard to find a niche to compete with these giants, as they expand into to every major area from Cloud, messaging, hardware, enterprise, etc, adopting an AI first strategy. As an example, take a look at everything that Amazon announced at AWS re: Invent 2017.\n\nIn my next posts I will cover additional trends that dominated 2017, including Fake News, the Seed Slump, digital health, etc as well as some predictions for 2018. In the meanwhile, take a moment to sign up to my newsletter.\n"
  },
  {
    "title": "Vectorized implementation of back-propagation",
    "content": "Vectorized implementation of back-propagation\n\nIn a previous post, we explained the basic principles behind back-propagation and how Neural Networks work. In this post, we will explain how to leverage optimised math libraries to speed-up the learning process.\nWhat is vectorization and why it matters?\n\u201cVectorization\u201d (simplified) is the process of rewriting a loop so that instead of processing a single element of an array N times, it processes several or all elements of the array simultaneously.\nLet\u2019s start by an example of a dataset with 1000 houses sold in a specific city. For each house we have 5 information: its area, the number of rooms, the construction year, the price paid and the agency fees. The goal is to train a model that predicts the price and the agency fees from the first 3 features.\nDataset example\nLet\u2019s consider a simple linear feed-forward model with 6 weights (W11,W12,W13,W21,W22,W23) where:\nPrice = W11.Area + W12.NbRooms + W13.Year\nFees = W21.Area + W22.NbRooms + W23.Year\nAs explained in more details previously, the goal of the machine learning, is to find which values for these 6 weights fit the model\u2019s output the closest to the dataset\u2019s real output. We start by initialising the weights randomly. Then, we forward-propagate to calculate the predicted price and agency fees. By comparing the results with the real price and fees from the dataset, we can get a gradient of the error to back-propagate later and update the weights accordingly.\nA simple implementation for this, would look something like this:\n\nThis sequential for loop on the dataset, is however too slow, and does not take advantage of modern parallelism in CPU and GPU.\nVectorizing forward-propagation\nIn order to achieve high performance, we need to transform the dataset into a matrix representation. If we take the column-based representation, every input from our dataset is copied to a column in the matrix.\nOur weight matrix will be a matrix of 2 rows x 3 columns.\nOur input matrix will be a matrix of 3 rows x 1000 columns.\nOur output matrix will be a matrix of 2 rows x 1000 columns.\nOur linear model that we are searching to solve, can then be presented in the following matrix-based form:\nMatrix or a vectorized-form of: Weights x Inputs = Outputs\nThe reason why this representation works, is because this is exactly how matrix multiplication operates:\nMatrix multiplication\nMatrix-multiplication: a row i of the first matrix is multiplied by a column j of the second matrix to calculate the value of the cell (i , j) of the output\nWith the vectorized implementation, the previous for loop with 1000 iterations can now be done with very few, high-performance vectorized operations as following:\nOn big datasets, and using GPUs (some have 1000 cores), we can expect in thousands of times of speedup! On CPUs, there are many advanced math libraries that implement high-performance matrix operations such as openBLAS.\nVectorizing back-propagation\nVectorizing forward-propagation is easy and straightforward, it follows the model definition. The challenge is in vectorizing the back-propagation of errors.\nWith numbers, if we pass a number x through a function f to get y=f(x), the derivative f\u2019 of f gives us the rate of change on y, when x changes.\nWith Matrices, we need to use the Jacobian, which is a Matrix made of the partial-derivatives in respect to the different elements of the input matrix.\nThe rational behind, is to fix all the elements in the input matrix except one, where we add a small delta \ud835\udeff to it and see what elements in the output matrix are affected, to which rate, and add them together. We do this for all elements of the input matrix, we get its gradient matrix at the input. Thus it has the same shape (number of rows and columns).\n\nConsider the following matrix operation. RxP=S, (And the first 3 equations that calculates the first 3 elements of the output S)\nEquation 1: s11 = r11.p11 + r12.p21 + r13.p31 (red output)\nEquation 2: s12 = r11.p12 + r12.p22 + r13.p32 (green output)\nEquation 3: s21 = r21.p11 + r22.p21 + r23.p31 (yellow output)\nLet\u2019s say we already have the gradient matrix \u0394S at the output S, and we want to back-propagate it to the input R (respectively P) to calculate \u0394R (resp. \u0394P). Since r11 is only involved in the calculation of s11 and s12 (red and green but not yellow), we can expect that only \ud835\udeffs11 and \ud835\udeffs12 back-propagate to \ud835\udeffr11.\nIn order to find the rate of back-propagation of \ud835\udeffs11, we partially derivate equation 1 in respect to r11 (and consider everything else as constant), we get the rate of p11 (Another way to explain this: a small change in r11, will be amplified by a p11 factor in s11).\nBy doing the same for \ud835\udeffs12 and equation 2, we get the rate of p12.\nIf we try to back-propagate \ud835\udeffs13 to r11, and derivate equation 3 in respect to r11, we get 0 since equation 3 does not depend at all on r11. Another way to see this: if we have an error or s21, there is nothing that can be done on r11 to reduce this error. Since r11 is not involved in the calculation of s21! The same applies for all the other elements of the S matrix (s21,s22,s31,s32).\nFinally, by adding up, we get \ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\nBy doing the same for all the elements of matrix R, we get the following:\n\ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\n\ud835\udeffr12=\ud835\udeffs11.p21 + \ud835\udeffs12.p22\n\ud835\udeffr13=\ud835\udeffs11.p31 + \ud835\udeffs12.p32\n\ud835\udeffr21=\ud835\udeffs21.p11 + \ud835\udeffs22.p12\n\ud835\udeffr22=\ud835\udeffs21.p21 + \ud835\udeffs22.p22\n\ud835\udeffr23=\ud835\udeffs21.p31 + \ud835\udeffs22.p32\n\ud835\udeffr31=\ud835\udeffs31.p11 + \ud835\udeffs32.p12\n\ud835\udeffr32=\ud835\udeffs31.p21 + \ud835\udeffs32.p22\n\ud835\udeffr33=\ud835\udeffs31.p31 + \ud835\udeffs32.p32\nIf we look closely to the pattern, we see we can put it in a vectorized matrix multiplication way as following:\n\nSimilarly, if we follow the same procedure to back-propagate to P, we get the following equation:\nVectorizing everything\nEach Neural network layer is made of several mathematical operations. If we manage to define each mathematical operation in term of matrix operations in both forward and backward passes, we get maximum speedup in learning.\nIn a first step, each Matrix M has to be augmented by a companion Matrix \u0394M to hold its gradient on the way back.\nIn a second step, each Matrix operation, has to define its own forward and backward operations. For instance:\n\nAfter creating this vectorized library of Mathematical operations, we can use this library to chain operations and create layers, activation functions, loss functions, optimizers. The back-propagation will be defined automatically as a callback stack (or calculation graph) of the mathematical functions used in each layer. This is how Tensorflow works to a certain extent.\nWe can see the full machine learning process as a stack of abstractions:\nAn abstraction of machine learning library stack\n"
  },
  {
    "title": "Vectorized implementation of back-propagation",
    "content": "Vectorized implementation of back-propagation\n\nIn a previous post, we explained the basic principles behind back-propagation and how Neural Networks work. In this post, we will explain how to leverage optimised math libraries to speed-up the learning process.\nWhat is vectorization and why it matters?\n\u201cVectorization\u201d (simplified) is the process of rewriting a loop so that instead of processing a single element of an array N times, it processes several or all elements of the array simultaneously.\nLet\u2019s start by an example of a dataset with 1000 houses sold in a specific city. For each house we have 5 information: its area, the number of rooms, the construction year, the price paid and the agency fees. The goal is to train a model that predicts the price and the agency fees from the first 3 features.\nDataset example\nLet\u2019s consider a simple linear feed-forward model with 6 weights (W11,W12,W13,W21,W22,W23) where:\nPrice = W11.Area + W12.NbRooms + W13.Year\nFees = W21.Area + W22.NbRooms + W23.Year\nAs explained in more details previously, the goal of the machine learning, is to find which values for these 6 weights fit the model\u2019s output the closest to the dataset\u2019s real output. We start by initialising the weights randomly. Then, we forward-propagate to calculate the predicted price and agency fees. By comparing the results with the real price and fees from the dataset, we can get a gradient of the error to back-propagate later and update the weights accordingly.\nA simple implementation for this, would look something like this:\n\nThis sequential for loop on the dataset, is however too slow, and does not take advantage of modern parallelism in CPU and GPU.\nVectorizing forward-propagation\nIn order to achieve high performance, we need to transform the dataset into a matrix representation. If we take the column-based representation, every input from our dataset is copied to a column in the matrix.\nOur weight matrix will be a matrix of 2 rows x 3 columns.\nOur input matrix will be a matrix of 3 rows x 1000 columns.\nOur output matrix will be a matrix of 2 rows x 1000 columns.\nOur linear model that we are searching to solve, can then be presented in the following matrix-based form:\nMatrix or a vectorized-form of: Weights x Inputs = Outputs\nThe reason why this representation works, is because this is exactly how matrix multiplication operates:\nMatrix multiplication\nMatrix-multiplication: a row i of the first matrix is multiplied by a column j of the second matrix to calculate the value of the cell (i , j) of the output\nWith the vectorized implementation, the previous for loop with 1000 iterations can now be done with very few, high-performance vectorized operations as following:\nOn big datasets, and using GPUs (some have 1000 cores), we can expect in thousands of times of speedup! On CPUs, there are many advanced math libraries that implement high-performance matrix operations such as openBLAS.\nVectorizing back-propagation\nVectorizing forward-propagation is easy and straightforward, it follows the model definition. The challenge is in vectorizing the back-propagation of errors.\nWith numbers, if we pass a number x through a function f to get y=f(x), the derivative f\u2019 of f gives us the rate of change on y, when x changes.\nWith Matrices, we need to use the Jacobian, which is a Matrix made of the partial-derivatives in respect to the different elements of the input matrix.\nThe rational behind, is to fix all the elements in the input matrix except one, where we add a small delta \ud835\udeff to it and see what elements in the output matrix are affected, to which rate, and add them together. We do this for all elements of the input matrix, we get its gradient matrix at the input. Thus it has the same shape (number of rows and columns).\n\nConsider the following matrix operation. RxP=S, (And the first 3 equations that calculates the first 3 elements of the output S)\nEquation 1: s11 = r11.p11 + r12.p21 + r13.p31 (red output)\nEquation 2: s12 = r11.p12 + r12.p22 + r13.p32 (green output)\nEquation 3: s21 = r21.p11 + r22.p21 + r23.p31 (yellow output)\nLet\u2019s say we already have the gradient matrix \u0394S at the output S, and we want to back-propagate it to the input R (respectively P) to calculate \u0394R (resp. \u0394P). Since r11 is only involved in the calculation of s11 and s12 (red and green but not yellow), we can expect that only \ud835\udeffs11 and \ud835\udeffs12 back-propagate to \ud835\udeffr11.\nIn order to find the rate of back-propagation of \ud835\udeffs11, we partially derivate equation 1 in respect to r11 (and consider everything else as constant), we get the rate of p11 (Another way to explain this: a small change in r11, will be amplified by a p11 factor in s11).\nBy doing the same for \ud835\udeffs12 and equation 2, we get the rate of p12.\nIf we try to back-propagate \ud835\udeffs13 to r11, and derivate equation 3 in respect to r11, we get 0 since equation 3 does not depend at all on r11. Another way to see this: if we have an error or s21, there is nothing that can be done on r11 to reduce this error. Since r11 is not involved in the calculation of s21! The same applies for all the other elements of the S matrix (s21,s22,s31,s32).\nFinally, by adding up, we get \ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\nBy doing the same for all the elements of matrix R, we get the following:\n\ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\n\ud835\udeffr12=\ud835\udeffs11.p21 + \ud835\udeffs12.p22\n\ud835\udeffr13=\ud835\udeffs11.p31 + \ud835\udeffs12.p32\n\ud835\udeffr21=\ud835\udeffs21.p11 + \ud835\udeffs22.p12\n\ud835\udeffr22=\ud835\udeffs21.p21 + \ud835\udeffs22.p22\n\ud835\udeffr23=\ud835\udeffs21.p31 + \ud835\udeffs22.p32\n\ud835\udeffr31=\ud835\udeffs31.p11 + \ud835\udeffs32.p12\n\ud835\udeffr32=\ud835\udeffs31.p21 + \ud835\udeffs32.p22\n\ud835\udeffr33=\ud835\udeffs31.p31 + \ud835\udeffs32.p32\nIf we look closely to the pattern, we see we can put it in a vectorized matrix multiplication way as following:\n\nSimilarly, if we follow the same procedure to back-propagate to P, we get the following equation:\nVectorizing everything\nEach Neural network layer is made of several mathematical operations. If we manage to define each mathematical operation in term of matrix operations in both forward and backward passes, we get maximum speedup in learning.\nIn a first step, each Matrix M has to be augmented by a companion Matrix \u0394M to hold its gradient on the way back.\nIn a second step, each Matrix operation, has to define its own forward and backward operations. For instance:\n\nAfter creating this vectorized library of Mathematical operations, we can use this library to chain operations and create layers, activation functions, loss functions, optimizers. The back-propagation will be defined automatically as a callback stack (or calculation graph) of the mathematical functions used in each layer. This is how Tensorflow works to a certain extent.\nWe can see the full machine learning process as a stack of abstractions:\nAn abstraction of machine learning library stack\n"
  },
  {
    "title": "Vectorized implementation of back-propagation",
    "content": "Vectorized implementation of back-propagation\n\nIn a previous post, we explained the basic principles behind back-propagation and how Neural Networks work. In this post, we will explain how to leverage optimised math libraries to speed-up the learning process.\nWhat is vectorization and why it matters?\n\u201cVectorization\u201d (simplified) is the process of rewriting a loop so that instead of processing a single element of an array N times, it processes several or all elements of the array simultaneously.\nLet\u2019s start by an example of a dataset with 1000 houses sold in a specific city. For each house we have 5 information: its area, the number of rooms, the construction year, the price paid and the agency fees. The goal is to train a model that predicts the price and the agency fees from the first 3 features.\nDataset example\nLet\u2019s consider a simple linear feed-forward model with 6 weights (W11,W12,W13,W21,W22,W23) where:\nPrice = W11.Area + W12.NbRooms + W13.Year\nFees = W21.Area + W22.NbRooms + W23.Year\nAs explained in more details previously, the goal of the machine learning, is to find which values for these 6 weights fit the model\u2019s output the closest to the dataset\u2019s real output. We start by initialising the weights randomly. Then, we forward-propagate to calculate the predicted price and agency fees. By comparing the results with the real price and fees from the dataset, we can get a gradient of the error to back-propagate later and update the weights accordingly.\nA simple implementation for this, would look something like this:\n\nThis sequential for loop on the dataset, is however too slow, and does not take advantage of modern parallelism in CPU and GPU.\nVectorizing forward-propagation\nIn order to achieve high performance, we need to transform the dataset into a matrix representation. If we take the column-based representation, every input from our dataset is copied to a column in the matrix.\nOur weight matrix will be a matrix of 2 rows x 3 columns.\nOur input matrix will be a matrix of 3 rows x 1000 columns.\nOur output matrix will be a matrix of 2 rows x 1000 columns.\nOur linear model that we are searching to solve, can then be presented in the following matrix-based form:\nMatrix or a vectorized-form of: Weights x Inputs = Outputs\nThe reason why this representation works, is because this is exactly how matrix multiplication operates:\nMatrix multiplication\nMatrix-multiplication: a row i of the first matrix is multiplied by a column j of the second matrix to calculate the value of the cell (i , j) of the output\nWith the vectorized implementation, the previous for loop with 1000 iterations can now be done with very few, high-performance vectorized operations as following:\nOn big datasets, and using GPUs (some have 1000 cores), we can expect in thousands of times of speedup! On CPUs, there are many advanced math libraries that implement high-performance matrix operations such as openBLAS.\nVectorizing back-propagation\nVectorizing forward-propagation is easy and straightforward, it follows the model definition. The challenge is in vectorizing the back-propagation of errors.\nWith numbers, if we pass a number x through a function f to get y=f(x), the derivative f\u2019 of f gives us the rate of change on y, when x changes.\nWith Matrices, we need to use the Jacobian, which is a Matrix made of the partial-derivatives in respect to the different elements of the input matrix.\nThe rational behind, is to fix all the elements in the input matrix except one, where we add a small delta \ud835\udeff to it and see what elements in the output matrix are affected, to which rate, and add them together. We do this for all elements of the input matrix, we get its gradient matrix at the input. Thus it has the same shape (number of rows and columns).\n\nConsider the following matrix operation. RxP=S, (And the first 3 equations that calculates the first 3 elements of the output S)\nEquation 1: s11 = r11.p11 + r12.p21 + r13.p31 (red output)\nEquation 2: s12 = r11.p12 + r12.p22 + r13.p32 (green output)\nEquation 3: s21 = r21.p11 + r22.p21 + r23.p31 (yellow output)\nLet\u2019s say we already have the gradient matrix \u0394S at the output S, and we want to back-propagate it to the input R (respectively P) to calculate \u0394R (resp. \u0394P). Since r11 is only involved in the calculation of s11 and s12 (red and green but not yellow), we can expect that only \ud835\udeffs11 and \ud835\udeffs12 back-propagate to \ud835\udeffr11.\nIn order to find the rate of back-propagation of \ud835\udeffs11, we partially derivate equation 1 in respect to r11 (and consider everything else as constant), we get the rate of p11 (Another way to explain this: a small change in r11, will be amplified by a p11 factor in s11).\nBy doing the same for \ud835\udeffs12 and equation 2, we get the rate of p12.\nIf we try to back-propagate \ud835\udeffs13 to r11, and derivate equation 3 in respect to r11, we get 0 since equation 3 does not depend at all on r11. Another way to see this: if we have an error or s21, there is nothing that can be done on r11 to reduce this error. Since r11 is not involved in the calculation of s21! The same applies for all the other elements of the S matrix (s21,s22,s31,s32).\nFinally, by adding up, we get \ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\nBy doing the same for all the elements of matrix R, we get the following:\n\ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\n\ud835\udeffr12=\ud835\udeffs11.p21 + \ud835\udeffs12.p22\n\ud835\udeffr13=\ud835\udeffs11.p31 + \ud835\udeffs12.p32\n\ud835\udeffr21=\ud835\udeffs21.p11 + \ud835\udeffs22.p12\n\ud835\udeffr22=\ud835\udeffs21.p21 + \ud835\udeffs22.p22\n\ud835\udeffr23=\ud835\udeffs21.p31 + \ud835\udeffs22.p32\n\ud835\udeffr31=\ud835\udeffs31.p11 + \ud835\udeffs32.p12\n\ud835\udeffr32=\ud835\udeffs31.p21 + \ud835\udeffs32.p22\n\ud835\udeffr33=\ud835\udeffs31.p31 + \ud835\udeffs32.p32\nIf we look closely to the pattern, we see we can put it in a vectorized matrix multiplication way as following:\n\nSimilarly, if we follow the same procedure to back-propagate to P, we get the following equation:\nVectorizing everything\nEach Neural network layer is made of several mathematical operations. If we manage to define each mathematical operation in term of matrix operations in both forward and backward passes, we get maximum speedup in learning.\nIn a first step, each Matrix M has to be augmented by a companion Matrix \u0394M to hold its gradient on the way back.\nIn a second step, each Matrix operation, has to define its own forward and backward operations. For instance:\n\nAfter creating this vectorized library of Mathematical operations, we can use this library to chain operations and create layers, activation functions, loss functions, optimizers. The back-propagation will be defined automatically as a callback stack (or calculation graph) of the mathematical functions used in each layer. This is how Tensorflow works to a certain extent.\nWe can see the full machine learning process as a stack of abstractions:\nAn abstraction of machine learning library stack\n"
  },
  {
    "title": "Vectorized implementation of back-propagation",
    "content": "Vectorized implementation of back-propagation\n\nIn a previous post, we explained the basic principles behind back-propagation and how Neural Networks work. In this post, we will explain how to leverage optimised math libraries to speed-up the learning process.\nWhat is vectorization and why it matters?\n\u201cVectorization\u201d (simplified) is the process of rewriting a loop so that instead of processing a single element of an array N times, it processes several or all elements of the array simultaneously.\nLet\u2019s start by an example of a dataset with 1000 houses sold in a specific city. For each house we have 5 information: its area, the number of rooms, the construction year, the price paid and the agency fees. The goal is to train a model that predicts the price and the agency fees from the first 3 features.\nDataset example\nLet\u2019s consider a simple linear feed-forward model with 6 weights (W11,W12,W13,W21,W22,W23) where:\nPrice = W11.Area + W12.NbRooms + W13.Year\nFees = W21.Area + W22.NbRooms + W23.Year\nAs explained in more details previously, the goal of the machine learning, is to find which values for these 6 weights fit the model\u2019s output the closest to the dataset\u2019s real output. We start by initialising the weights randomly. Then, we forward-propagate to calculate the predicted price and agency fees. By comparing the results with the real price and fees from the dataset, we can get a gradient of the error to back-propagate later and update the weights accordingly.\nA simple implementation for this, would look something like this:\n\nThis sequential for loop on the dataset, is however too slow, and does not take advantage of modern parallelism in CPU and GPU.\nVectorizing forward-propagation\nIn order to achieve high performance, we need to transform the dataset into a matrix representation. If we take the column-based representation, every input from our dataset is copied to a column in the matrix.\nOur weight matrix will be a matrix of 2 rows x 3 columns.\nOur input matrix will be a matrix of 3 rows x 1000 columns.\nOur output matrix will be a matrix of 2 rows x 1000 columns.\nOur linear model that we are searching to solve, can then be presented in the following matrix-based form:\nMatrix or a vectorized-form of: Weights x Inputs = Outputs\nThe reason why this representation works, is because this is exactly how matrix multiplication operates:\nMatrix multiplication\nMatrix-multiplication: a row i of the first matrix is multiplied by a column j of the second matrix to calculate the value of the cell (i , j) of the output\nWith the vectorized implementation, the previous for loop with 1000 iterations can now be done with very few, high-performance vectorized operations as following:\nOn big datasets, and using GPUs (some have 1000 cores), we can expect in thousands of times of speedup! On CPUs, there are many advanced math libraries that implement high-performance matrix operations such as openBLAS.\nVectorizing back-propagation\nVectorizing forward-propagation is easy and straightforward, it follows the model definition. The challenge is in vectorizing the back-propagation of errors.\nWith numbers, if we pass a number x through a function f to get y=f(x), the derivative f\u2019 of f gives us the rate of change on y, when x changes.\nWith Matrices, we need to use the Jacobian, which is a Matrix made of the partial-derivatives in respect to the different elements of the input matrix.\nThe rational behind, is to fix all the elements in the input matrix except one, where we add a small delta \ud835\udeff to it and see what elements in the output matrix are affected, to which rate, and add them together. We do this for all elements of the input matrix, we get its gradient matrix at the input. Thus it has the same shape (number of rows and columns).\n\nConsider the following matrix operation. RxP=S, (And the first 3 equations that calculates the first 3 elements of the output S)\nEquation 1: s11 = r11.p11 + r12.p21 + r13.p31 (red output)\nEquation 2: s12 = r11.p12 + r12.p22 + r13.p32 (green output)\nEquation 3: s21 = r21.p11 + r22.p21 + r23.p31 (yellow output)\nLet\u2019s say we already have the gradient matrix \u0394S at the output S, and we want to back-propagate it to the input R (respectively P) to calculate \u0394R (resp. \u0394P). Since r11 is only involved in the calculation of s11 and s12 (red and green but not yellow), we can expect that only \ud835\udeffs11 and \ud835\udeffs12 back-propagate to \ud835\udeffr11.\nIn order to find the rate of back-propagation of \ud835\udeffs11, we partially derivate equation 1 in respect to r11 (and consider everything else as constant), we get the rate of p11 (Another way to explain this: a small change in r11, will be amplified by a p11 factor in s11).\nBy doing the same for \ud835\udeffs12 and equation 2, we get the rate of p12.\nIf we try to back-propagate \ud835\udeffs13 to r11, and derivate equation 3 in respect to r11, we get 0 since equation 3 does not depend at all on r11. Another way to see this: if we have an error or s21, there is nothing that can be done on r11 to reduce this error. Since r11 is not involved in the calculation of s21! The same applies for all the other elements of the S matrix (s21,s22,s31,s32).\nFinally, by adding up, we get \ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\nBy doing the same for all the elements of matrix R, we get the following:\n\ud835\udeffr11=\ud835\udeffs11.p11 + \ud835\udeffs12.p12\n\ud835\udeffr12=\ud835\udeffs11.p21 + \ud835\udeffs12.p22\n\ud835\udeffr13=\ud835\udeffs11.p31 + \ud835\udeffs12.p32\n\ud835\udeffr21=\ud835\udeffs21.p11 + \ud835\udeffs22.p12\n\ud835\udeffr22=\ud835\udeffs21.p21 + \ud835\udeffs22.p22\n\ud835\udeffr23=\ud835\udeffs21.p31 + \ud835\udeffs22.p32\n\ud835\udeffr31=\ud835\udeffs31.p11 + \ud835\udeffs32.p12\n\ud835\udeffr32=\ud835\udeffs31.p21 + \ud835\udeffs32.p22\n\ud835\udeffr33=\ud835\udeffs31.p31 + \ud835\udeffs32.p32\nIf we look closely to the pattern, we see we can put it in a vectorized matrix multiplication way as following:\n\nSimilarly, if we follow the same procedure to back-propagate to P, we get the following equation:\nVectorizing everything\nEach Neural network layer is made of several mathematical operations. If we manage to define each mathematical operation in term of matrix operations in both forward and backward passes, we get maximum speedup in learning.\nIn a first step, each Matrix M has to be augmented by a companion Matrix \u0394M to hold its gradient on the way back.\nIn a second step, each Matrix operation, has to define its own forward and backward operations. For instance:\n\nAfter creating this vectorized library of Mathematical operations, we can use this library to chain operations and create layers, activation functions, loss functions, optimizers. The back-propagation will be defined automatically as a callback stack (or calculation graph) of the mathematical functions used in each layer. This is how Tensorflow works to a certain extent.\nWe can see the full machine learning process as a stack of abstractions:\nAn abstraction of machine learning library stack\n"
  },
  {
    "title": "Building Smarter Businesses With Cognitive Services",
    "content": "Building Smarter Businesses With Cognitive Services\nToday\u2019s successful businesses aren\u2019t just fast and efficient. They\u2019re becoming truly smart thanks to a new breed of technology called \u201ccognitive services.\u201d\n\nThe term \u201ccognitive services\u201d describes machine learning, artificial intelligence, and distributed algorithms that make it easy to integrate vision, speech, language, knowledge, problem-solving, analysis, categorization, moderation, and more into apps and businesses.\nCognitive services enable applications to evolve and adapt rather than simply following prewritten rules. They augment and expand human capabilities, allowing us to do our jobs faster, more efficiently, and more sustainably.\nCognitive computing doesn\u2019t aim to replace the human element but to extend human capabilities. Humans can think deeply and use reason to solve complex problems, but we lack the ability to analyze and process massive amounts of data. That\u2019s where computers excel. Cognitive computing era makes the most of both strengths: the human\u2019s and the machine\u2019s.\nAs cognitive systems solve complex problems, they improve their efficiency and accuracy building and acting upon sophisticated pattern recognition models. These systems aren\u2019t explicitly programmed to work in a fully prescribed way but to naturally interact with human data inputs, then learn and grow based on the data they accumulate.\nBig players like Watson, AWS, and Microsoft, as well as fast-moving startups like SiftNinja and Clarifai, have released a massive number of cognitive services, delivering them through APIs that make them a snap to fold into new applications.\nExamples of Cognitive Services\nTranslation: Enable two users to chat in their own \u2014 different! \u2014 languages by translating their messages in real-time.\nNatural language processing: Analyze massive amounts of data inputs and gauge the sentiment of the messages.\nChatbots: Create an intelligent bot that parses natural language from a human and responds as accurately as another human could.\nFacial recognition: Detect human faces and organize them into groups based on predetermined categories.\nMachine learning: Intelligently sense, process, and act on information delivered by sensors to control devices in response to environmental factors like temperature, rain, or earthquakes.\nThe Impact of Cognitive Services\nCognitive services are used to create new types of customer engagement, build smarter products, improve internal operations, and make smarter decisions. Cognitive services have already made a significant impact on three areas of business.\nDiscovery\nWith the vast amounts of data and information they have at their disposal, applications can use cognitive services to find patterns, insights, and connections that the hardest-working human might never identify. And having found patterns once, they can create new and unanticipated ways to adapt and grow, making discovery a more accurate and efficient proposition.\nEngagement\nCognitive services empower businesses to see, hear, speak, understand, and interpret natural language and information sets, enabling them to create new, engaging experiences for users, customers and themselves. By understanding and responding to the ways users interact with apps and each other, cognitive systems are changing the way humans and systems interact.\nDecision\nThe most challenging but potentially revolutionary impact of cognitive services is on the decision-making process. Intelligent systems can rapidly weigh evidence and analyze information, then make a decision based on data, not hunches. They can consider and act on complex sets of information \u2014 something as simple as recommending a product on an e-commerce site or as complex as optimizing smart devices in an industrial setting.\nThe Rise of Cognitive Business\nOrganizations that deploy cognitive services will work more efficiently, safely, and sustainably, and deliver more engaging and immersive experiences to their customers. From the way we buy goods to the way our children learn to the food that we eat, they will drive the innovation of industries and organizations into the future.\nThe question is, How can you get started implementing dynamic cognitive services into your business today? To start, look at a couple things:\nWhat are the biggest inefficiencies affecting your workflow today?\nWhat are your most significant customer complaints?\nWhat processes represent the biggest bottlenecks?\nWith answers in hand, you\u2019ll be ready to explore the vast range of cognitive services at your fingertips and discover how they can transform your business.\nIntelligence at the Edge: Event-Driven Architecture\nEvent-driven architecture provides an efficient way to carry out cognitive tasks. It applies basic business logic while data is in motion and can decide whether to involve back-end processes.\n\nCognitive services are quickly changing applications and the businesses that deploy them. Using APIs from companies like IBM, AWS, and Microsoft, developers can leverage some of the world\u2019s most sophisticated technology for computer vision, translation, sentiment analysis, and much more with just a few lines of code.\nTo get the most out of cognitive services, many developers are adopting a design pattern called event-driven architecture.\nAs the name suggests, event-driven architecture makes software change its behavior in response to events in real-time. Event-driven architecture is different from traditional request-response architectures such as REST in that an event-driven system broadcasts a notification when a predefined event occurs rather than following along a set path of subsequent subroutines.\nThis notification may be picked up by any number of other systems, whose use of the information is decoupled from the original event. It\u2019s a way to create faster, more dynamic, more distributed, and independent applications, allowing you to trigger and execute business logic at the edge, with each system informed by, but not necessarily reliant upon, the next.\nImage Source: Moving the Cloud to the Edge\nWhat Is the Connection With Cognitive Services?\nThe event-driven design pattern provides a fast and efficient way to carry out cognitive tasks. Instead of sending all your data to an external server, having that server parse the data, and figuring out what action to take, it applies basic business logic while the data is in motion, directly in your network, and can decide whether to involve back-end processes. This way, you aren\u2019t wasting valuable bandwidth or computational power sending data that never needed to travel back to home base for processing.\nAs a result, it becomes possible to build powerful cognitive applications right where the intelligence is applied: at the edge of the network.\nBecause cognitive services are delivered as discrete components, you can add them via serverless microservices and process data in real-time without the need for ingestion by a centralized data center unless it is truly necessary.\nA Case Study: Yummy Cola\nLet\u2019s take one example. Say a beverage company called Yummy Cola is launching a new line of flavored colas leading up to, and during, this year\u2019s Super Bowl. It wants to monitor brand reaction through social media channels but knows the #superbowl hashtag will be incredibly busy with game analysis and the activity of other brands. It needs a way to filter their brand mentions and gauge the sentiment of how users feel about their product launch.\nTo do this at scale would cost a fortune, and without an event-driven architecture, sending every user\u2019s message to a central server or data center to process and analyze would be incredibly slow. An event-driven system will be much more efficient, using cognitive services to carry out basic business logic at the edge.\nIn this way, the brand can monitor each message, determine whether it refers to the new colas, parse the sentiment of the relevant ones, and only pass the relevant information to the back end.\nTo do this, it could deploy edge computing resources to filter the messages with a natural language processing service, identifying which messages mentioned the brand and which were unrelated. From there, it could use a different cognitive service to analyze people\u2019s feelings about the different colas. It could even publish the popularity of the different products. And it could do all this without bringing the back-end servers into play.\nArchitecture for the Edge \u2014 and Beyond\nRESTful architectures were well-suited to an earlier, simpler generation of web applications. Modern applications demand a different approach, with their dense mesh of microservices, edge-computing nodes, and streams of data from sensors and devices.\nWhat applications need most now is an architecture that is light, flexible, and decentralized. Event-driven architecture satisfies on all counts \u2014 an elegant example of form following function.\n\nWant in-depth analysis of how cognitive services are changing everything? Check out our full eBook: A World Transformed: Building Smarter, Next Generation Apps with Cognitive Services. In it, we cover:\nWhat are cognitive services?\nHow cognitive services are transforming business\nCognitive services and edge computing\nUse cases of today and tomorrow\nOriginally published at dzone.com.\n"
  },
  {
    "title": "Building Smarter Businesses With Cognitive Services",
    "content": "Building Smarter Businesses With Cognitive Services\nToday\u2019s successful businesses aren\u2019t just fast and efficient. They\u2019re becoming truly smart thanks to a new breed of technology called \u201ccognitive services.\u201d\n\nThe term \u201ccognitive services\u201d describes machine learning, artificial intelligence, and distributed algorithms that make it easy to integrate vision, speech, language, knowledge, problem-solving, analysis, categorization, moderation, and more into apps and businesses.\nCognitive services enable applications to evolve and adapt rather than simply following prewritten rules. They augment and expand human capabilities, allowing us to do our jobs faster, more efficiently, and more sustainably.\nCognitive computing doesn\u2019t aim to replace the human element but to extend human capabilities. Humans can think deeply and use reason to solve complex problems, but we lack the ability to analyze and process massive amounts of data. That\u2019s where computers excel. Cognitive computing era makes the most of both strengths: the human\u2019s and the machine\u2019s.\nAs cognitive systems solve complex problems, they improve their efficiency and accuracy building and acting upon sophisticated pattern recognition models. These systems aren\u2019t explicitly programmed to work in a fully prescribed way but to naturally interact with human data inputs, then learn and grow based on the data they accumulate.\nBig players like Watson, AWS, and Microsoft, as well as fast-moving startups like SiftNinja and Clarifai, have released a massive number of cognitive services, delivering them through APIs that make them a snap to fold into new applications.\nExamples of Cognitive Services\nTranslation: Enable two users to chat in their own \u2014 different! \u2014 languages by translating their messages in real-time.\nNatural language processing: Analyze massive amounts of data inputs and gauge the sentiment of the messages.\nChatbots: Create an intelligent bot that parses natural language from a human and responds as accurately as another human could.\nFacial recognition: Detect human faces and organize them into groups based on predetermined categories.\nMachine learning: Intelligently sense, process, and act on information delivered by sensors to control devices in response to environmental factors like temperature, rain, or earthquakes.\nThe Impact of Cognitive Services\nCognitive services are used to create new types of customer engagement, build smarter products, improve internal operations, and make smarter decisions. Cognitive services have already made a significant impact on three areas of business.\nDiscovery\nWith the vast amounts of data and information they have at their disposal, applications can use cognitive services to find patterns, insights, and connections that the hardest-working human might never identify. And having found patterns once, they can create new and unanticipated ways to adapt and grow, making discovery a more accurate and efficient proposition.\nEngagement\nCognitive services empower businesses to see, hear, speak, understand, and interpret natural language and information sets, enabling them to create new, engaging experiences for users, customers and themselves. By understanding and responding to the ways users interact with apps and each other, cognitive systems are changing the way humans and systems interact.\nDecision\nThe most challenging but potentially revolutionary impact of cognitive services is on the decision-making process. Intelligent systems can rapidly weigh evidence and analyze information, then make a decision based on data, not hunches. They can consider and act on complex sets of information \u2014 something as simple as recommending a product on an e-commerce site or as complex as optimizing smart devices in an industrial setting.\nThe Rise of Cognitive Business\nOrganizations that deploy cognitive services will work more efficiently, safely, and sustainably, and deliver more engaging and immersive experiences to their customers. From the way we buy goods to the way our children learn to the food that we eat, they will drive the innovation of industries and organizations into the future.\nThe question is, How can you get started implementing dynamic cognitive services into your business today? To start, look at a couple things:\nWhat are the biggest inefficiencies affecting your workflow today?\nWhat are your most significant customer complaints?\nWhat processes represent the biggest bottlenecks?\nWith answers in hand, you\u2019ll be ready to explore the vast range of cognitive services at your fingertips and discover how they can transform your business.\nIntelligence at the Edge: Event-Driven Architecture\nEvent-driven architecture provides an efficient way to carry out cognitive tasks. It applies basic business logic while data is in motion and can decide whether to involve back-end processes.\n\nCognitive services are quickly changing applications and the businesses that deploy them. Using APIs from companies like IBM, AWS, and Microsoft, developers can leverage some of the world\u2019s most sophisticated technology for computer vision, translation, sentiment analysis, and much more with just a few lines of code.\nTo get the most out of cognitive services, many developers are adopting a design pattern called event-driven architecture.\nAs the name suggests, event-driven architecture makes software change its behavior in response to events in real-time. Event-driven architecture is different from traditional request-response architectures such as REST in that an event-driven system broadcasts a notification when a predefined event occurs rather than following along a set path of subsequent subroutines.\nThis notification may be picked up by any number of other systems, whose use of the information is decoupled from the original event. It\u2019s a way to create faster, more dynamic, more distributed, and independent applications, allowing you to trigger and execute business logic at the edge, with each system informed by, but not necessarily reliant upon, the next.\nImage Source: Moving the Cloud to the Edge\nWhat Is the Connection With Cognitive Services?\nThe event-driven design pattern provides a fast and efficient way to carry out cognitive tasks. Instead of sending all your data to an external server, having that server parse the data, and figuring out what action to take, it applies basic business logic while the data is in motion, directly in your network, and can decide whether to involve back-end processes. This way, you aren\u2019t wasting valuable bandwidth or computational power sending data that never needed to travel back to home base for processing.\nAs a result, it becomes possible to build powerful cognitive applications right where the intelligence is applied: at the edge of the network.\nBecause cognitive services are delivered as discrete components, you can add them via serverless microservices and process data in real-time without the need for ingestion by a centralized data center unless it is truly necessary.\nA Case Study: Yummy Cola\nLet\u2019s take one example. Say a beverage company called Yummy Cola is launching a new line of flavored colas leading up to, and during, this year\u2019s Super Bowl. It wants to monitor brand reaction through social media channels but knows the #superbowl hashtag will be incredibly busy with game analysis and the activity of other brands. It needs a way to filter their brand mentions and gauge the sentiment of how users feel about their product launch.\nTo do this at scale would cost a fortune, and without an event-driven architecture, sending every user\u2019s message to a central server or data center to process and analyze would be incredibly slow. An event-driven system will be much more efficient, using cognitive services to carry out basic business logic at the edge.\nIn this way, the brand can monitor each message, determine whether it refers to the new colas, parse the sentiment of the relevant ones, and only pass the relevant information to the back end.\nTo do this, it could deploy edge computing resources to filter the messages with a natural language processing service, identifying which messages mentioned the brand and which were unrelated. From there, it could use a different cognitive service to analyze people\u2019s feelings about the different colas. It could even publish the popularity of the different products. And it could do all this without bringing the back-end servers into play.\nArchitecture for the Edge \u2014 and Beyond\nRESTful architectures were well-suited to an earlier, simpler generation of web applications. Modern applications demand a different approach, with their dense mesh of microservices, edge-computing nodes, and streams of data from sensors and devices.\nWhat applications need most now is an architecture that is light, flexible, and decentralized. Event-driven architecture satisfies on all counts \u2014 an elegant example of form following function.\n\nWant in-depth analysis of how cognitive services are changing everything? Check out our full eBook: A World Transformed: Building Smarter, Next Generation Apps with Cognitive Services. In it, we cover:\nWhat are cognitive services?\nHow cognitive services are transforming business\nCognitive services and edge computing\nUse cases of today and tomorrow\nOriginally published at dzone.com.\n"
  },
  {
    "title": "Building Smarter Businesses With Cognitive Services",
    "content": "Building Smarter Businesses With Cognitive Services\nToday\u2019s successful businesses aren\u2019t just fast and efficient. They\u2019re becoming truly smart thanks to a new breed of technology called \u201ccognitive services.\u201d\n\nThe term \u201ccognitive services\u201d describes machine learning, artificial intelligence, and distributed algorithms that make it easy to integrate vision, speech, language, knowledge, problem-solving, analysis, categorization, moderation, and more into apps and businesses.\nCognitive services enable applications to evolve and adapt rather than simply following prewritten rules. They augment and expand human capabilities, allowing us to do our jobs faster, more efficiently, and more sustainably.\nCognitive computing doesn\u2019t aim to replace the human element but to extend human capabilities. Humans can think deeply and use reason to solve complex problems, but we lack the ability to analyze and process massive amounts of data. That\u2019s where computers excel. Cognitive computing era makes the most of both strengths: the human\u2019s and the machine\u2019s.\nAs cognitive systems solve complex problems, they improve their efficiency and accuracy building and acting upon sophisticated pattern recognition models. These systems aren\u2019t explicitly programmed to work in a fully prescribed way but to naturally interact with human data inputs, then learn and grow based on the data they accumulate.\nBig players like Watson, AWS, and Microsoft, as well as fast-moving startups like SiftNinja and Clarifai, have released a massive number of cognitive services, delivering them through APIs that make them a snap to fold into new applications.\nExamples of Cognitive Services\nTranslation: Enable two users to chat in their own \u2014 different! \u2014 languages by translating their messages in real-time.\nNatural language processing: Analyze massive amounts of data inputs and gauge the sentiment of the messages.\nChatbots: Create an intelligent bot that parses natural language from a human and responds as accurately as another human could.\nFacial recognition: Detect human faces and organize them into groups based on predetermined categories.\nMachine learning: Intelligently sense, process, and act on information delivered by sensors to control devices in response to environmental factors like temperature, rain, or earthquakes.\nThe Impact of Cognitive Services\nCognitive services are used to create new types of customer engagement, build smarter products, improve internal operations, and make smarter decisions. Cognitive services have already made a significant impact on three areas of business.\nDiscovery\nWith the vast amounts of data and information they have at their disposal, applications can use cognitive services to find patterns, insights, and connections that the hardest-working human might never identify. And having found patterns once, they can create new and unanticipated ways to adapt and grow, making discovery a more accurate and efficient proposition.\nEngagement\nCognitive services empower businesses to see, hear, speak, understand, and interpret natural language and information sets, enabling them to create new, engaging experiences for users, customers and themselves. By understanding and responding to the ways users interact with apps and each other, cognitive systems are changing the way humans and systems interact.\nDecision\nThe most challenging but potentially revolutionary impact of cognitive services is on the decision-making process. Intelligent systems can rapidly weigh evidence and analyze information, then make a decision based on data, not hunches. They can consider and act on complex sets of information \u2014 something as simple as recommending a product on an e-commerce site or as complex as optimizing smart devices in an industrial setting.\nThe Rise of Cognitive Business\nOrganizations that deploy cognitive services will work more efficiently, safely, and sustainably, and deliver more engaging and immersive experiences to their customers. From the way we buy goods to the way our children learn to the food that we eat, they will drive the innovation of industries and organizations into the future.\nThe question is, How can you get started implementing dynamic cognitive services into your business today? To start, look at a couple things:\nWhat are the biggest inefficiencies affecting your workflow today?\nWhat are your most significant customer complaints?\nWhat processes represent the biggest bottlenecks?\nWith answers in hand, you\u2019ll be ready to explore the vast range of cognitive services at your fingertips and discover how they can transform your business.\nIntelligence at the Edge: Event-Driven Architecture\nEvent-driven architecture provides an efficient way to carry out cognitive tasks. It applies basic business logic while data is in motion and can decide whether to involve back-end processes.\n\nCognitive services are quickly changing applications and the businesses that deploy them. Using APIs from companies like IBM, AWS, and Microsoft, developers can leverage some of the world\u2019s most sophisticated technology for computer vision, translation, sentiment analysis, and much more with just a few lines of code.\nTo get the most out of cognitive services, many developers are adopting a design pattern called event-driven architecture.\nAs the name suggests, event-driven architecture makes software change its behavior in response to events in real-time. Event-driven architecture is different from traditional request-response architectures such as REST in that an event-driven system broadcasts a notification when a predefined event occurs rather than following along a set path of subsequent subroutines.\nThis notification may be picked up by any number of other systems, whose use of the information is decoupled from the original event. It\u2019s a way to create faster, more dynamic, more distributed, and independent applications, allowing you to trigger and execute business logic at the edge, with each system informed by, but not necessarily reliant upon, the next.\nImage Source: Moving the Cloud to the Edge\nWhat Is the Connection With Cognitive Services?\nThe event-driven design pattern provides a fast and efficient way to carry out cognitive tasks. Instead of sending all your data to an external server, having that server parse the data, and figuring out what action to take, it applies basic business logic while the data is in motion, directly in your network, and can decide whether to involve back-end processes. This way, you aren\u2019t wasting valuable bandwidth or computational power sending data that never needed to travel back to home base for processing.\nAs a result, it becomes possible to build powerful cognitive applications right where the intelligence is applied: at the edge of the network.\nBecause cognitive services are delivered as discrete components, you can add them via serverless microservices and process data in real-time without the need for ingestion by a centralized data center unless it is truly necessary.\nA Case Study: Yummy Cola\nLet\u2019s take one example. Say a beverage company called Yummy Cola is launching a new line of flavored colas leading up to, and during, this year\u2019s Super Bowl. It wants to monitor brand reaction through social media channels but knows the #superbowl hashtag will be incredibly busy with game analysis and the activity of other brands. It needs a way to filter their brand mentions and gauge the sentiment of how users feel about their product launch.\nTo do this at scale would cost a fortune, and without an event-driven architecture, sending every user\u2019s message to a central server or data center to process and analyze would be incredibly slow. An event-driven system will be much more efficient, using cognitive services to carry out basic business logic at the edge.\nIn this way, the brand can monitor each message, determine whether it refers to the new colas, parse the sentiment of the relevant ones, and only pass the relevant information to the back end.\nTo do this, it could deploy edge computing resources to filter the messages with a natural language processing service, identifying which messages mentioned the brand and which were unrelated. From there, it could use a different cognitive service to analyze people\u2019s feelings about the different colas. It could even publish the popularity of the different products. And it could do all this without bringing the back-end servers into play.\nArchitecture for the Edge \u2014 and Beyond\nRESTful architectures were well-suited to an earlier, simpler generation of web applications. Modern applications demand a different approach, with their dense mesh of microservices, edge-computing nodes, and streams of data from sensors and devices.\nWhat applications need most now is an architecture that is light, flexible, and decentralized. Event-driven architecture satisfies on all counts \u2014 an elegant example of form following function.\n\nWant in-depth analysis of how cognitive services are changing everything? Check out our full eBook: A World Transformed: Building Smarter, Next Generation Apps with Cognitive Services. In it, we cover:\nWhat are cognitive services?\nHow cognitive services are transforming business\nCognitive services and edge computing\nUse cases of today and tomorrow\nOriginally published at dzone.com.\n"
  },
  {
    "title": "Building Smarter Businesses With Cognitive Services",
    "content": "Building Smarter Businesses With Cognitive Services\nToday\u2019s successful businesses aren\u2019t just fast and efficient. They\u2019re becoming truly smart thanks to a new breed of technology called \u201ccognitive services.\u201d\n\nThe term \u201ccognitive services\u201d describes machine learning, artificial intelligence, and distributed algorithms that make it easy to integrate vision, speech, language, knowledge, problem-solving, analysis, categorization, moderation, and more into apps and businesses.\nCognitive services enable applications to evolve and adapt rather than simply following prewritten rules. They augment and expand human capabilities, allowing us to do our jobs faster, more efficiently, and more sustainably.\nCognitive computing doesn\u2019t aim to replace the human element but to extend human capabilities. Humans can think deeply and use reason to solve complex problems, but we lack the ability to analyze and process massive amounts of data. That\u2019s where computers excel. Cognitive computing era makes the most of both strengths: the human\u2019s and the machine\u2019s.\nAs cognitive systems solve complex problems, they improve their efficiency and accuracy building and acting upon sophisticated pattern recognition models. These systems aren\u2019t explicitly programmed to work in a fully prescribed way but to naturally interact with human data inputs, then learn and grow based on the data they accumulate.\nBig players like Watson, AWS, and Microsoft, as well as fast-moving startups like SiftNinja and Clarifai, have released a massive number of cognitive services, delivering them through APIs that make them a snap to fold into new applications.\nExamples of Cognitive Services\nTranslation: Enable two users to chat in their own \u2014 different! \u2014 languages by translating their messages in real-time.\nNatural language processing: Analyze massive amounts of data inputs and gauge the sentiment of the messages.\nChatbots: Create an intelligent bot that parses natural language from a human and responds as accurately as another human could.\nFacial recognition: Detect human faces and organize them into groups based on predetermined categories.\nMachine learning: Intelligently sense, process, and act on information delivered by sensors to control devices in response to environmental factors like temperature, rain, or earthquakes.\nThe Impact of Cognitive Services\nCognitive services are used to create new types of customer engagement, build smarter products, improve internal operations, and make smarter decisions. Cognitive services have already made a significant impact on three areas of business.\nDiscovery\nWith the vast amounts of data and information they have at their disposal, applications can use cognitive services to find patterns, insights, and connections that the hardest-working human might never identify. And having found patterns once, they can create new and unanticipated ways to adapt and grow, making discovery a more accurate and efficient proposition.\nEngagement\nCognitive services empower businesses to see, hear, speak, understand, and interpret natural language and information sets, enabling them to create new, engaging experiences for users, customers and themselves. By understanding and responding to the ways users interact with apps and each other, cognitive systems are changing the way humans and systems interact.\nDecision\nThe most challenging but potentially revolutionary impact of cognitive services is on the decision-making process. Intelligent systems can rapidly weigh evidence and analyze information, then make a decision based on data, not hunches. They can consider and act on complex sets of information \u2014 something as simple as recommending a product on an e-commerce site or as complex as optimizing smart devices in an industrial setting.\nThe Rise of Cognitive Business\nOrganizations that deploy cognitive services will work more efficiently, safely, and sustainably, and deliver more engaging and immersive experiences to their customers. From the way we buy goods to the way our children learn to the food that we eat, they will drive the innovation of industries and organizations into the future.\nThe question is, How can you get started implementing dynamic cognitive services into your business today? To start, look at a couple things:\nWhat are the biggest inefficiencies affecting your workflow today?\nWhat are your most significant customer complaints?\nWhat processes represent the biggest bottlenecks?\nWith answers in hand, you\u2019ll be ready to explore the vast range of cognitive services at your fingertips and discover how they can transform your business.\nIntelligence at the Edge: Event-Driven Architecture\nEvent-driven architecture provides an efficient way to carry out cognitive tasks. It applies basic business logic while data is in motion and can decide whether to involve back-end processes.\n\nCognitive services are quickly changing applications and the businesses that deploy them. Using APIs from companies like IBM, AWS, and Microsoft, developers can leverage some of the world\u2019s most sophisticated technology for computer vision, translation, sentiment analysis, and much more with just a few lines of code.\nTo get the most out of cognitive services, many developers are adopting a design pattern called event-driven architecture.\nAs the name suggests, event-driven architecture makes software change its behavior in response to events in real-time. Event-driven architecture is different from traditional request-response architectures such as REST in that an event-driven system broadcasts a notification when a predefined event occurs rather than following along a set path of subsequent subroutines.\nThis notification may be picked up by any number of other systems, whose use of the information is decoupled from the original event. It\u2019s a way to create faster, more dynamic, more distributed, and independent applications, allowing you to trigger and execute business logic at the edge, with each system informed by, but not necessarily reliant upon, the next.\nImage Source: Moving the Cloud to the Edge\nWhat Is the Connection With Cognitive Services?\nThe event-driven design pattern provides a fast and efficient way to carry out cognitive tasks. Instead of sending all your data to an external server, having that server parse the data, and figuring out what action to take, it applies basic business logic while the data is in motion, directly in your network, and can decide whether to involve back-end processes. This way, you aren\u2019t wasting valuable bandwidth or computational power sending data that never needed to travel back to home base for processing.\nAs a result, it becomes possible to build powerful cognitive applications right where the intelligence is applied: at the edge of the network.\nBecause cognitive services are delivered as discrete components, you can add them via serverless microservices and process data in real-time without the need for ingestion by a centralized data center unless it is truly necessary.\nA Case Study: Yummy Cola\nLet\u2019s take one example. Say a beverage company called Yummy Cola is launching a new line of flavored colas leading up to, and during, this year\u2019s Super Bowl. It wants to monitor brand reaction through social media channels but knows the #superbowl hashtag will be incredibly busy with game analysis and the activity of other brands. It needs a way to filter their brand mentions and gauge the sentiment of how users feel about their product launch.\nTo do this at scale would cost a fortune, and without an event-driven architecture, sending every user\u2019s message to a central server or data center to process and analyze would be incredibly slow. An event-driven system will be much more efficient, using cognitive services to carry out basic business logic at the edge.\nIn this way, the brand can monitor each message, determine whether it refers to the new colas, parse the sentiment of the relevant ones, and only pass the relevant information to the back end.\nTo do this, it could deploy edge computing resources to filter the messages with a natural language processing service, identifying which messages mentioned the brand and which were unrelated. From there, it could use a different cognitive service to analyze people\u2019s feelings about the different colas. It could even publish the popularity of the different products. And it could do all this without bringing the back-end servers into play.\nArchitecture for the Edge \u2014 and Beyond\nRESTful architectures were well-suited to an earlier, simpler generation of web applications. Modern applications demand a different approach, with their dense mesh of microservices, edge-computing nodes, and streams of data from sensors and devices.\nWhat applications need most now is an architecture that is light, flexible, and decentralized. Event-driven architecture satisfies on all counts \u2014 an elegant example of form following function.\n\nWant in-depth analysis of how cognitive services are changing everything? Check out our full eBook: A World Transformed: Building Smarter, Next Generation Apps with Cognitive Services. In it, we cover:\nWhat are cognitive services?\nHow cognitive services are transforming business\nCognitive services and edge computing\nUse cases of today and tomorrow\nOriginally published at dzone.com.\n"
  },
  {
    "title": "Best Practices for Custom Models in Watson Visual Recognition",
    "content": "Best Practices for Custom Models in Watson Visual Recognition\n\nSince the launch of the Watson Visual Recognition API, we\u2019ve seen users help California save water, perform infrastructure inspections with drones, and even find Pokemon. Powering many of these use cases are custom classifiers, a feature within Visual Recognition that allows users to train Watson on almost any visual content.\nTo create custom classifiers, users define categories they want to identify and upload example images for those categories. For example, a user wishing to identify different dog breeds may create 4 classes (golden retrievers, huskies, dalmatians, and beagles) and upload training images for each class. You can find this exact example in the Watson Visual Recognition demo or explore other tutorials on custom classifiers.\nCustom classifiers can be highly powerful but require careful training and content considerations to be properly optimized. Through our user conversations, we\u2019ve assembled a best practices guide below to help you get the most out of your custom classifiers.\nHow training can increase Watson Visual Recognition\u2019s quality\nThe accuracy you will see from your custom classifier depends directly on the quality of the training you perform. Clients in the past who closely controlled their training processes have observed greater than 98% accuracy for their use cases. Accuracy \u2014 different from confidence score \u2014 is based on a ground truth for a particular classification problem and particular data set.\n\u201cClients who closely control their image training processes observed greater than 98% accuracy\nAs a best practice, clients often create a ground truth to benchmark against human classification. Note that often humans make mistakes in classifications due to fatigue, reputation, carelessness, or other problems of the human condition.\nOn a basic level, images in training and testing sets should resemble each other. Significant visual differences between training and testing groups will result in poor performance results.\nThere are a number of additional factors that will impact the quality of your training beyond the resolution of your images. Lighting, angle, focus, color, shape, distance from subject, and presence of other objects in the image will all impact your training. Please note that Watson takes a holistic approach when being trained on each image. While it will evaluate all of the elements listed above, it cannot be tasked to exclusively consider a specific element.\nThe API will accept as few as 10 images per class, but we strongly recommend using a significantly greater amount of images to improve the performance and accuracy of your classifier. 100+ images per class is usually a good starting point to get more robust levels of accuracy.\nWhat is the score that I see for each tag?\nEach returned tag will include a confidence score between 0 and 1. This number does not represent a percentage of accuracy, but instead indicates Watson\u2019s confidence in the returned classification based on the training data for that classifier. The API will classify for all classes in the classifier, but you can adjust the threshold to only return results above a certain confidence score.\nThe custom classifier scores can be compared to one another to compare likelihoods, but they should be viewed as something that is compared to the cost/benefit of being right or wrong, and then a threshold for action needs to be chosen. Be aware that the nature of these numbers may change as we make changes to our system, and we will communicate these changes as they occur.\nFurther details about scores can be found here.\nExamples of difficult use cases\nWhile Watson Visual Recognition is highly flexible, there have been a number of recurring use case that we\u2019ve seen the API either struggle on or require significant pre/post-work from the user.\nFace Recognition: Visual Recognition is capable of face detection (detecting the presence of faces) not face recognition (identifying individuals).\nDetecting details: Occasionally, users want to classify an image based on a small section of an image or details scattered within an image. Because Watson analyzes the entire image when training, it may struggle on classifications that depend on small details. Some users have adopted the strategy of breaking the image into pieces or zooming into relevant parts of an image. See this guide for image pre-processing techniques.\nEmotion: Emotion classification (whether facial emotion or contextual emotion) is not a feature currently supported by Visual Recognition. Some users have attempted to do this through custom classifiers, but this is an edge case and we cannot estimate the accuracy of this type of training.\nExamples of good and bad training images\nGOOD: The following images were utilized for training and testing by our partner OmniEarth. This demonstrates good training since images in training and testing sets should resemble each other in regards to angle, lighting, distance, size of subject, etc. See the case study OmniEarth: Combating drought with IBM Watson cognitive capabilities for more details.\nTraining images:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single apple while the testing image shows a large group of apples taken from a distance with other visual items introduced (baskets, sign, etc). It\u2019s entirely possible that Watson may fail to classify the test image as \u2018apples,\u2019 especially if another class in the classifier contains training images of a large group of round objects (such as peaches, oranges ,etc).\nTraining image:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single sofa in a well-lit, studio-like setting while the testing image show a sofa that is partially cut off, farther away, and situated among many other objects in a real world setting. Watson may not be able to properly classify the test image due to the number of other objects cluttering the scene.\nTraining image:\n\nTesting image:\n\nNeed help or have questions?\nWe\u2019re excited to see what you build with Watson Visual Recognition, and we\u2019re happy to help you along the way. Try the custom classifiers feature, share any questions or comments you have on our developerWorks forums, and start building with Watson for free today.\nOriginally published at www.ibm.com on October 24, 2016.\n"
  },
  {
    "title": "Best Practices for Custom Models in Watson Visual Recognition",
    "content": "Best Practices for Custom Models in Watson Visual Recognition\n\nSince the launch of the Watson Visual Recognition API, we\u2019ve seen users help California save water, perform infrastructure inspections with drones, and even find Pokemon. Powering many of these use cases are custom classifiers, a feature within Visual Recognition that allows users to train Watson on almost any visual content.\nTo create custom classifiers, users define categories they want to identify and upload example images for those categories. For example, a user wishing to identify different dog breeds may create 4 classes (golden retrievers, huskies, dalmatians, and beagles) and upload training images for each class. You can find this exact example in the Watson Visual Recognition demo or explore other tutorials on custom classifiers.\nCustom classifiers can be highly powerful but require careful training and content considerations to be properly optimized. Through our user conversations, we\u2019ve assembled a best practices guide below to help you get the most out of your custom classifiers.\nHow training can increase Watson Visual Recognition\u2019s quality\nThe accuracy you will see from your custom classifier depends directly on the quality of the training you perform. Clients in the past who closely controlled their training processes have observed greater than 98% accuracy for their use cases. Accuracy \u2014 different from confidence score \u2014 is based on a ground truth for a particular classification problem and particular data set.\n\u201cClients who closely control their image training processes observed greater than 98% accuracy\nAs a best practice, clients often create a ground truth to benchmark against human classification. Note that often humans make mistakes in classifications due to fatigue, reputation, carelessness, or other problems of the human condition.\nOn a basic level, images in training and testing sets should resemble each other. Significant visual differences between training and testing groups will result in poor performance results.\nThere are a number of additional factors that will impact the quality of your training beyond the resolution of your images. Lighting, angle, focus, color, shape, distance from subject, and presence of other objects in the image will all impact your training. Please note that Watson takes a holistic approach when being trained on each image. While it will evaluate all of the elements listed above, it cannot be tasked to exclusively consider a specific element.\nThe API will accept as few as 10 images per class, but we strongly recommend using a significantly greater amount of images to improve the performance and accuracy of your classifier. 100+ images per class is usually a good starting point to get more robust levels of accuracy.\nWhat is the score that I see for each tag?\nEach returned tag will include a confidence score between 0 and 1. This number does not represent a percentage of accuracy, but instead indicates Watson\u2019s confidence in the returned classification based on the training data for that classifier. The API will classify for all classes in the classifier, but you can adjust the threshold to only return results above a certain confidence score.\nThe custom classifier scores can be compared to one another to compare likelihoods, but they should be viewed as something that is compared to the cost/benefit of being right or wrong, and then a threshold for action needs to be chosen. Be aware that the nature of these numbers may change as we make changes to our system, and we will communicate these changes as they occur.\nFurther details about scores can be found here.\nExamples of difficult use cases\nWhile Watson Visual Recognition is highly flexible, there have been a number of recurring use case that we\u2019ve seen the API either struggle on or require significant pre/post-work from the user.\nFace Recognition: Visual Recognition is capable of face detection (detecting the presence of faces) not face recognition (identifying individuals).\nDetecting details: Occasionally, users want to classify an image based on a small section of an image or details scattered within an image. Because Watson analyzes the entire image when training, it may struggle on classifications that depend on small details. Some users have adopted the strategy of breaking the image into pieces or zooming into relevant parts of an image. See this guide for image pre-processing techniques.\nEmotion: Emotion classification (whether facial emotion or contextual emotion) is not a feature currently supported by Visual Recognition. Some users have attempted to do this through custom classifiers, but this is an edge case and we cannot estimate the accuracy of this type of training.\nExamples of good and bad training images\nGOOD: The following images were utilized for training and testing by our partner OmniEarth. This demonstrates good training since images in training and testing sets should resemble each other in regards to angle, lighting, distance, size of subject, etc. See the case study OmniEarth: Combating drought with IBM Watson cognitive capabilities for more details.\nTraining images:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single apple while the testing image shows a large group of apples taken from a distance with other visual items introduced (baskets, sign, etc). It\u2019s entirely possible that Watson may fail to classify the test image as \u2018apples,\u2019 especially if another class in the classifier contains training images of a large group of round objects (such as peaches, oranges ,etc).\nTraining image:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single sofa in a well-lit, studio-like setting while the testing image show a sofa that is partially cut off, farther away, and situated among many other objects in a real world setting. Watson may not be able to properly classify the test image due to the number of other objects cluttering the scene.\nTraining image:\n\nTesting image:\n\nNeed help or have questions?\nWe\u2019re excited to see what you build with Watson Visual Recognition, and we\u2019re happy to help you along the way. Try the custom classifiers feature, share any questions or comments you have on our developerWorks forums, and start building with Watson for free today.\nOriginally published at www.ibm.com on October 24, 2016.\n"
  },
  {
    "title": "Best Practices for Custom Models in Watson Visual Recognition",
    "content": "Best Practices for Custom Models in Watson Visual Recognition\n\nSince the launch of the Watson Visual Recognition API, we\u2019ve seen users help California save water, perform infrastructure inspections with drones, and even find Pokemon. Powering many of these use cases are custom classifiers, a feature within Visual Recognition that allows users to train Watson on almost any visual content.\nTo create custom classifiers, users define categories they want to identify and upload example images for those categories. For example, a user wishing to identify different dog breeds may create 4 classes (golden retrievers, huskies, dalmatians, and beagles) and upload training images for each class. You can find this exact example in the Watson Visual Recognition demo or explore other tutorials on custom classifiers.\nCustom classifiers can be highly powerful but require careful training and content considerations to be properly optimized. Through our user conversations, we\u2019ve assembled a best practices guide below to help you get the most out of your custom classifiers.\nHow training can increase Watson Visual Recognition\u2019s quality\nThe accuracy you will see from your custom classifier depends directly on the quality of the training you perform. Clients in the past who closely controlled their training processes have observed greater than 98% accuracy for their use cases. Accuracy \u2014 different from confidence score \u2014 is based on a ground truth for a particular classification problem and particular data set.\n\u201cClients who closely control their image training processes observed greater than 98% accuracy\nAs a best practice, clients often create a ground truth to benchmark against human classification. Note that often humans make mistakes in classifications due to fatigue, reputation, carelessness, or other problems of the human condition.\nOn a basic level, images in training and testing sets should resemble each other. Significant visual differences between training and testing groups will result in poor performance results.\nThere are a number of additional factors that will impact the quality of your training beyond the resolution of your images. Lighting, angle, focus, color, shape, distance from subject, and presence of other objects in the image will all impact your training. Please note that Watson takes a holistic approach when being trained on each image. While it will evaluate all of the elements listed above, it cannot be tasked to exclusively consider a specific element.\nThe API will accept as few as 10 images per class, but we strongly recommend using a significantly greater amount of images to improve the performance and accuracy of your classifier. 100+ images per class is usually a good starting point to get more robust levels of accuracy.\nWhat is the score that I see for each tag?\nEach returned tag will include a confidence score between 0 and 1. This number does not represent a percentage of accuracy, but instead indicates Watson\u2019s confidence in the returned classification based on the training data for that classifier. The API will classify for all classes in the classifier, but you can adjust the threshold to only return results above a certain confidence score.\nThe custom classifier scores can be compared to one another to compare likelihoods, but they should be viewed as something that is compared to the cost/benefit of being right or wrong, and then a threshold for action needs to be chosen. Be aware that the nature of these numbers may change as we make changes to our system, and we will communicate these changes as they occur.\nFurther details about scores can be found here.\nExamples of difficult use cases\nWhile Watson Visual Recognition is highly flexible, there have been a number of recurring use case that we\u2019ve seen the API either struggle on or require significant pre/post-work from the user.\nFace Recognition: Visual Recognition is capable of face detection (detecting the presence of faces) not face recognition (identifying individuals).\nDetecting details: Occasionally, users want to classify an image based on a small section of an image or details scattered within an image. Because Watson analyzes the entire image when training, it may struggle on classifications that depend on small details. Some users have adopted the strategy of breaking the image into pieces or zooming into relevant parts of an image. See this guide for image pre-processing techniques.\nEmotion: Emotion classification (whether facial emotion or contextual emotion) is not a feature currently supported by Visual Recognition. Some users have attempted to do this through custom classifiers, but this is an edge case and we cannot estimate the accuracy of this type of training.\nExamples of good and bad training images\nGOOD: The following images were utilized for training and testing by our partner OmniEarth. This demonstrates good training since images in training and testing sets should resemble each other in regards to angle, lighting, distance, size of subject, etc. See the case study OmniEarth: Combating drought with IBM Watson cognitive capabilities for more details.\nTraining images:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single apple while the testing image shows a large group of apples taken from a distance with other visual items introduced (baskets, sign, etc). It\u2019s entirely possible that Watson may fail to classify the test image as \u2018apples,\u2019 especially if another class in the classifier contains training images of a large group of round objects (such as peaches, oranges ,etc).\nTraining image:\n\nTesting image:\n\nBAD: The following images demonstrate bad training since the training image shows a close-up shot of a single sofa in a well-lit, studio-like setting while the testing image show a sofa that is partially cut off, farther away, and situated among many other objects in a real world setting. Watson may not be able to properly classify the test image due to the number of other objects cluttering the scene.\nTraining image:\n\nTesting image:\n\nNeed help or have questions?\nWe\u2019re excited to see what you build with Watson Visual Recognition, and we\u2019re happy to help you along the way. Try the custom classifiers feature, share any questions or comments you have on our developerWorks forums, and start building with Watson for free today.\nOriginally published at www.ibm.com on October 24, 2016.\n"
  },
  {
    "title": "To perform like Magnus\u2026 relax like Magnus?",
    "content": "To perform like Magnus\u2026 relax like Magnus?\nMagnus Carlsen is the world\u2019s highest-rated chess player, and he doesn\u2019t spend all day playing chess. What role does that play in his success?\nMagnus Carlsen, 27, is the highest-rated (human) chess player of all-time and has been world chess champion since 2013. His first championship victory is captured in the very-enjoyable Magnus, now available on Netflix everywhere.\nMagnus, as one might expect, puts in hours of deliberate practice in trying to become the best at chess. He is quizzed by his head coach about historical positions; he analyzes his own games; he reads chess news to understand developments in other players.\nBut something else stands out about Magnus in the documentary: He spends a good amount of time doing things that aren\u2019t quite chess-related.\nSoon-to-be-World Champion Magnus Carlsen at his training camp in South Norway. Magnus asks \u201cWhy do I do that?\u201d about a missed volleyball hit \u2014 but he could also be asking a more meta question.\nRepeatedly in the film, Magnus is shown playing volleyball, ping pong, and swimming, even in the run-up to critical matches. At times when many others would be inclined to hunker down and cram, Magnus seems to find continued \u2018distractions\u2019 in other domains.\nNow, I will not pretend to have a comprehensive accounting of Magnus\u2019s practice hours; perhaps this is only a trivial subsection of Magnus\u2019s week. Additionally, Magnus is certainly not a slacker; he is shown studying chess when surrounded by family, for instance, when it would be easy to study just a bit less.\nBut Magnus\u2019s overall preparation style \u2014 and the varied activities \u2014 does not escape notice of his head coach, particularly compared with the documentary\u2019s portrayal of then-World Champion Vishy Anand: \u201cYou know, [Magnus] may not always be the most serious guy in training. But in his head, he has stuff going on. It\u2019s a different kind of approach than maybe other kinds of schools.\u201d\nMagnus plays ping pong with his head coach in lead-up to the chess world championship.\nMagnus without question puts in legwork for chess, but he also finds room for other activities. Without getting overly-rigorous (and at risk of leaning too pop-psychological), I think there are a few questions to consider for one\u2019s own performance after observing how Magnus spends portions of his preparation time:\nWould your performance benefit from time for more-complex realizations to form? As Magnus\u2019s coach notes, his time playing ping pong is not dead time from training, but rather time to gradually work over things without full-force thinking. Plenty of activities involve insight problems that aren\u2019t necessarily best solved by thinking harder or longer; many innovations arise from taking a concept in one domain and applying it to another. For Magnus, sports provide this \u2018idle work\u2019 time, just as many people find that taking walks encourages their best thinking. As an additional upside, sports help to keep the body active and healthy.\nWould your performance benefit from time to mentally recharge? Though this is not explicitly discussed as a factor in the documentary, I suspect a large reason for Magnus\u2019s breaks is that studying chess is exhausting. On a biological level, Stanford neuroscientist Robert Sapolsky contends that grand masters can burn thousands of calories per day in the course of a chess tournament (though it need not be several thousands to be significant). Even without the calorie consideration, many workers are only capable of peak productivity for stints of ~3 hours \u2014 though this isn\u2019t ironclad, and someone like Magnus very well may retain focus for longer. At some point, however, everyone will face diminishing returns \u2014 and when faced with diminishing returns, why not play ping pong? (Or sleep.)\nThis red-lined engine is at a balmy 37C, just like the human body. Coincidence? I think not.\nWould your performance be more sustainable with allowances for \u2018sub-optimal\u2019 activities? This question is also not discussed in the documentary, but I do wonder if Magnus\u2019s working in more time for sports and friendships will allow him to sustain peak performance for longer. On one hand, time spent in these ways might trade off with time spent training on chess and could in theory lead to worse short-run outcomes (though as discussed above, perhaps not). On the other hand, Magnus is a human being, and if these interests keep him happy, healthy, and motivated to keep pursuing his goals, his hobbies may well end up being instrumental to his success even if locally suboptimal. Put more simply, this is a question of avoiding burnout: If taking on certain stresses and time pressures will cause you to redline, perhaps they aren\u2019t the right path for your long-term career goals.\nI continue to be inspired by Magnus\u2019s journey to the top of the chess world, as well as by the feats of winetasters in Somm and friends of mine from the national debate community. (Not to mention my friend Max, who recently traveled to Germany to play Magnus in a game of chess\u2026 Max lost but clearly hasn\u2019t been playing enough ping pong.)\nWine: It\u2019s serious business. (Screenshot from Somm)\nThere\u2019s something fascinating about peak performance and the focus it inspires in people \u2014 and particularly when people seem to have found a balance between that focus and continuing to achieve their goals.\nOf course, in the future, computers might not face these tradeoffs that can constrain human performance today. (The Stockfish and AlphaZero chess engines, for instance, don\u2019t step away from chess to have dinner with their loved ones, at least as far as we know.)\nIt\u2019s worth considering, then, how demands on human performance may evolve over time, particularly as computers expand deeper into the realm of human activities and things previously considered art.\nAt chess, we can say with confidence that Magnus aka \u201cThe Mozart of Chess\u201d and the highest-rated human ever < Stockfish (the go-to chess engine for human preparation) < AlphaZero (a self-playing reinforcement learning agent that ran for less than a day [on incredibly high-end hardware]).\nUnfortunately for Magnus\u2019s computer-beating prospects, no amount of sleep or time training in other domains is likely to reverse that \u2014 but he might pose a model for us to increase our own productivity in the interim.\nSteven Adler is a former strategy consultant focused across AI, technology, and ethics.\nIf you want to follow along with Steven\u2019s projects and writings, make sure to follow this Medium account. Learn more on LinkedIn.\n"
  },
  {
    "title": "To perform like Magnus\u2026 relax like Magnus?",
    "content": "To perform like Magnus\u2026 relax like Magnus?\nMagnus Carlsen is the world\u2019s highest-rated chess player, and he doesn\u2019t spend all day playing chess. What role does that play in his success?\nMagnus Carlsen, 27, is the highest-rated (human) chess player of all-time and has been world chess champion since 2013. His first championship victory is captured in the very-enjoyable Magnus, now available on Netflix everywhere.\nMagnus, as one might expect, puts in hours of deliberate practice in trying to become the best at chess. He is quizzed by his head coach about historical positions; he analyzes his own games; he reads chess news to understand developments in other players.\nBut something else stands out about Magnus in the documentary: He spends a good amount of time doing things that aren\u2019t quite chess-related.\nSoon-to-be-World Champion Magnus Carlsen at his training camp in South Norway. Magnus asks \u201cWhy do I do that?\u201d about a missed volleyball hit \u2014 but he could also be asking a more meta question.\nRepeatedly in the film, Magnus is shown playing volleyball, ping pong, and swimming, even in the run-up to critical matches. At times when many others would be inclined to hunker down and cram, Magnus seems to find continued \u2018distractions\u2019 in other domains.\nNow, I will not pretend to have a comprehensive accounting of Magnus\u2019s practice hours; perhaps this is only a trivial subsection of Magnus\u2019s week. Additionally, Magnus is certainly not a slacker; he is shown studying chess when surrounded by family, for instance, when it would be easy to study just a bit less.\nBut Magnus\u2019s overall preparation style \u2014 and the varied activities \u2014 does not escape notice of his head coach, particularly compared with the documentary\u2019s portrayal of then-World Champion Vishy Anand: \u201cYou know, [Magnus] may not always be the most serious guy in training. But in his head, he has stuff going on. It\u2019s a different kind of approach than maybe other kinds of schools.\u201d\nMagnus plays ping pong with his head coach in lead-up to the chess world championship.\nMagnus without question puts in legwork for chess, but he also finds room for other activities. Without getting overly-rigorous (and at risk of leaning too pop-psychological), I think there are a few questions to consider for one\u2019s own performance after observing how Magnus spends portions of his preparation time:\nWould your performance benefit from time for more-complex realizations to form? As Magnus\u2019s coach notes, his time playing ping pong is not dead time from training, but rather time to gradually work over things without full-force thinking. Plenty of activities involve insight problems that aren\u2019t necessarily best solved by thinking harder or longer; many innovations arise from taking a concept in one domain and applying it to another. For Magnus, sports provide this \u2018idle work\u2019 time, just as many people find that taking walks encourages their best thinking. As an additional upside, sports help to keep the body active and healthy.\nWould your performance benefit from time to mentally recharge? Though this is not explicitly discussed as a factor in the documentary, I suspect a large reason for Magnus\u2019s breaks is that studying chess is exhausting. On a biological level, Stanford neuroscientist Robert Sapolsky contends that grand masters can burn thousands of calories per day in the course of a chess tournament (though it need not be several thousands to be significant). Even without the calorie consideration, many workers are only capable of peak productivity for stints of ~3 hours \u2014 though this isn\u2019t ironclad, and someone like Magnus very well may retain focus for longer. At some point, however, everyone will face diminishing returns \u2014 and when faced with diminishing returns, why not play ping pong? (Or sleep.)\nThis red-lined engine is at a balmy 37C, just like the human body. Coincidence? I think not.\nWould your performance be more sustainable with allowances for \u2018sub-optimal\u2019 activities? This question is also not discussed in the documentary, but I do wonder if Magnus\u2019s working in more time for sports and friendships will allow him to sustain peak performance for longer. On one hand, time spent in these ways might trade off with time spent training on chess and could in theory lead to worse short-run outcomes (though as discussed above, perhaps not). On the other hand, Magnus is a human being, and if these interests keep him happy, healthy, and motivated to keep pursuing his goals, his hobbies may well end up being instrumental to his success even if locally suboptimal. Put more simply, this is a question of avoiding burnout: If taking on certain stresses and time pressures will cause you to redline, perhaps they aren\u2019t the right path for your long-term career goals.\nI continue to be inspired by Magnus\u2019s journey to the top of the chess world, as well as by the feats of winetasters in Somm and friends of mine from the national debate community. (Not to mention my friend Max, who recently traveled to Germany to play Magnus in a game of chess\u2026 Max lost but clearly hasn\u2019t been playing enough ping pong.)\nWine: It\u2019s serious business. (Screenshot from Somm)\nThere\u2019s something fascinating about peak performance and the focus it inspires in people \u2014 and particularly when people seem to have found a balance between that focus and continuing to achieve their goals.\nOf course, in the future, computers might not face these tradeoffs that can constrain human performance today. (The Stockfish and AlphaZero chess engines, for instance, don\u2019t step away from chess to have dinner with their loved ones, at least as far as we know.)\nIt\u2019s worth considering, then, how demands on human performance may evolve over time, particularly as computers expand deeper into the realm of human activities and things previously considered art.\nAt chess, we can say with confidence that Magnus aka \u201cThe Mozart of Chess\u201d and the highest-rated human ever < Stockfish (the go-to chess engine for human preparation) < AlphaZero (a self-playing reinforcement learning agent that ran for less than a day [on incredibly high-end hardware]).\nUnfortunately for Magnus\u2019s computer-beating prospects, no amount of sleep or time training in other domains is likely to reverse that \u2014 but he might pose a model for us to increase our own productivity in the interim.\nSteven Adler is a former strategy consultant focused across AI, technology, and ethics.\nIf you want to follow along with Steven\u2019s projects and writings, make sure to follow this Medium account. Learn more on LinkedIn.\n"
  },
  {
    "title": "To perform like Magnus\u2026 relax like Magnus?",
    "content": "To perform like Magnus\u2026 relax like Magnus?\nMagnus Carlsen is the world\u2019s highest-rated chess player, and he doesn\u2019t spend all day playing chess. What role does that play in his success?\nMagnus Carlsen, 27, is the highest-rated (human) chess player of all-time and has been world chess champion since 2013. His first championship victory is captured in the very-enjoyable Magnus, now available on Netflix everywhere.\nMagnus, as one might expect, puts in hours of deliberate practice in trying to become the best at chess. He is quizzed by his head coach about historical positions; he analyzes his own games; he reads chess news to understand developments in other players.\nBut something else stands out about Magnus in the documentary: He spends a good amount of time doing things that aren\u2019t quite chess-related.\nSoon-to-be-World Champion Magnus Carlsen at his training camp in South Norway. Magnus asks \u201cWhy do I do that?\u201d about a missed volleyball hit \u2014 but he could also be asking a more meta question.\nRepeatedly in the film, Magnus is shown playing volleyball, ping pong, and swimming, even in the run-up to critical matches. At times when many others would be inclined to hunker down and cram, Magnus seems to find continued \u2018distractions\u2019 in other domains.\nNow, I will not pretend to have a comprehensive accounting of Magnus\u2019s practice hours; perhaps this is only a trivial subsection of Magnus\u2019s week. Additionally, Magnus is certainly not a slacker; he is shown studying chess when surrounded by family, for instance, when it would be easy to study just a bit less.\nBut Magnus\u2019s overall preparation style \u2014 and the varied activities \u2014 does not escape notice of his head coach, particularly compared with the documentary\u2019s portrayal of then-World Champion Vishy Anand: \u201cYou know, [Magnus] may not always be the most serious guy in training. But in his head, he has stuff going on. It\u2019s a different kind of approach than maybe other kinds of schools.\u201d\nMagnus plays ping pong with his head coach in lead-up to the chess world championship.\nMagnus without question puts in legwork for chess, but he also finds room for other activities. Without getting overly-rigorous (and at risk of leaning too pop-psychological), I think there are a few questions to consider for one\u2019s own performance after observing how Magnus spends portions of his preparation time:\nWould your performance benefit from time for more-complex realizations to form? As Magnus\u2019s coach notes, his time playing ping pong is not dead time from training, but rather time to gradually work over things without full-force thinking. Plenty of activities involve insight problems that aren\u2019t necessarily best solved by thinking harder or longer; many innovations arise from taking a concept in one domain and applying it to another. For Magnus, sports provide this \u2018idle work\u2019 time, just as many people find that taking walks encourages their best thinking. As an additional upside, sports help to keep the body active and healthy.\nWould your performance benefit from time to mentally recharge? Though this is not explicitly discussed as a factor in the documentary, I suspect a large reason for Magnus\u2019s breaks is that studying chess is exhausting. On a biological level, Stanford neuroscientist Robert Sapolsky contends that grand masters can burn thousands of calories per day in the course of a chess tournament (though it need not be several thousands to be significant). Even without the calorie consideration, many workers are only capable of peak productivity for stints of ~3 hours \u2014 though this isn\u2019t ironclad, and someone like Magnus very well may retain focus for longer. At some point, however, everyone will face diminishing returns \u2014 and when faced with diminishing returns, why not play ping pong? (Or sleep.)\nThis red-lined engine is at a balmy 37C, just like the human body. Coincidence? I think not.\nWould your performance be more sustainable with allowances for \u2018sub-optimal\u2019 activities? This question is also not discussed in the documentary, but I do wonder if Magnus\u2019s working in more time for sports and friendships will allow him to sustain peak performance for longer. On one hand, time spent in these ways might trade off with time spent training on chess and could in theory lead to worse short-run outcomes (though as discussed above, perhaps not). On the other hand, Magnus is a human being, and if these interests keep him happy, healthy, and motivated to keep pursuing his goals, his hobbies may well end up being instrumental to his success even if locally suboptimal. Put more simply, this is a question of avoiding burnout: If taking on certain stresses and time pressures will cause you to redline, perhaps they aren\u2019t the right path for your long-term career goals.\nI continue to be inspired by Magnus\u2019s journey to the top of the chess world, as well as by the feats of winetasters in Somm and friends of mine from the national debate community. (Not to mention my friend Max, who recently traveled to Germany to play Magnus in a game of chess\u2026 Max lost but clearly hasn\u2019t been playing enough ping pong.)\nWine: It\u2019s serious business. (Screenshot from Somm)\nThere\u2019s something fascinating about peak performance and the focus it inspires in people \u2014 and particularly when people seem to have found a balance between that focus and continuing to achieve their goals.\nOf course, in the future, computers might not face these tradeoffs that can constrain human performance today. (The Stockfish and AlphaZero chess engines, for instance, don\u2019t step away from chess to have dinner with their loved ones, at least as far as we know.)\nIt\u2019s worth considering, then, how demands on human performance may evolve over time, particularly as computers expand deeper into the realm of human activities and things previously considered art.\nAt chess, we can say with confidence that Magnus aka \u201cThe Mozart of Chess\u201d and the highest-rated human ever < Stockfish (the go-to chess engine for human preparation) < AlphaZero (a self-playing reinforcement learning agent that ran for less than a day [on incredibly high-end hardware]).\nUnfortunately for Magnus\u2019s computer-beating prospects, no amount of sleep or time training in other domains is likely to reverse that \u2014 but he might pose a model for us to increase our own productivity in the interim.\nSteven Adler is a former strategy consultant focused across AI, technology, and ethics.\nIf you want to follow along with Steven\u2019s projects and writings, make sure to follow this Medium account. Learn more on LinkedIn.\n"
  },
  {
    "title": "To perform like Magnus\u2026 relax like Magnus?",
    "content": "To perform like Magnus\u2026 relax like Magnus?\nMagnus Carlsen is the world\u2019s highest-rated chess player, and he doesn\u2019t spend all day playing chess. What role does that play in his success?\nMagnus Carlsen, 27, is the highest-rated (human) chess player of all-time and has been world chess champion since 2013. His first championship victory is captured in the very-enjoyable Magnus, now available on Netflix everywhere.\nMagnus, as one might expect, puts in hours of deliberate practice in trying to become the best at chess. He is quizzed by his head coach about historical positions; he analyzes his own games; he reads chess news to understand developments in other players.\nBut something else stands out about Magnus in the documentary: He spends a good amount of time doing things that aren\u2019t quite chess-related.\nSoon-to-be-World Champion Magnus Carlsen at his training camp in South Norway. Magnus asks \u201cWhy do I do that?\u201d about a missed volleyball hit \u2014 but he could also be asking a more meta question.\nRepeatedly in the film, Magnus is shown playing volleyball, ping pong, and swimming, even in the run-up to critical matches. At times when many others would be inclined to hunker down and cram, Magnus seems to find continued \u2018distractions\u2019 in other domains.\nNow, I will not pretend to have a comprehensive accounting of Magnus\u2019s practice hours; perhaps this is only a trivial subsection of Magnus\u2019s week. Additionally, Magnus is certainly not a slacker; he is shown studying chess when surrounded by family, for instance, when it would be easy to study just a bit less.\nBut Magnus\u2019s overall preparation style \u2014 and the varied activities \u2014 does not escape notice of his head coach, particularly compared with the documentary\u2019s portrayal of then-World Champion Vishy Anand: \u201cYou know, [Magnus] may not always be the most serious guy in training. But in his head, he has stuff going on. It\u2019s a different kind of approach than maybe other kinds of schools.\u201d\nMagnus plays ping pong with his head coach in lead-up to the chess world championship.\nMagnus without question puts in legwork for chess, but he also finds room for other activities. Without getting overly-rigorous (and at risk of leaning too pop-psychological), I think there are a few questions to consider for one\u2019s own performance after observing how Magnus spends portions of his preparation time:\nWould your performance benefit from time for more-complex realizations to form? As Magnus\u2019s coach notes, his time playing ping pong is not dead time from training, but rather time to gradually work over things without full-force thinking. Plenty of activities involve insight problems that aren\u2019t necessarily best solved by thinking harder or longer; many innovations arise from taking a concept in one domain and applying it to another. For Magnus, sports provide this \u2018idle work\u2019 time, just as many people find that taking walks encourages their best thinking. As an additional upside, sports help to keep the body active and healthy.\nWould your performance benefit from time to mentally recharge? Though this is not explicitly discussed as a factor in the documentary, I suspect a large reason for Magnus\u2019s breaks is that studying chess is exhausting. On a biological level, Stanford neuroscientist Robert Sapolsky contends that grand masters can burn thousands of calories per day in the course of a chess tournament (though it need not be several thousands to be significant). Even without the calorie consideration, many workers are only capable of peak productivity for stints of ~3 hours \u2014 though this isn\u2019t ironclad, and someone like Magnus very well may retain focus for longer. At some point, however, everyone will face diminishing returns \u2014 and when faced with diminishing returns, why not play ping pong? (Or sleep.)\nThis red-lined engine is at a balmy 37C, just like the human body. Coincidence? I think not.\nWould your performance be more sustainable with allowances for \u2018sub-optimal\u2019 activities? This question is also not discussed in the documentary, but I do wonder if Magnus\u2019s working in more time for sports and friendships will allow him to sustain peak performance for longer. On one hand, time spent in these ways might trade off with time spent training on chess and could in theory lead to worse short-run outcomes (though as discussed above, perhaps not). On the other hand, Magnus is a human being, and if these interests keep him happy, healthy, and motivated to keep pursuing his goals, his hobbies may well end up being instrumental to his success even if locally suboptimal. Put more simply, this is a question of avoiding burnout: If taking on certain stresses and time pressures will cause you to redline, perhaps they aren\u2019t the right path for your long-term career goals.\nI continue to be inspired by Magnus\u2019s journey to the top of the chess world, as well as by the feats of winetasters in Somm and friends of mine from the national debate community. (Not to mention my friend Max, who recently traveled to Germany to play Magnus in a game of chess\u2026 Max lost but clearly hasn\u2019t been playing enough ping pong.)\nWine: It\u2019s serious business. (Screenshot from Somm)\nThere\u2019s something fascinating about peak performance and the focus it inspires in people \u2014 and particularly when people seem to have found a balance between that focus and continuing to achieve their goals.\nOf course, in the future, computers might not face these tradeoffs that can constrain human performance today. (The Stockfish and AlphaZero chess engines, for instance, don\u2019t step away from chess to have dinner with their loved ones, at least as far as we know.)\nIt\u2019s worth considering, then, how demands on human performance may evolve over time, particularly as computers expand deeper into the realm of human activities and things previously considered art.\nAt chess, we can say with confidence that Magnus aka \u201cThe Mozart of Chess\u201d and the highest-rated human ever < Stockfish (the go-to chess engine for human preparation) < AlphaZero (a self-playing reinforcement learning agent that ran for less than a day [on incredibly high-end hardware]).\nUnfortunately for Magnus\u2019s computer-beating prospects, no amount of sleep or time training in other domains is likely to reverse that \u2014 but he might pose a model for us to increase our own productivity in the interim.\nSteven Adler is a former strategy consultant focused across AI, technology, and ethics.\nIf you want to follow along with Steven\u2019s projects and writings, make sure to follow this Medium account. Learn more on LinkedIn.\n"
  }
]